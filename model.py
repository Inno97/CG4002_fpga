#***************************************************************************************************
# custom driver file for the entire model, do not use the one generated by FINN
# 
# Project uses a 1D CNN, which is currently not supported by FINN in v0.3b
# 1D CNN utilizes Conv1D layers, which will take in multiple channels of data for time series
# convolution. Afterwards, the output from the convolution layers are flattened and then passed
# onto the fully connected layers.
#
# Due to Conv1D layers not being synthesizeable under FINN, the convolution layers will not be 
# hardware accelerated, while the fully connected layers will. This driver.py is meant to provide
# both the software and hardware layers.
#*************************************************************************************************** 

# for the model
from brevitas.core.bit_width import BitWidthImplType
from brevitas.core.quant import QuantType
from brevitas.core.restrict_val import RestrictValueType
from brevitas.core.scaling import ScalingImplType

import torch
from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d, MaxPool1d, Sequential

from brevitas.nn import QuantConv2d, QuantLinear
from brevitas.core.restrict_val import RestrictValueType

import quant_conv1d as qconv1d # local copy as it is not implemented in FINN v0.3b
import brevitas_commons as commons

#***************************************************************************************************
# Model
#***************************************************************************************************
build_dir = ""
model_path = "cnv_1d_5_56_all_3_normalized_4layer_final.pt"

# QuantConv1d configuration (i, OUT_CH, is_maxpool_enabled)
CNV_OUT_CH_POOL = [(0, 32, True)]
KERNEL_SIZE = 22 # default 3
NUM_CONV_LAYERS = 2

# Intermediate QuantLinear configuration
INTERMEDIATE_FC_PER_OUT_CH_SCALING = True
INTERMEDIATE_FC_FEATURES = [(256, 128)]  # (IN_CH, OUT_CH)

# Last QuantLinear configuration
LAST_FC_IN_FEATURES = 128
LAST_FC_PER_OUT_CH_SCALING = False

# MaxPool2d configuration
MAXPOOL_SIZE = 4

# fully connected dropout layers
IN_DROPOUT = 0.2
HIDDEN_DROPOUT = 0.2

# Network specific bit-widths and IO
WEIGHT_BIT_WIDTH = 1
ACT_BIT_WIDTH = 1
IN_BIT_WIDTH = 8
NUM_CLASSES = 9
IN_CHANNELS = 5

# only use inputs that are multiples of 4
INPUT_SPECIFICATIONS = (1, 5, 56) # batch size, channels, length

class CNV(Module):

    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device="cpu"):
        super(CNV, self).__init__()
        self.device = device

        weight_quant_type = commons.get_quant_type(weight_bit_width)
        act_quant_type = commons.get_quant_type(act_bit_width)
        in_quant_type = commons.get_quant_type(in_bit_width)
        stats_op = commons.get_stats_op(weight_quant_type)

        self.conv_features = ModuleList()
        self.linear_features = ModuleList()
        self.conv_features.append(commons.get_act_quant(in_bit_width, in_quant_type))

        # convolution layers
        for i, out_ch, is_pool_enabled in CNV_OUT_CH_POOL:
            self.conv_features.append(commons.get_quant_conv1d(in_ch=in_ch,
                                                       out_ch=out_ch,
                                                       bit_width=weight_bit_width,
                                                       quant_type=weight_quant_type,
                                                       stats_op=stats_op))
            in_ch = out_ch
            self.conv_features.append(BatchNorm1d(in_ch))
            if i == (NUM_CONV_LAYERS - 1):
                self.conv_features.append(Sequential())
            else:
                self.conv_features.append(commons.get_act_quant(act_bit_width, act_quant_type))
            if is_pool_enabled:
                self.conv_features.append(MaxPool1d(kernel_size=MAXPOOL_SIZE))

        # fully connected layers
        self.linear_features.append(commons.get_act_quant(in_bit_width, in_quant_type))
        
        for in_features, out_features in INTERMEDIATE_FC_FEATURES:
            self.linear_features.append(commons.get_quant_linear(in_features=in_features,
                                                         out_features=out_features,
                                                         per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,
                                                         bit_width=weight_bit_width,
                                                         quant_type=weight_quant_type,
                                                         stats_op=stats_op))
            self.linear_features.append(BatchNorm1d(out_features))
            self.linear_features.append(commons.get_act_quant(act_bit_width, act_quant_type))
            
        # last layer
        self.fc = get_quant_linear(in_features=LAST_FC_IN_FEATURES,
                                   out_features=num_classes,
                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,
                                   bit_width=weight_bit_width,
                                   quant_type=weight_quant_type,
                                   stats_op=stats_op)

    def forward(self, x):
        #x = 2.0 * x - torch.tensor([1.0]).to(self.device)
        for mod in self.conv_features:
            x = mod(x)
        x = x.view(x.shape[0], -1)
        
        for mod in self.linear_features:
            x = mod(x)
        out = self.fc(x)
        
        #out = self.fc_bn(x)
        return out

# this function will not be used as we wont use cfg, but if you want to, you can use this
def cnv(cfg):
    weight_bit_width = cfg.getint('QUANT', 'WEIGHT_BIT_WIDTH')
    act_bit_width = cfg.getint('QUANT', 'ACT_BIT_WIDTH')
    in_bit_width = cfg.getint('QUANT', 'IN_BIT_WIDTH')
    num_classes = cfg.getint('MODEL', 'NUM_CLASSES')
    in_channels = cfg.getint('MODEL', 'IN_CHANNELS')
    net = CNV(weight_bit_width=weight_bit_width,
              act_bit_width=act_bit_width,
              in_bit_width=in_bit_width,
              num_classes=num_classes,
              in_ch=in_channels)
    return net

# helper function to create the CNN
def cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):
    net = CNV(weight_bit_width=WEIGHT_BIT_WIDTH,
              act_bit_width=ACT_BIT_WIDTH,
              in_bit_width=IN_BIT_WIDTH,
              num_classes=NUM_CLASSES,
              in_ch=IN_CHANNELS)
    return net

# the software half
class CNV_software(Module):

    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device="cpu"):
        super(CNV_software, self).__init__()
        self.device = device

        weight_quant_type = commons.get_quant_type(weight_bit_width)
        act_quant_type = commons.get_quant_type(act_bit_width)
        in_quant_type = commons.get_quant_type(in_bit_width)
        stats_op = commons.get_stats_op(weight_quant_type)

        self.conv_features = ModuleList()
        self.conv_features.append(commons.get_act_quant(in_bit_width, in_quant_type))

        # convolution layers
        for i, out_ch, is_pool_enabled in CNV_OUT_CH_POOL:
            self.conv_features.append(commons.get_quant_conv1d(in_ch=in_ch,
                                                       out_ch=out_ch,
                                                       bit_width=weight_bit_width,
                                                       quant_type=weight_quant_type,
                                                       stats_op=stats_op))
            in_ch = out_ch
            self.conv_features.append(BatchNorm1d(in_ch))
            if i == (NUM_CONV_LAYERS - 1):
                self.conv_features.append(Sequential())
            else:
                self.conv_features.append(commons.get_act_quant(act_bit_width, act_quant_type))
            if is_pool_enabled:
                self.conv_features.append(MaxPool1d(kernel_size=MAXPOOL_SIZE))

    def forward(self, x):
        #x = 2.0 * x - torch.tensor([1.0]).to(self.device)
        for mod in self.conv_features:
            x = mod(x)
            
        x = x.view(x.shape[0], -1)
        
        return x

def cnv_software(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):
    net = CNV_software(weight_bit_width=WEIGHT_BIT_WIDTH,
              act_bit_width=ACT_BIT_WIDTH,
              in_bit_width=IN_BIT_WIDTH,
              num_classes=NUM_CLASSES,
              in_ch=IN_CHANNELS)
    return net

# loads the software layers automatically with pretrained weights
def cnv_software_auto():
    net = CNV_software(weight_bit_width=WEIGHT_BIT_WIDTH,
              act_bit_width=ACT_BIT_WIDTH,
              in_bit_width=IN_BIT_WIDTH,
              num_classes=NUM_CLASSES,
              in_ch=IN_CHANNELS)
    cnv_pretrained_model = cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)
    cnv_pretrained_model.load_state_dict(torch.load(build_dir + model_path))
    cnv_pretrained_model.eval()

    # copy over the layers
    net.conv_features = cnv_pretrained_model.conv_features

    return net

# the hardware portion of the model, this part is synthesized via FINN into a bitstream
# but it can still be run in software
class CNV_hardware(Module):

    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device="cpu"):
        super(CNV_hardware, self).__init__()
        self.device = device

        weight_quant_type = commons.get_quant_type(weight_bit_width)
        act_quant_type = commons.get_quant_type(act_bit_width)
        in_quant_type = commons.get_quant_type(in_bit_width)
        stats_op = commons.get_stats_op(weight_quant_type)

        self.linear_features = ModuleList()

        # fully connected layers
        self.linear_features.append(commons.get_act_quant(in_bit_width, in_quant_type))
        
        for in_features, out_features in INTERMEDIATE_FC_FEATURES:
            self.linear_features.append(commons.get_quant_linear(in_features=in_features,
                                                         out_features=out_features,
                                                         per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,
                                                         bit_width=weight_bit_width,
                                                         quant_type=weight_quant_type,
                                                         stats_op=stats_op))
            self.linear_features.append(BatchNorm1d(out_features))
            self.linear_features.append(commons.get_act_quant(act_bit_width, act_quant_type))
            
        # last layer
        self.fc = get_quant_linear(in_features=LAST_FC_IN_FEATURES,
                                   out_features=num_classes,
                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,
                                   bit_width=weight_bit_width,
                                   quant_type=weight_quant_type,
                                   stats_op=stats_op)

    def forward(self, x):        
        for mod in self.linear_features:
            x = mod(x)
        out = self.fc(x)
        
        return out
    
def cnv_hardware(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):
    net = CNV_hardware(weight_bit_width=WEIGHT_BIT_WIDTH,
              act_bit_width=ACT_BIT_WIDTH,
              in_bit_width=IN_BIT_WIDTH,
              num_classes=NUM_CLASSES,
              in_ch=IN_CHANNELS)
    return net

# loads the hardware layers automatically with pretrained weights
def cnv_hardware_auto():
    net = CNV_hardware(weight_bit_width=WEIGHT_BIT_WIDTH,
              act_bit_width=ACT_BIT_WIDTH,
              in_bit_width=IN_BIT_WIDTH,
              num_classes=NUM_CLASSES,
              in_ch=IN_CHANNELS)
              
    cnv_pretrained_model = cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)
    cnv_pretrained_model.load_state_dict(torch.load(build_dir + model_path))
    cnv_pretrained_model.eval()

    # copy over the layers
    net.linear_features = cnv_pretrained_model.linear_features
    net.fc = cnv_pretrained_model.fc
    
    return net
    