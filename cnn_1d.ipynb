{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End FINN Flow for a 1D Convolutional Net (FINN v0.31b)\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "FINN walkthrough for 1D CNN on Ultra96 for use in CG4002 by Daniel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "\n",
    "| Date | Changes |\n",
    "|:------:|:---------:|\n",
    "| 28/9/2020 | Added creation of CNN in section 1.1 (training not setup yet) |\n",
    "| 29/9/2020 | Tweaked creation of CNN and added notes for finn compilation. Added basic training and testing, with a simple CNN being implemented |\n",
    "| 5/10/2020 | Show accuracy and loss during training and cleaned up training code |\n",
    "| 19/10/2020 | Added Brevitas Conv1D layers and create new 1D CNN |\n",
    "| 20/10/2020 | Add extra 1D CNN using 16 inputs instead of 8, cleaned up notebook with end-to-end flow. |\n",
    "\n",
    "## To Do\n",
    "| |\n",
    "|:------|\n",
    "| Show hardware utilization by pulling logs from Vivado in /tmp/ |\n",
    "| Clean up this notebook (FINN transformation parts) |\n",
    "| Exporting to ONNX is not working for 1D CNN, for the hardware synthesis, copy over the FC layers, export and synthesize | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Recap of the End-to-End Flow\n",
    "\n",
    "The FINN compiler comes with many *transformations* that modify the ONNX representation of the network according to certain patterns. This notebook will demonstrate a *possible* sequence of such transformations to create a 1D CNN, train it and export to FINN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](finn-design-flow-example.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: toposort==1.5 from file:///workspace/finn/notebooks/CNN/toposort-1.5-py2.py3-none-any.whl in /workspace/.local/lib/python3.6/site-packages (1.5)\n",
      "toposort                      1.5      \n",
      "Requirement already satisfied: dependencies in /workspace/.local/lib/python3.6/site-packages (4.0.1)\n",
      "dependencies                  4.0.1    \n",
      "Requirement already satisfied: pandas in /workspace/.local/lib/python3.6/site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "pandas                        1.1.3    \n"
     ]
    }
   ],
   "source": [
    "# run this to install libaries, and restart the kernel for it to take effect\n",
    "\n",
    "# download the whl file on this local machine\n",
    "# restart the entire kernel after installation to have the notebook recognize modules\n",
    "# toposort may not be needed, will delete if needed\n",
    "!pip install /workspace/finn/notebooks/CNN/toposort-1.5-py2.py3-none-any.whl --user\n",
    "!pip list | grep \"toposort\"\n",
    "\n",
    "!pip install dependencies --user\n",
    "!pip list | grep \"dependencies\"\n",
    "\n",
    "!pip install pandas --user\n",
    "!pip list | grep \"pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the build directory and file name\n",
    "build_dir = \"/workspace/finn/notebooks/CNN\"\n",
    "file_name = \"/cnn_1d_3_classes_sample_dataset\"\n",
    "model_path = \"/cnv_1d_2_16.pt\"\n",
    "\n",
    "# exports a new model\n",
    "create_new_model = True\n",
    "\n",
    "# train the network, will implement loading of statedict later on\n",
    "train_network = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports are put here\n",
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "import datetime # for tracking time for each code block\n",
    "import time\n",
    "\n",
    "# 1. Brevitas Export, FINN Import and Tidy-Up\n",
    "\n",
    "# 1.1 Network Setup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from dependencies import Injector, value\n",
    "\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d, MaxPool1d, Sequential\n",
    "\n",
    "from brevitas.nn import QuantConv2d, QuantLinear\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "\n",
    "# 1.2 Training the Network\n",
    "\n",
    "# imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 1.3 Split Model into Conv1D and FC Layers\n",
    "import torch.nn.functional as func\n",
    "\n",
    "# 1.4 Export and Tidy-Up\n",
    "\n",
    "import onnx\n",
    "import brevitas.onnx as bo\n",
    "\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "\n",
    "# 2. How FINN Implements Convolutions: Lowering and Streamlining\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "\n",
    "# 3. Partitioning, Conversion to HLS Layers and Folding\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (CreateDataflowPartition,)\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_tlastmarker import InsertTLastMarker\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.util.basic import pynq_part_map\n",
    "\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (ReplaceVerilogRelPaths,)\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_tlastmarker import InsertTLastMarker\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "import toposort\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# 4. Hardware Generation\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation import Transformation\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import get_by_name, make_build_dir\n",
    "from finn.util.basic import get_num_default_workers\n",
    "from finn.util.basic import pynq_part_map\n",
    "\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (CreateDataflowPartition,)\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "from shutil import copy\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "\n",
    "# 5. Deployment and Remote Execution\n",
    "\n",
    "import pkg_resources as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "\n",
    "import numpy as np\n",
    "from finn.core.onnx_exec import execute_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing, Training and Exporting the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Network Setup\n",
    "\n",
    "Declare the network below, and then create the CNN.\n",
    "\n",
    "Note that you may have to trail and error for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# network for CNV_1w1a\\n# QuantConv2d configuration (IN_CH, OUT_CH, bias)\\nCNV_OUT_CH_POOL = [(0, 64, False), (1, 64, True), (2, 128, False), (3, 128, True), (4, 256, False), (5, 256, False)]\\n\\n# Intermediate QuantLinear configuration\\nINTERMEDIATE_FC_PER_OUT_CH_SCALING = True\\nINTERMEDIATE_FC_FEATURES = [(256, 512), (512, 512)] # (IN_CH, OUT_CH)\\n\\n# Last QuantLinear configuration\\nLAST_FC_IN_FEATURES = 512\\nLAST_FC_PER_OUT_CH_SCALING = False\\n\\n# MaxPool2d configuration\\nPOOL_SIZE = 2\\n\\n# Network specific bit-widths and IO\\nWEIGHT_BIT_WIDTH = 1\\nACT_BIT_WIDTH = 1\\nIN_BIT_WIDTH = 8\\nNUM_CLASSES = 10\\nIN_CHANNELS = 3\\n\\nINPUT_SPECIFICATIONS = (1, 3, 32, 32)\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare features of the CNN\n",
    "\n",
    "# notes on CNN structure:\n",
    "# conv layers should have alternating maxpool layers, and the last layer should not be a max pool layer\n",
    "# last layer needs Sequential() to flatten for the fully connected layers\n",
    "#\n",
    "# maxpool layers must have their input size be divisible by kernel size, this is mandatory\n",
    "# Conv1D is non-synthesizeable under FINN 0.3b\n",
    "\n",
    "# QuantConv1d configuration (i, OUT_CH, is_maxpool_enabled)\n",
    "CNV_OUT_CH_POOL = [(0, 16, False), (1, 32, True), (2, 64, False), (3, 128, False)]\n",
    "KERNEL_SIZE = 3 # default 3\n",
    "NUM_CONV_LAYERS = 3\n",
    "\n",
    "# Intermediate QuantLinear configuration\n",
    "INTERMEDIATE_FC_PER_OUT_CH_SCALING = True\n",
    "INTERMEDIATE_FC_FEATURES = [(256, 128)] # (IN_CH, OUT_CH)\n",
    "\n",
    "# Last QuantLinear configuration\n",
    "LAST_FC_IN_FEATURES = 128\n",
    "LAST_FC_PER_OUT_CH_SCALING = False\n",
    "\n",
    "# MaxPool2d configuration\n",
    "POOL_SIZE = 2\n",
    "\n",
    "# Network specific bit-widths and IO\n",
    "WEIGHT_BIT_WIDTH = 1\n",
    "ACT_BIT_WIDTH = 1\n",
    "IN_BIT_WIDTH = 8\n",
    "NUM_CLASSES = 3\n",
    "IN_CHANNELS = 2\n",
    "\n",
    "# only use inputs that are multiples of 4\n",
    "INPUT_SPECIFICATIONS = (1, 2, 16) # batch size, channels, length\n",
    "\n",
    "classes = [\"shrug\", \"zigzag\", \"windows\"]\n",
    "\n",
    "\"\"\"\n",
    "# network for CNV_1w1a\n",
    "# QuantConv2d configuration (IN_CH, OUT_CH, bias)\n",
    "CNV_OUT_CH_POOL = [(0, 64, False), (1, 64, True), (2, 128, False), (3, 128, True), (4, 256, False), (5, 256, False)]\n",
    "\n",
    "# Intermediate QuantLinear configuration\n",
    "INTERMEDIATE_FC_PER_OUT_CH_SCALING = True\n",
    "INTERMEDIATE_FC_FEATURES = [(256, 512), (512, 512)] # (IN_CH, OUT_CH)\n",
    "\n",
    "# Last QuantLinear configuration\n",
    "LAST_FC_IN_FEATURES = 512\n",
    "LAST_FC_PER_OUT_CH_SCALING = False\n",
    "\n",
    "# MaxPool2d configuration\n",
    "POOL_SIZE = 2\n",
    "\n",
    "# Network specific bit-widths and IO\n",
    "WEIGHT_BIT_WIDTH = 1\n",
    "ACT_BIT_WIDTH = 1\n",
    "IN_BIT_WIDTH = 8\n",
    "NUM_CLASSES = 10\n",
    "IN_CHANNELS = 3\n",
    "\n",
    "INPUT_SPECIFICATIONS = (1, 3, 32, 32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantConv1D as per https://github.com/Xilinx/brevitas/blob/quant_quartznet_4b-r0/brevitas/nn/quant_conv1d.py\n",
    "from enum import auto\n",
    "from typing import Union, Optional, Tuple\n",
    "import re\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import docrep\n",
    "from torch.nn import Conv1d, Module\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import conv1d\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from brevitas.core.bit_width import BitWidthParameter, BitWidthConst, BitWidthImplType\n",
    "from brevitas.core.quant import QuantType, IdentityQuant\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType, SCALING_SCALAR_SHAPE\n",
    "from brevitas.core.stats import StatsInputViewShapeImpl, StatsOp\n",
    "from brevitas.function.ops import max_uint, ceil_ste\n",
    "#from brevitas.function.ops_ste import ceil_ste\n",
    "from brevitas.proxy.parameter_quant import WeightQuantProxy, BiasQuantProxy, WeightReg\n",
    "from brevitas.utils.python_utils import AutoName\n",
    "from brevitas.nn.quant_layer import QuantLayer, SCALING_MIN_VAL\n",
    "from brevitas.config import docstrings\n",
    "__all__ = ['QuantConv1d']\n",
    "\n",
    "\n",
    "class PaddingType(AutoName):\n",
    "    STANDARD = auto()\n",
    "    SAME = auto()\n",
    "\n",
    "\n",
    "@docstrings.dedent\n",
    "class QuantConv1d(QuantLayer, Conv1d):\n",
    "    \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        %(weight_quant_proxy.parameters_with_prefix)s\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Union[int, Tuple[int]],\n",
    "                 stride: Union[int, Tuple[int]] = 1,\n",
    "                 padding: Union[int, Tuple[int]] = 0,\n",
    "                 padding_type: PaddingType = PaddingType.STANDARD,\n",
    "                 dilation: Union[int, Tuple[int]] = 1,\n",
    "                 groups: int = 1,\n",
    "                 bias: bool = True,\n",
    "                 bias_quant_type: QuantType = QuantType.FP,\n",
    "                 bias_narrow_range: bool = False,\n",
    "                 bias_bit_width: int = None,\n",
    "                 weight_quant_override: WeightQuantProxy = None,\n",
    "                 weight_quant_type: QuantType = QuantType.FP,\n",
    "                 weight_narrow_range: bool = False,\n",
    "                 weight_scaling_override: Optional[Module] = None,\n",
    "                 weight_bit_width_impl_override: Union[BitWidthParameter, BitWidthConst] = None,\n",
    "                 weight_bit_width_impl_type: BitWidthImplType = BitWidthImplType.CONST,\n",
    "                 weight_restrict_bit_width_type: RestrictValueType = RestrictValueType.INT,\n",
    "                 weight_bit_width: int = 32,\n",
    "                 weight_min_overall_bit_width: Optional[int] = 2,\n",
    "                 weight_max_overall_bit_width: Optional[int] = None,\n",
    "                 weight_scaling_impl_type: ScalingImplType = ScalingImplType.STATS,\n",
    "                 weight_scaling_const: Optional[float] = None,\n",
    "                 weight_scaling_stats_op: StatsOp = StatsOp.MAX,\n",
    "                 weight_scaling_per_output_channel: bool = False,\n",
    "                 weight_ternary_threshold: float = 0.5,\n",
    "                 weight_restrict_scaling_type: RestrictValueType = RestrictValueType.LOG_FP,\n",
    "                 weight_scaling_stats_sigma: float = 3.0,\n",
    "                 weight_scaling_min_val: float = SCALING_MIN_VAL,\n",
    "                 weight_override_pretrained_bit_width: bool = False,\n",
    "                 compute_output_scale: bool = False,\n",
    "                 compute_output_bit_width: bool = False,\n",
    "                 return_quant_tensor: bool = False) -> None:\n",
    "        QuantLayer.__init__(self,\n",
    "                            compute_output_scale=compute_output_scale,\n",
    "                            compute_output_bit_width=compute_output_bit_width,\n",
    "                            return_quant_tensor=return_quant_tensor)\n",
    "        Conv1d.__init__(self,\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                        dilation=dilation,\n",
    "                        groups=groups,\n",
    "                        bias=bias)\n",
    "        if weight_quant_type == QuantType.FP and compute_output_bit_width:\n",
    "            raise Exception(\"Computing output bit width requires enabling quantization\")\n",
    "        if bias_quant_type != QuantType.FP and not (compute_output_scale and compute_output_bit_width):\n",
    "            raise Exception(\"Quantizing bias requires to compute output scale and output bit width\")\n",
    "\n",
    "        self.per_elem_ops = 2 * self.kernel_size[0] * (in_channels // groups)\n",
    "        self.padding_type = padding_type\n",
    "        self.weight_reg = WeightReg()\n",
    "\n",
    "        if weight_quant_override is not None:\n",
    "            self.weight_quant = weight_quant_override\n",
    "            self.weight_quant.add_tracked_parameter(self.weight)\n",
    "        else:\n",
    "            weight_scaling_stats_input_concat_dim = 1\n",
    "            if weight_scaling_per_output_channel:\n",
    "                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n",
    "                weight_scaling_shape = self.per_output_channel_broadcastable_shape\n",
    "                weight_scaling_stats_reduce_dim = 1\n",
    "            else:\n",
    "                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_TENSOR\n",
    "                weight_scaling_shape = SCALING_SCALAR_SHAPE\n",
    "                weight_scaling_stats_reduce_dim = None\n",
    "\n",
    "            if weight_scaling_stats_op == StatsOp.MAX_AVE:\n",
    "                weight_stats_input_view_shape_impl = StatsInputViewShapeImpl.OVER_OUTPUT_CHANNELS\n",
    "                weight_scaling_stats_reduce_dim = 1\n",
    "\n",
    "            self.weight_quant = WeightQuantProxy(bit_width=weight_bit_width,\n",
    "                                                 quant_type=weight_quant_type,\n",
    "                                                 narrow_range=weight_narrow_range,\n",
    "                                                 scaling_override=weight_scaling_override,\n",
    "                                                 restrict_scaling_type=weight_restrict_scaling_type,\n",
    "                                                 scaling_const=weight_scaling_const,\n",
    "                                                 scaling_stats_op=weight_scaling_stats_op,\n",
    "                                                 scaling_impl_type=weight_scaling_impl_type,\n",
    "                                                 scaling_stats_reduce_dim=weight_scaling_stats_reduce_dim,\n",
    "                                                 scaling_shape=weight_scaling_shape,\n",
    "                                                 bit_width_impl_type=weight_bit_width_impl_type,\n",
    "                                                 bit_width_impl_override=weight_bit_width_impl_override,\n",
    "                                                 restrict_bit_width_type=weight_restrict_bit_width_type,\n",
    "                                                 min_overall_bit_width=weight_min_overall_bit_width,\n",
    "                                                 max_overall_bit_width=weight_max_overall_bit_width,\n",
    "                                                 tracked_parameter_list_init=self.weight,\n",
    "                                                 ternary_threshold=weight_ternary_threshold,\n",
    "                                                 scaling_stats_input_view_shape_impl=weight_stats_input_view_shape_impl,\n",
    "                                                 scaling_stats_input_concat_dim=weight_scaling_stats_input_concat_dim,\n",
    "                                                 scaling_stats_sigma=weight_scaling_stats_sigma,\n",
    "                                                 scaling_min_val=weight_scaling_min_val,\n",
    "                                                 override_pretrained_bit_width=weight_override_pretrained_bit_width)\n",
    "        self.bias_quant = BiasQuantProxy(quant_type=bias_quant_type,\n",
    "                                         bit_width=bias_bit_width,\n",
    "                                         narrow_range=bias_narrow_range)\n",
    "\n",
    "    @property\n",
    "    def per_output_channel_broadcastable_shape(self):\n",
    "        if self.transposed:\n",
    "            raise Exception(\"Transposed filters are not supported.\")\n",
    "        else:\n",
    "            output_dim = 0\n",
    "        per_channel_size = [1] * len(self.weight.size())\n",
    "        per_channel_size[output_dim] = self.out_channels\n",
    "        per_channel_size = tuple(per_channel_size)\n",
    "        return per_channel_size\n",
    "\n",
    "    @property\n",
    "    def int_weight(self):\n",
    "        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n",
    "            raise Exception(\"Can't export int weight without quantization enabled\")\n",
    "        return self.weight_quant.int_weight(self.weight)\n",
    "\n",
    "    @property\n",
    "    def quant_weight_scale(self):\n",
    "        \"\"\"\n",
    "        Returns scale factor of the quantized weights with scalar () shape or (self.out_channels, 1, 1)\n",
    "        shape depending on whether scaling is per layer or per-channel.\n",
    "        -------\n",
    "        \"\"\"\n",
    "        if isinstance(self.weight_quant.tensor_quant, IdentityQuant):\n",
    "            raise Exception(\"Can't generate scaling factor without quantization enabled\")\n",
    "        zero_hw_sentinel = self.weight_quant.zero_hw_sentinel\n",
    "        _, scale, _ = self.weight_quant.tensor_quant(self.weight, zero_hw_sentinel)\n",
    "        return scale\n",
    "\n",
    "    def forward(self, input):\n",
    "        output_scale = None\n",
    "        output_bit_width = None\n",
    "        quant_bias_bit_width = None\n",
    "\n",
    "        input, input_scale, input_bit_width = self.unpack_input(input)\n",
    "        quant_weight, quant_weight_scale, quant_weight_bit_width = self.weight_quant(self.weight)\n",
    "        quant_weight = self.weight_reg(quant_weight)\n",
    "\n",
    "        if self.compute_output_bit_width:\n",
    "            assert input_bit_width is not None\n",
    "            output_bit_width = self.max_output_bit_width(input_bit_width, quant_weight_bit_width)\n",
    "        if self.compute_output_scale:\n",
    "            assert input_scale is not None\n",
    "            output_scale = input_scale * quant_weight_scale\n",
    "\n",
    "        if self.bias is not None:\n",
    "            quant_bias, _, quant_bias_bit_width = self.bias_quant(self.bias, output_scale, output_bit_width)\n",
    "            output = self.conv1d(input, quant_weight, quant_bias)\n",
    "        else:\n",
    "            output = self.conv1d(input, quant_weight, None)\n",
    "\n",
    "        if self.compute_output_bit_width and quant_bias_bit_width is not None:\n",
    "            output_bit_width = torch.where(quant_bias_bit_width > output_bit_width,\n",
    "                                           quant_bias_bit_width,\n",
    "                                           output_bit_width)\n",
    "\n",
    "        return self.pack_output(output, output_scale, output_bit_width)\n",
    "\n",
    "    def conv1d(self, x, weight, bias):\n",
    "        if self.padding_type == PaddingType.SAME:\n",
    "            out = self.conv1d_same_padding(x, weight, bias)\n",
    "        else:\n",
    "            out = conv1d(x, weight, bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return out\n",
    "\n",
    "    def conv1d_same_padding(self, x, weight, bias):\n",
    "        ih = x.size()[-1]\n",
    "        kh = weight.size()[-1]\n",
    "        sh = self.stride[0]\n",
    "        oh = math.ceil(ih / sh)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        if pad_h > 0:\n",
    "            x = F.pad(x, [pad_h // 2, pad_h - pad_h // 2])\n",
    "        out = F.conv1d(x, weight, bias, self.stride, 0, self.dilation, self.groups)\n",
    "        return out\n",
    "\n",
    "    def merge_bn_in(self, bn, affine_only, sign_only):\n",
    "        raise Exception(\"Merged Batch-Normalization is not yet supported\")\n",
    "\n",
    "    def max_output_bit_width(self, input_bit_width, weight_bit_width):\n",
    "        max_uint_input = max_uint(bit_width=input_bit_width, narrow_range=False)\n",
    "        max_kernel_val = self.weight_quant.tensor_quant.int_quant.max_uint(weight_bit_width)\n",
    "        group_size = self.out_channels // self.groups\n",
    "        max_uint_output = max_uint_input * max_kernel_val * self.kernel_size[0] * group_size\n",
    "        max_output_bit_width = ceil_ste(torch.log2(max_uint_output))\n",
    "        return max_output_bit_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.stats import StatsOp\n",
    "from brevitas.nn import QuantConv2d, QuantHardTanh, QuantLinear\n",
    "\n",
    "# Quant common\n",
    "BIT_WIDTH_IMPL_TYPE = BitWidthImplType.CONST\n",
    "SCALING_VALUE_TYPE = RestrictValueType.LOG_FP\n",
    "SCALING_IMPL_TYPE = ScalingImplType.PARAMETER\n",
    "NARROW_RANGE_ENABLED = True\n",
    "\n",
    "# Weight quant common\n",
    "STATS_OP = StatsOp.MEAN_LEARN_SIGMA_STD\n",
    "BIAS_ENABLED = False\n",
    "WEIGHT_SCALING_IMPL_TYPE = ScalingImplType.STATS\n",
    "SIGMA = 0.001\n",
    "\n",
    "# QuantHardTanh configuration\n",
    "HARD_TANH_MIN = -1.0\n",
    "HARD_TANH_MAX = 1.0\n",
    "ACT_PER_OUT_CH_SCALING = False\n",
    "\n",
    "# QuantConv2d configuration\n",
    "CONV_PER_OUT_CH_SCALING = True\n",
    "\n",
    "def get_stats_op(quant_type):\n",
    "    if quant_type == QuantType.BINARY:\n",
    "        return StatsOp.AVE\n",
    "    else:\n",
    "        return StatsOp.MAX\n",
    "\n",
    "\n",
    "def get_quant_type(bit_width):\n",
    "    if bit_width is None:\n",
    "        return QuantType.FP\n",
    "    elif bit_width == 1:\n",
    "        return QuantType.BINARY\n",
    "    else:\n",
    "        return QuantType.INT\n",
    "\n",
    "\n",
    "def get_act_quant(act_bit_width, act_quant_type):\n",
    "    if act_quant_type == QuantType.INT:\n",
    "        act_scaling_impl_type = ScalingImplType.PARAMETER\n",
    "    else:\n",
    "        act_scaling_impl_type = ScalingImplType.CONST\n",
    "    return QuantHardTanh(quant_type=act_quant_type,\n",
    "                         bit_width=act_bit_width,\n",
    "                         bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                         min_val=HARD_TANH_MIN,\n",
    "                         max_val=HARD_TANH_MAX,\n",
    "                         scaling_impl_type=act_scaling_impl_type,\n",
    "                         restrict_scaling_type=SCALING_VALUE_TYPE,\n",
    "                         scaling_per_channel=ACT_PER_OUT_CH_SCALING,\n",
    "                         narrow_range=NARROW_RANGE_ENABLED)\n",
    "\n",
    "\n",
    "def get_quant_linear(in_features, out_features, per_out_ch_scaling, bit_width, quant_type, stats_op):\n",
    "    return QuantLinear(bias=BIAS_ENABLED,\n",
    "                       in_features=in_features,\n",
    "                       out_features=out_features,\n",
    "                       weight_quant_type=quant_type,\n",
    "                       weight_narrow_range=NARROW_RANGE_ENABLED,\n",
    "                       weight_bit_width=bit_width,\n",
    "                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                       weight_scaling_per_output_channel=per_out_ch_scaling,\n",
    "                       weight_scaling_stats_op=stats_op,\n",
    "                       weight_scaling_stats_sigma=SIGMA)\n",
    "\n",
    "\n",
    "def get_quant_conv2d(in_ch, out_ch, bit_width, quant_type, stats_op):\n",
    "    return QuantConv2d(in_channels=in_ch,\n",
    "                       kernel_size=KERNEL_SIZE,\n",
    "                       out_channels=out_ch,\n",
    "                       weight_quant_type=quant_type,\n",
    "                       weight_bit_width=bit_width,\n",
    "                       weight_narrow_range=NARROW_RANGE_ENABLED,\n",
    "                       weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n",
    "                       weight_scaling_stats_op=stats_op,\n",
    "                       weight_scaling_stats_sigma=SIGMA,\n",
    "                       weight_scaling_per_output_channel=CONV_PER_OUT_CH_SCALING,\n",
    "                       weight_restrict_scaling_type=SCALING_VALUE_TYPE,\n",
    "                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                       bias=BIAS_ENABLED)\n",
    "\n",
    "def get_quant_conv1d(in_ch, out_ch, bit_width, quant_type, stats_op):\n",
    "    return QuantConv1d(in_channels=in_ch,\n",
    "                       kernel_size=KERNEL_SIZE,\n",
    "                       out_channels=out_ch,\n",
    "                       weight_quant_type=quant_type,\n",
    "                       weight_bit_width=bit_width,\n",
    "                       weight_narrow_range=NARROW_RANGE_ENABLED,\n",
    "                       weight_scaling_impl_type=WEIGHT_SCALING_IMPL_TYPE,\n",
    "                       weight_scaling_stats_op=stats_op,\n",
    "                       weight_scaling_stats_sigma=SIGMA,\n",
    "                       weight_scaling_per_output_channel=CONV_PER_OUT_CH_SCALING,\n",
    "                       weight_restrict_scaling_type=SCALING_VALUE_TYPE,\n",
    "                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                       bias=BIAS_ENABLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the classes needed for the CNN, taken from: https://github.com/maltanar/brevitas_cnv_lfc\n",
    "# this is where the pre-trained models also come from, however, we will import the whole thing here to make custom CNNs\n",
    "class CNV(Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device=\"cpu\"):\n",
    "        super(CNV, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        weight_quant_type = get_quant_type(weight_bit_width)\n",
    "        act_quant_type = get_quant_type(act_bit_width)\n",
    "        in_quant_type = get_quant_type(in_bit_width)\n",
    "        stats_op = get_stats_op(weight_quant_type)\n",
    "\n",
    "        self.conv_features = ModuleList()\n",
    "        self.linear_features = ModuleList()\n",
    "        self.conv_features.append(get_act_quant(in_bit_width, in_quant_type))\n",
    "\n",
    "        # convolution layers\n",
    "        for i, out_ch, is_pool_enabled in CNV_OUT_CH_POOL:\n",
    "            self.conv_features.append(get_quant_conv1d(in_ch=in_ch,\n",
    "                                                       out_ch=out_ch,\n",
    "                                                       bit_width=weight_bit_width,\n",
    "                                                       quant_type=weight_quant_type,\n",
    "                                                       stats_op=stats_op))\n",
    "            in_ch = out_ch\n",
    "            self.conv_features.append(BatchNorm1d(in_ch))\n",
    "            if i == (NUM_CONV_LAYERS - 1):\n",
    "                self.conv_features.append(Sequential())\n",
    "            self.conv_features.append(get_act_quant(act_bit_width, act_quant_type))\n",
    "            if is_pool_enabled:\n",
    "                self.conv_features.append(MaxPool1d(kernel_size=2))\n",
    "\n",
    "        # fully connected layers\n",
    "        for in_features, out_features in INTERMEDIATE_FC_FEATURES:\n",
    "            self.linear_features.append(get_quant_linear(in_features=in_features,\n",
    "                                                         out_features=out_features,\n",
    "                                                         per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n",
    "                                                         bit_width=weight_bit_width,\n",
    "                                                         quant_type=weight_quant_type,\n",
    "                                                         stats_op=stats_op))\n",
    "            self.linear_features.append(BatchNorm1d(out_features))\n",
    "            self.linear_features.append(get_act_quant(act_bit_width, act_quant_type))\n",
    "            \n",
    "        # last layer\n",
    "        self.fc = get_quant_linear(in_features=LAST_FC_IN_FEATURES,\n",
    "                                   out_features=num_classes,\n",
    "                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n",
    "                                   bit_width=weight_bit_width,\n",
    "                                   quant_type=weight_quant_type,\n",
    "                                   stats_op=stats_op)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0]).to(self.device)\n",
    "        for mod in self.conv_features:\n",
    "            x = mod(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        for mod in self.linear_features:\n",
    "            x = mod(x)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "# will not be used as we wont use cfg\n",
    "def cnv(cfg):\n",
    "    weight_bit_width = cfg.getint('QUANT', 'WEIGHT_BIT_WIDTH')\n",
    "    act_bit_width = cfg.getint('QUANT', 'ACT_BIT_WIDTH')\n",
    "    in_bit_width = cfg.getint('QUANT', 'IN_BIT_WIDTH')\n",
    "    num_classes = cfg.getint('MODEL', 'NUM_CLASSES')\n",
    "    in_channels = cfg.getint('MODEL', 'IN_CHANNELS')\n",
    "    net = CNV(weight_bit_width=weight_bit_width,\n",
    "              act_bit_width=act_bit_width,\n",
    "              in_bit_width=in_bit_width,\n",
    "              num_classes=num_classes,\n",
    "              in_ch=in_channels)\n",
    "    return net\n",
    "\n",
    "def cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):\n",
    "    net = CNV(weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "              act_bit_width=ACT_BIT_WIDTH,\n",
    "              in_bit_width=IN_BIT_WIDTH,\n",
    "              num_classes=NUM_CLASSES,\n",
    "              in_ch=IN_CHANNELS)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV(\n",
      "  (conv_features): ModuleList(\n",
      "    (0): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): RescalingIntQuant(\n",
      "            (int_quant): IntQuant(\n",
      "              (float_to_int_impl): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): RoundSte()\n",
      "                  (1): Identity()\n",
      "                )\n",
      "              )\n",
      "              (tensor_clamp_impl): TensorClamp()\n",
      "            )\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (int_scaling_impl): IntScaling(\n",
      "              (forward_impl): SignedFpIntScale()\n",
      "            )\n",
      "            (msb_clamp_bit_width_impl): BitWidthConst()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): QuantConv1d(\n",
      "      2, 16, kernel_size=(3,), stride=(1,), bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): QuantConv1d(\n",
      "      16, 32, kernel_size=(3,), stride=(1,), bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): QuantConv1d(\n",
      "      32, 64, kernel_size=(3,), stride=(1,), bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Sequential()\n",
      "    (11): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): QuantConv1d(\n",
      "      64, 128, kernel_size=(3,), stride=(1,), bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_features): ModuleList(\n",
      "    (0): QuantLinear(\n",
      "      in_features=256, out_features=128, bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): QuantLinear(\n",
      "    in_features=128, out_features=3, bias=False\n",
      "    (weight_reg): WeightReg()\n",
      "    (weight_quant): WeightQuantProxy(\n",
      "      (tensor_quant): BinaryQuant(\n",
      "        (scaling_impl): ParameterStatsScaling(\n",
      "          (parameter_list_stats): ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper()\n",
      "            (stats): Stats(\n",
      "              (stats_impl): AbsAve()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_scaling): RestrictValue(\n",
      "              (forward_impl): Sequential(\n",
      "                (0): PowerOfTwo()\n",
      "                (1): ClampMin()\n",
      "              )\n",
      "            )\n",
      "            (restrict_scaling_preprocess): LogTwo()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxy()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the model and export\n",
    "bnn_pynq_model = cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)\n",
    "\n",
    "# print for reference\n",
    "print(bnn_pynq_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Training the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24575, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data from csv\n",
    "df = pd.read_csv('dataset_3classes_2_16.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([720, 2, 16])\n",
      "torch.Size([180, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "# stitch together 8 inputs (1x8) to make a 8x8 input, and make the training / testing data\n",
    "\n",
    "def parse_input(df, starting_index):\n",
    "    data = np.array(((df.iloc[starting_index, 0],df.iloc[starting_index + 1,0],df.iloc[starting_index + 2,0],df.iloc[starting_index + 3,0],df.iloc[starting_index + 4,0],df.iloc[starting_index + 5,0],df.iloc[starting_index + 6,0],df.iloc[starting_index + 7,0],\n",
    "                  df.iloc[starting_index + 8, 0], df.iloc[starting_index + 9, 0], df.iloc[starting_index + 10, 0], df.iloc[starting_index + 11, 0], df.iloc[starting_index + 12, 0], df.iloc[starting_index + 13, 0], df.iloc[starting_index + 14, 0], df.iloc[starting_index + 15, 0]),\n",
    "                 (df.iloc[starting_index, 1],df.iloc[starting_index + 1, 1],df.iloc[starting_index + 2, 1],df.iloc[starting_index + 3, 1],df.iloc[starting_index + 4, 1],df.iloc[starting_index + 5, 1],df.iloc[starting_index + 6, 1],df.iloc[starting_index + 7, 1], \n",
    "                  df.iloc[starting_index + 8, 1], df.iloc[starting_index + 9, 1], df.iloc[starting_index + 10, 1], df.iloc[starting_index + 11, 1], df.iloc[starting_index + 12, 1], df.iloc[starting_index + 13, 1], df.iloc[starting_index + 14, 1], df.iloc[starting_index + 15, 1])))\n",
    "    return data\n",
    "\n",
    "# 20% set aside for testing\n",
    "num_items = (df.shape[0]) // 8\n",
    "max_data = 900\n",
    "batch_size = 2\n",
    "\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(num_items):\n",
    "    if i == max_data:\n",
    "        break\n",
    "    starting_index = i * 8 * (num_items // max_data)\n",
    "    \n",
    "    # 16 inputs\n",
    "    data = parse_input(df, starting_index)\n",
    "    \n",
    "    # do encoding, go by index as shown below\n",
    "    if 'shrug' in df.iloc[starting_index, 2]:\n",
    "        value = (0)\n",
    "    elif 'zigzag' in df.iloc[starting_index, 2]:\n",
    "        value = (1)\n",
    "    elif 'windows' in df.iloc[starting_index, 2]:\n",
    "        value = (2)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    if i % 5 != 4: # training\n",
    "        x_train_list.append(data)\n",
    "        y_train_list.append(value) \n",
    "    else: # testing\n",
    "        x_test_list.append(data)\n",
    "        y_test_list.append(value)\n",
    "        \n",
    "# remove extra inputs that cannot fit in batch_size\n",
    "while len(x_train_list) % batch_size != 0:\n",
    "    x_train_list.pop()\n",
    "    y_train_list.pop()\n",
    "    \n",
    "while len(x_test_list) % batch_size != 0:\n",
    "    x_test_list.pop()\n",
    "    y_test_list.pop()\n",
    "        \n",
    "# transform to PyTorch DataLoader\n",
    "tensor_x_train = torch.Tensor(x_train_list) # transform to torch tensor\n",
    "tensor_y_train = torch.Tensor(y_train_list)\n",
    "    \n",
    "print(tensor_x_train.size())\n",
    "\n",
    "dataset_train = TensorDataset(tensor_x_train,tensor_y_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size = batch_size, shuffle = True, num_workers = 1)\n",
    "\n",
    "tensor_x_test = torch.Tensor(x_test_list) # transform to torch tensor\n",
    "tensor_y_test = torch.Tensor(y_test_list)\n",
    "    \n",
    "print(tensor_x_test.size())\n",
    "\n",
    "dataset_test = TensorDataset(tensor_x_test,tensor_y_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size = batch_size, shuffle = True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "# validate input data size\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.1\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "log_freq = 10\n",
    "\n",
    "EPOCHS = 25 # we'll see how long it takes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # linux CUDA not set up yet\n",
    "\n",
    "# training stuff\n",
    "# like the CNN model, it is taken from https://github.com/maltanar/brevitas_cnv_lfc\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class TrainingEpochMeters(object):\n",
    "    def __init__(self):\n",
    "        self.batch_time = AverageMeter()\n",
    "        self.data_time = AverageMeter()\n",
    "        self.losses = AverageMeter()\n",
    "        self.top1 = AverageMeter()\n",
    "        self.top5 = AverageMeter()\n",
    "\n",
    "class EvalEpochMeters(object):\n",
    "    def __init__(self):\n",
    "        self.model_time = AverageMeter()\n",
    "        self.loss_time = AverageMeter()\n",
    "        self.losses = AverageMeter()\n",
    "        self.top1 = AverageMeter()\n",
    "        self.top5 = AverageMeter()\n",
    "\n",
    "def eval_model(epoch=None):\n",
    "    eval_meters = EvalEpochMeters()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    bnn_pynq_model.eval()\n",
    "    criterion.eval()\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "\n",
    "        end = time.time()\n",
    "        (input, target) = data\n",
    "\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = bnn_pynq_model(input)\n",
    "\n",
    "        # measure model elapsed time\n",
    "        eval_meters.model_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        #compute loss\n",
    "        loss = criterion(output, target.long())\n",
    "        eval_meters.loss_time.update(time.time() - end)\n",
    "\n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, NUM_CLASSES))\n",
    "        eval_meters.losses.update(loss.item(), input.size(0))\n",
    "        eval_meters.top1.update(prec1.item(), input.size(0))\n",
    "        eval_meters.top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred).long())\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def softmax_train(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def get_prediction_train(output_tensor):\n",
    "    prediction_list = softmax_train(output_tensor.tolist())\n",
    "    max_val = -1\n",
    "    prediction = 0\n",
    "    for i in range(len(prediction_list)):\n",
    "        if prediction_list[i] > max_val:\n",
    "            max_val = prediction_list[i]\n",
    "            prediction = i\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# returns the number of correct predictions\n",
    "def compare_output(output, target):\n",
    "    running_total = 0\n",
    "    \n",
    "    # iterate for each item in \n",
    "    for i in range(len(output)):\n",
    "        if get_prediction_train(output[i]) == int(target.tolist()[i]):\n",
    "            running_total += 1\n",
    "    \n",
    "    return running_total\n",
    "        \n",
    "def train_model():\n",
    "    optimizer = optim.SGD(bnn_pynq_model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    # training starts\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # keep track of training / testing metrics\n",
    "    num_inputs_training = len(train_loader) * batch_size\n",
    "    num_inputs_testing = len(test_loader) * batch_size\n",
    "        \n",
    "    for epoch in range(EPOCHS):\n",
    "        # keep track of training / testing metrics\n",
    "        running_loss_training = 0.0\n",
    "        running_loss_testing = 0.0\n",
    "        num_inputs_training_correct = 0\n",
    "        num_inputs_testing_correct = 0\n",
    "\n",
    "        # Set to training mode\n",
    "        bnn_pynq_model.train()\n",
    "        criterion.train()\n",
    "\n",
    "        # Init metrics\n",
    "        epoch_meters = TrainingEpochMeters()\n",
    "        start_data_loading = time.time()\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            (input, target) = data\n",
    "            #print(\"input\", input)\n",
    "            #print(\"target\", target)\n",
    "            \n",
    "            input = input.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            \n",
    "            # measure data loading time\n",
    "            epoch_meters.data_time.update(time.time() - start_data_loading)\n",
    "\n",
    "            # Training batch starts\n",
    "            start_batch = time.time()\n",
    "            output = bnn_pynq_model(input)\n",
    "            loss = criterion(output, target.long())\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # measure elapsed time\n",
    "            epoch_meters.batch_time.update(time.time() - start_batch)\n",
    "            if i % int(log_freq) == 0 or i == len(train_loader) - 1:\n",
    "                # set the third value of topk depending on the number of classes\n",
    "                prec1, prec5 = accuracy(output.detach(), target, topk=(1, NUM_CLASSES))\n",
    "                epoch_meters.losses.update(loss.item(), input.size(0))\n",
    "                epoch_meters.top1.update(prec1.item(), input.size(0))\n",
    "                epoch_meters.top5.update(prec5.item(), input.size(0))\n",
    "                #self.logger.training_batch_cli_log(epoch_meters, epoch, i, len(self.train_loader))\n",
    "                \n",
    "            # update loss and accuracy\n",
    "            running_loss_training += loss.item()\n",
    "            num_inputs_training_correct += compare_output(output, target.long())\n",
    "\n",
    "            # training batch ends\n",
    "            #start_data_loading = time.time()\n",
    "            \n",
    "        # validate\n",
    "        for j, data in enumerate(test_loader):\n",
    "            (input, target) = data\n",
    "            \n",
    "            input = input.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            \n",
    "            output = bnn_pynq_model(input)\n",
    "            loss = criterion(output, target.long())\n",
    "        \n",
    "            # update loss and accuracy\n",
    "            running_loss_testing += loss.item()\n",
    "            num_inputs_testing_correct += compare_output(output, target.long())\n",
    "            \n",
    "        print('Epoch [%d] (took %.3f) training loss: %.3f, accuracy: %.3f, validation loss: %.3f, accuracy: %.3f' \n",
    "              % (epoch + 1, time.time() - start_data_loading, running_loss_training / num_inputs_training, num_inputs_training_correct / num_inputs_training, \n",
    "                running_loss_testing / num_inputs_testing, num_inputs_testing_correct / num_inputs_testing))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Perform eval\n",
    "        with torch.no_grad():\n",
    "            top1avg = eval_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] (took 41.889) training loss: 0.496, accuracy: 0.503, validation loss: 0.437, accuracy: 0.650\n",
      "Epoch [2] (took 41.234) training loss: 0.389, accuracy: 0.694, validation loss: 0.354, accuracy: 0.639\n",
      "Epoch [3] (took 41.943) training loss: 0.331, accuracy: 0.729, validation loss: 0.302, accuracy: 0.756\n",
      "Epoch [4] (took 42.769) training loss: 0.309, accuracy: 0.761, validation loss: 0.267, accuracy: 0.783\n",
      "Epoch [5] (took 49.936) training loss: 0.280, accuracy: 0.812, validation loss: 0.361, accuracy: 0.767\n",
      "Epoch [6] (took 41.346) training loss: 0.317, accuracy: 0.776, validation loss: 0.282, accuracy: 0.761\n",
      "Epoch [7] (took 38.242) training loss: 0.326, accuracy: 0.776, validation loss: 0.275, accuracy: 0.811\n",
      "Epoch [8] (took 35.404) training loss: 0.261, accuracy: 0.796, validation loss: 0.286, accuracy: 0.728\n",
      "Epoch [9] (took 35.857) training loss: 0.234, accuracy: 0.825, validation loss: 0.246, accuracy: 0.844\n",
      "Epoch [10] (took 35.350) training loss: 0.317, accuracy: 0.768, validation loss: 0.252, accuracy: 0.806\n",
      "Epoch [11] (took 35.463) training loss: 0.297, accuracy: 0.782, validation loss: 0.297, accuracy: 0.783\n",
      "Epoch [12] (took 34.930) training loss: 0.264, accuracy: 0.793, validation loss: 0.273, accuracy: 0.728\n",
      "Epoch [13] (took 35.546) training loss: 0.255, accuracy: 0.783, validation loss: 0.252, accuracy: 0.839\n",
      "Epoch [14] (took 35.366) training loss: 0.296, accuracy: 0.760, validation loss: 0.338, accuracy: 0.750\n",
      "Epoch [15] (took 35.302) training loss: 0.291, accuracy: 0.778, validation loss: 0.278, accuracy: 0.744\n",
      "Epoch [16] (took 36.609) training loss: 0.263, accuracy: 0.779, validation loss: 0.247, accuracy: 0.783\n",
      "Epoch [17] (took 35.508) training loss: 0.265, accuracy: 0.785, validation loss: 0.296, accuracy: 0.733\n",
      "Epoch [18] (took 36.048) training loss: 0.295, accuracy: 0.803, validation loss: 0.235, accuracy: 0.811\n",
      "Epoch [19] (took 35.387) training loss: 0.264, accuracy: 0.815, validation loss: 0.343, accuracy: 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-827d7d628bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbnn_pynq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnv_manual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHT_BIT_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACT_BIT_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIN_BIT_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIN_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#bo.export_finn_onnx(bnn_pynq_model, INPUT_SPECIFICATIONS, build_dir + file_name + \".onnx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d8c690cbae83>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# compute gradient and do SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "# to do: put up accuracy / loss\n",
    "\n",
    "if train_network:\n",
    "    train_model()\n",
    "    #bo.export_finn_onnx(bnn_pynq_model, INPUT_SPECIFICATIONS, build_dir + file_name + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bnn_pynq_model.state_dict(), build_dir + model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46654114 0.46654114 0.06691772] prediction 0 target 0.0\n",
      "[0.23009177 0.29330513 0.4766031 ] prediction 2 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.44826663 0.27586667 0.27586669] prediction 0 target 0.0\n",
      "[0.32177992 0.52287298 0.1553471 ] prediction 1 target 0.0\n",
      "[0.25396622 0.67057966 0.07545412] prediction 1 target 0.0\n",
      "[0.42039302 0.15921396 0.42039303] prediction 2 target 0.0\n",
      "[0.96414181 0.03223148 0.00362671] prediction 0 target 0.0\n",
      "[0.0107673  0.32208286 0.66714984] prediction 2 target 2.0\n",
      "[0.08093834 0.91693903 0.00212263] prediction 1 target 1.0\n",
      "[0.08053391 0.00710874 0.91235735] prediction 2 target 2.0\n",
      "[0.58280307 0.28136237 0.13583455] prediction 0 target 0.0\n",
      "[0.23009178 0.47660309 0.29330513] prediction 1 target 0.0\n",
      "[0.02393976 0.912849   0.06321124] prediction 1 target 1.0\n",
      "[0.87815893 0.02303    0.09881107] prediction 0 target 0.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.29330513 0.23009176 0.47660311] prediction 2 target 2.0\n",
      "[0.36122297 0.58696548 0.05181154] prediction 1 target 2.0\n",
      "[0.80979068 0.18873874 0.00147058] prediction 0 target 0.0\n",
      "[0.00733595 0.05114528 0.94151876] prediction 2 target 2.0\n",
      "[0.38926284 0.30536858 0.30536858] prediction 0 target 2.0\n",
      "[0.37686678 0.48040381 0.14272941] prediction 1 target 2.0\n",
      "[0.9148585  0.08075473 0.00438677] prediction 0 target 0.0\n",
      "[0.01709573 0.1519341  0.83097017] prediction 2 target 2.0\n",
      "[0.20624466 0.69418571 0.09956964] prediction 1 target 0.0\n",
      "[0.52287294 0.32177994 0.15534711] prediction 0 target 0.0\n",
      "[0.21076758 0.70940918 0.07982324] prediction 1 target 0.0\n",
      "[0.49565059 0.38882759 0.11552182] prediction 0 target 0.0\n",
      "[0.01199773 0.94761987 0.0403824 ] prediction 1 target 1.0\n",
      "[0.90832209 0.01150018 0.08017772] prediction 0 target 0.0\n",
      "[0.05027277 0.0242704  0.92545682] prediction 2 target 2.0\n",
      "[0.27348049 0.72210574 0.00441377] prediction 1 target 1.0\n",
      "[0.02644284 0.48677858 0.48677858] prediction 1 target 2.0\n",
      "[0.95007655 0.04048708 0.00943637] prediction 0 target 0.0\n",
      "[0.98548651 0.00978807 0.00472543] prediction 0 target 0.0\n",
      "[0.00611086 0.61525601 0.37863313] prediction 1 target 2.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.05931509 0.52714817 0.41353674] prediction 1 target 2.0\n",
      "[0.81602415 0.14920133 0.03477452] prediction 0 target 2.0\n",
      "[0.96867529 0.00592089 0.02540382] prediction 0 target 0.0\n",
      "[0.00568402 0.92992248 0.0643935 ] prediction 1 target 1.0\n",
      "[0.94418264 0.00452737 0.05128998] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 2.0\n",
      "[0.00522729 0.32388658 0.67088613] prediction 2 target 2.0\n",
      "[0.98188022 0.01584682 0.00227297] prediction 0 target 0.0\n",
      "[0.00475434 0.99151598 0.00372968] prediction 1 target 1.0\n",
      "[0.84201003 0.00403745 0.15395252] prediction 0 target 0.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.09521399 0.84619061 0.0585954 ] prediction 1 target 1.0\n",
      "[0.62684331 0.07053287 0.30262382] prediction 0 target 1.0\n",
      "[0.18709565 0.01016343 0.80274091] prediction 2 target 2.0\n",
      "[0.0513401 0.9451048 0.0035551] prediction 1 target 1.0\n",
      "[0.42039302 0.42039303 0.15921395] prediction 1 target 0.0\n",
      "[0.35913359 0.35913359 0.28173281] prediction 0 target 0.0\n",
      "[0.0072343  0.0642931  0.92847259] prediction 2 target 2.0\n",
      "[0.89699323 0.10093031 0.00207646] prediction 0 target 0.0\n",
      "[0.09969409 0.01429949 0.88600642] prediction 2 target 2.0\n",
      "[0.1249173  0.87090668 0.00417601] prediction 1 target 1.0\n",
      "[0.30536858 0.38926283 0.30536858] prediction 1 target 1.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 1.0\n",
      "[0.90688444 0.03031736 0.0627982 ] prediction 0 target 0.0\n",
      "[0.01913974 0.93032313 0.05053713] prediction 1 target 1.0\n",
      "[0.21744292 0.73187743 0.05067965] prediction 1 target 2.0\n",
      "[0.77708084 0.11145957 0.11145959] prediction 0 target 2.0\n",
      "[0.26645705 0.70356101 0.02998194] prediction 1 target 1.0\n",
      "[0.33292652 0.12608805 0.54098543] prediction 2 target 2.0\n",
      "[0.77708084 0.11145957 0.11145959] prediction 0 target 2.0\n",
      "[0.21744292 0.73187743 0.05067965] prediction 1 target 2.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.00267987 0.43843432 0.55888581] prediction 2 target 2.0\n",
      "[0.9925194  0.00606664 0.00141396] prediction 0 target 0.0\n",
      "[0.91375731 0.00558522 0.08065748] prediction 0 target 0.0\n",
      "[0.00595349 0.97400803 0.02003848] prediction 1 target 1.0\n",
      "[0.94418264 0.00452737 0.05128998] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.00582836 0.04063456 0.95353708] prediction 2 target 2.0\n",
      "[0.87317208 0.12524224 0.00158568] prediction 0 target 0.0\n",
      "[0.25643191 0.41668634 0.32688175] prediction 1 target 0.0\n",
      "[0.42662528 0.54383258 0.02954213] prediction 1 target 0.0\n",
      "[0.34600416 0.44106227 0.21293357] prediction 1 target 0.0\n",
      "[0.52287293 0.32177995 0.15534712] prediction 0 target 0.0\n",
      "[0.93106307 0.06447247 0.00446447] prediction 0 target 0.0\n",
      "[0.01644031 0.49177992 0.49177977] prediction 1 target 2.0\n",
      "[0.91932691 0.03073331 0.04993977] prediction 0 target 0.0\n",
      "[0.05710172 0.82461999 0.11827829] prediction 1 target 1.0\n",
      "[0.0079905 0.1875064 0.8045031] prediction 2 target 2.0\n",
      "[0.89583075 0.1007995  0.00336975] prediction 0 target 0.0\n",
      "[0.96867528 0.0059209  0.02540382] prediction 0 target 0.0\n",
      "[0.00568402 0.92992248 0.0643935 ] prediction 1 target 1.0\n",
      "[0.00884867 0.89090593 0.1002454 ] prediction 1 target 1.0\n",
      "[0.98420877 0.00601584 0.00977538] prediction 0 target 0.0\n",
      "[0.12528506 0.87347058 0.00124436] prediction 1 target 1.0\n",
      "[0.05128998 0.00452737 0.94418265] prediction 2 target 2.0\n",
      "[0.06447248 0.00446447 0.93106306] prediction 2 target 2.0\n",
      "[0.06467543 0.93399399 0.00133058] prediction 1 target 1.0\n",
      "[0.12369524 0.86238648 0.01391828] prediction 1 target 1.0\n",
      "[0.26428021 0.03790668 0.69781311] prediction 2 target 1.0\n",
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.56900536 0.21549732 0.21549732] prediction 0 target 2.0\n",
      "[0.34989375 0.56855614 0.08155011] prediction 1 target 2.0\n",
      "[0.05027277 0.0242704  0.92545682] prediction 2 target 2.0\n",
      "[0.27348049 0.72210574 0.00441377] prediction 1 target 1.0\n",
      "[0.27394546 0.72333365 0.00272089] prediction 1 target 1.0\n",
      "[0.07805408 0.0376825  0.88426342] prediction 2 target 2.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.95353708 0.00582836 0.04063456] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.95843971 0.03204086 0.00951943] prediction 0 target 0.0\n",
      "[0.01644032 0.49177984 0.49177984] prediction 1 target 2.0\n",
      "[0.01139757 0.43460188 0.55400055] prediction 2 target 2.0\n",
      "[0.9686753  0.02540381 0.00592089] prediction 0 target 0.0\n",
      "[0.01199773 0.04038241 0.94761986] prediction 2 target 2.0\n",
      "[0.76871961 0.22838878 0.00289161] prediction 0 target 0.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.9148585  0.08075473 0.00438677] prediction 0 target 0.0\n",
      "[0.01709573 0.1519341  0.83097017] prediction 2 target 2.0\n",
      "[0.00933256 0.93962503 0.05104241] prediction 1 target 1.0\n",
      "[0.93962504 0.00933256 0.0510424 ] prediction 0 target 0.0\n",
      "[0.46654112 0.46654117 0.06691771] prediction 1 target 1.0\n",
      "[0.24561813 0.24561807 0.5087638 ] prediction 2 target 1.0\n",
      "[0.18856541 0.00238741 0.80904718] prediction 2 target 2.0\n",
      "[2.01449228e-02 9.79181628e-01 6.73449651e-04] prediction 1 target 1.0\n",
      "[0.93417663 0.01507692 0.05074645] prediction 0 target 0.0\n",
      "[0.01461347 0.90546132 0.07992521] prediction 1 target 1.0\n",
      "[0.00493257 0.1880844  0.80698303] prediction 2 target 2.0\n",
      "[0.95745953 0.04080172 0.00173875] prediction 0 target 0.0\n",
      "[0.56183645 0.27124025 0.1669233 ] prediction 0 target 1.0\n",
      "[0.28984773 0.60037928 0.10977299] prediction 1 target 1.0\n",
      "[0.30262388 0.62684326 0.07053286] prediction 1 target 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36264659 0.17507648 0.46227693] prediction 2 target 0.0\n",
      "[0.95007654 0.00943637 0.04048709] prediction 0 target 0.0\n",
      "[0.0092035  0.92663093 0.06416557] prediction 1 target 1.0\n",
      "[0.95593965 0.03195728 0.01210307] prediction 0 target 0.0\n",
      "[0.01838938 0.55008241 0.4315282 ] prediction 1 target 2.0\n",
      "[0.09969409 0.01429949 0.88600642] prediction 2 target 2.0\n",
      "[0.1249173  0.87090668 0.00417601] prediction 1 target 1.0\n",
      "[0.97272354 0.02550999 0.00176647] prediction 0 target 0.0\n",
      "[0.00493257 0.18808438 0.80698305] prediction 2 target 2.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.08017775 0.01150018 0.90832207] prediction 2 target 2.0\n",
      "[0.12502984 0.87169122 0.00327895] prediction 1 target 1.0\n",
      "[0.00372968 0.99151598 0.00475434] prediction 1 target 1.0\n",
      "[0.80851683 0.00304131 0.18844186] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.94418264 0.00452737 0.05128998] prediction 0 target 0.0\n",
      "[0.01644031 0.49177987 0.49177981] prediction 1 target 2.0\n",
      "[0.95843971 0.03204085 0.00951943] prediction 0 target 0.0\n",
      "[0.08093834 0.91693902 0.00212263] prediction 1 target 1.0\n",
      "[0.15249594 0.01346084 0.83404323] prediction 2 target 2.0\n",
      "[0.21744295 0.73187738 0.05067966] prediction 1 target 1.0\n",
      "[0.46227692 0.3626466  0.17507648] prediction 0 target 1.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.28173282 0.35913359 0.3591336 ] prediction 2 target 0.0\n",
      "[0.53945427 0.42319063 0.0373551 ] prediction 0 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.20624465 0.69418571 0.09956964] prediction 1 target 1.0\n",
      "[0.67570197 0.12354494 0.20075309] prediction 0 target 1.0\n",
      "[0.42039302 0.42039303 0.15921395] prediction 1 target 0.0\n",
      "[0.3591336  0.35913359 0.28173282] prediction 0 target 0.0\n",
      "[0.44106228 0.34600415 0.21293356] prediction 0 target 0.0\n",
      "[0.38882757 0.49565059 0.11552184] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.79620726 0.08958982 0.11420293] prediction 0 target 0.0\n",
      "[0.08362175 0.7431674  0.17321085] prediction 1 target 1.0\n",
      "[0.93417663 0.01507692 0.05074645] prediction 0 target 0.0\n",
      "[0.01461347 0.90546132 0.07992521] prediction 1 target 1.0\n",
      "[0.94151877 0.00733595 0.05114527] prediction 0 target 0.0\n",
      "[0.00741772 0.95201268 0.0405696 ] prediction 1 target 1.0\n",
      "[0.47660308 0.29330514 0.23009178] prediction 0 target 0.0\n",
      "[0.30860893 0.50147082 0.18992025] prediction 1 target 0.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.02980318 0.07869317 0.89150365] prediction 2 target 2.0\n",
      "[0.72011941 0.27272821 0.00715238] prediction 0 target 0.0\n",
      "[0.89699325 0.10093029 0.00207646] prediction 0 target 0.0\n",
      "[0.0072343  0.06429309 0.92847261] prediction 2 target 2.0\n",
      "[0.40277523 0.19444956 0.40277521] prediction 0 target 2.0\n",
      "[0.29687122 0.61492745 0.08820133] prediction 1 target 2.0\n",
      "[0.42662528 0.54383258 0.02954213] prediction 1 target 0.0\n",
      "[0.25643191 0.41668634 0.32688175] prediction 1 target 0.0\n",
      "[0.10167646 0.34222638 0.55609716] prediction 2 target 2.0\n",
      "[0.73995969 0.21984415 0.04019617] prediction 0 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.15896896 0.15896896 0.68206208] prediction 2 target 2.0\n",
      "[0.48326779 0.48326779 0.03346442] prediction 0 target 2.0\n",
      "[0.16460862 0.70625934 0.12913203] prediction 1 target 0.0\n",
      "[0.62042533 0.14460321 0.23497146] prediction 0 target 0.0\n",
      "[0.5339743 0.4188917 0.047134 ] prediction 0 target 0.0\n",
      "[0.2034522  0.25934684 0.53720096] prediction 2 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.65696113 0.09423036 0.24880851] prediction 0 target 1.0\n",
      "[0.11420295 0.79620722 0.08958983] prediction 1 target 1.0\n",
      "[0.69062085 0.26155635 0.0478228 ] prediction 0 target 0.0\n",
      "[0.2034522  0.25934685 0.53720095] prediction 2 target 0.0\n",
      "[0.15122381 0.02169058 0.82708561] prediction 2 target 2.0\n",
      "[0.10070629 0.89500215 0.00429155] prediction 1 target 1.0\n",
      "[0.04081702 0.95781845 0.00136452] prediction 1 target 1.0\n",
      "[0.10070629 0.00429155 0.89500215] prediction 2 target 2.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.28984773 0.60037927 0.109773  ] prediction 1 target 0.0\n",
      "[0.41668634 0.25643192 0.32688174] prediction 0 target 0.0\n",
      "[0.06447247 0.00446447 0.93106306] prediction 2 target 2.0\n",
      "[0.06467542 0.933994   0.00133058] prediction 1 target 1.0\n",
      "[0.00611086 0.37863317 0.61525597] prediction 2 target 2.0\n",
      "[0.98126746 0.01583693 0.00289561] prediction 0 target 0.0\n",
      "[0.55609713 0.34222639 0.10167648] prediction 0 target 0.0\n",
      "[0.23009177 0.4766031  0.29330513] prediction 1 target 0.0\n",
      "[0.60037928 0.28984773 0.10977299] prediction 0 target 2.0\n",
      "[0.33333333 0.33333334 0.33333334] prediction 1 target 2.0\n",
      "[0.97400804 0.02003847 0.00595349] prediction 0 target 0.0\n",
      "[0.01018187 0.49490909 0.49490904] prediction 1 target 2.0\n",
      "[0.08037695 0.00904407 0.91057899] prediction 2 target 2.0\n",
      "[0.10087274 0.89648184 0.00264542] prediction 1 target 1.0\n",
      "[0.13785954 0.10814795 0.75399251] prediction 2 target 2.0\n",
      "[0.3199301  0.66269063 0.01737928] prediction 1 target 1.0\n",
      "[0.95007654 0.00943637 0.04048709] prediction 0 target 0.0\n",
      "[0.0092035  0.92663093 0.06416557] prediction 1 target 1.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01095145 0.86498114 0.12406741] prediction 1 target 1.0\n",
      "[0.96256931 0.012187   0.02524369] prediction 0 target 0.0\n",
      "[0.54098542 0.12608807 0.33292651] prediction 0 target 0.0\n",
      "[0.17321085 0.74316741 0.08362174] prediction 1 target 0.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.36856716 0.03253348 0.59889936] prediction 2 target 2.0\n",
      "[0.07992519 0.90546134 0.01461347] prediction 1 target 1.0\n",
      "[0.95353708 0.00582836 0.04063456] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.00967985 0.97459097 0.01572917] prediction 1 target 1.0\n",
      "[0.89260822 0.00695486 0.10043692] prediction 0 target 0.0\n",
      "[0.00350565 0.06453456 0.93195979] prediction 2 target 2.0\n",
      "[0.94747243 0.0514687  0.00105888] prediction 0 target 0.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.80979072 0.1887387  0.00147058] prediction 0 target 0.0\n",
      "[0.00943637 0.0404871  0.95007653] prediction 2 target 2.0\n",
      "[0.83989082 0.00654411 0.15356507] prediction 0 target 0.0\n",
      "[0.00763545 0.97995739 0.01240715] prediction 1 target 1.0\n",
      "[0.76957545 0.22864305 0.0017815 ] prediction 0 target 0.0\n",
      "[0.00933256 0.05104242 0.93962501] prediction 2 target 2.0\n",
      "[0.15122385 0.02169059 0.82708557] prediction 2 target 2.0\n",
      "[0.12459214 0.86863975 0.00676811] prediction 1 target 1.0\n",
      "[0.12459214 0.86863975 0.00676811] prediction 1 target 1.0\n",
      "[0.15122385 0.02169059 0.82708557] prediction 2 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.10043692 0.00695486 0.89260822] prediction 2 target 2.0\n",
      "[0.06462167 0.93321801 0.00216032] prediction 1 target 1.0\n",
      "[0.14384235 0.06944339 0.78671426] prediction 2 target 0.0\n",
      "[0.31993002 0.66269071 0.01737927] prediction 1 target 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38926285 0.30536858 0.30536858] prediction 0 target 0.0\n",
      "[0.50830609 0.39875551 0.0929384 ] prediction 0 target 0.0\n",
      "[0.18709563 0.80274094 0.01016343] prediction 1 target 1.0\n",
      "[0.18402751 0.02639574 0.78957676] prediction 2 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.00846637 0.322832   0.66870163] prediction 2 target 2.0\n",
      "[0.95567928 0.04072584 0.00359488] prediction 0 target 0.0\n",
      "[0.5967195  0.17728711 0.22599339] prediction 0 target 2.0\n",
      "[0.47336814 0.47336814 0.05326372] prediction 0 target 2.0\n",
      "[0.08089114 0.00270421 0.91640465] prediction 2 target 2.0\n",
      "[3.23214038e-02 9.66830957e-01 8.47639459e-04] prediction 1 target 1.0\n",
      "[0.34989375 0.56855615 0.0815501 ] prediction 1 target 2.0\n",
      "[0.34600416 0.21293357 0.44106227] prediction 2 target 2.0\n",
      "[0.21744295 0.73187738 0.05067966] prediction 1 target 1.0\n",
      "[0.46227692 0.3626466  0.17507648] prediction 0 target 1.0\n",
      "[0.76810939 0.22820751 0.0036831 ] prediction 0 target 0.0\n",
      "[0.01391828 0.12369526 0.86238646] prediction 2 target 2.0\n",
      "[0.94370288 0.03154821 0.02474891] prediction 0 target 0.0\n",
      "[0.02367318 0.70813673 0.26819009] prediction 1 target 1.0\n",
      "[0.01018187 0.49490909 0.49490904] prediction 1 target 2.0\n",
      "[0.97400804 0.02003847 0.00595349] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.94418264 0.00452737 0.05128998] prediction 0 target 0.0\n",
      "[0.00627919 0.18782983 0.80589097] prediction 2 target 2.0\n",
      "[0.96548847 0.03227651 0.00223502] prediction 0 target 0.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.1249173  0.87090668 0.00417601] prediction 1 target 1.0\n",
      "[0.09969409 0.01429949 0.88600642] prediction 2 target 2.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.30536858 0.38926283 0.30536858] prediction 1 target 1.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 1.0\n",
      "[0.00597931 0.97823274 0.01578795] prediction 1 target 1.0\n",
      "[0.89394819 0.00546413 0.10058767] prediction 0 target 0.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.11145956 0.11145957 0.77708087] prediction 2 target 2.0\n",
      "[0.55536478 0.43567205 0.00896318] prediction 0 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.0079905 0.1875064 0.8045031] prediction 2 target 2.0\n",
      "[0.89583075 0.1007995  0.00336975] prediction 0 target 0.0\n",
      "[0.00403745 0.15395258 0.84200997] prediction 2 target 2.0\n",
      "[0.97309402 0.02551969 0.00138628] prediction 0 target 0.0\n",
      "[0.08093834 0.91693902 0.00212263] prediction 1 target 1.0\n",
      "[0.15249594 0.01346084 0.83404323] prediction 2 target 2.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.15249592 0.01346084 0.83404324] prediction 2 target 2.0\n",
      "[0.15408666 0.84274328 0.00317006] prediction 1 target 1.0\n",
      "[0.00933256 0.05104243 0.93962501] prediction 2 target 2.0\n",
      "[0.84331945 0.154192   0.00248854] prediction 0 target 0.0\n",
      "[0.0079905 0.1875064 0.8045031] prediction 2 target 2.0\n",
      "[0.89583075 0.1007995  0.00336975] prediction 0 target 0.0\n",
      "[0.01125233 0.10000227 0.8887454 ] prediction 2 target 2.0\n",
      "[0.93321801 0.06462168 0.00216032] prediction 0 target 0.0\n",
      "[0.25643191 0.41668634 0.32688175] prediction 1 target 0.0\n",
      "[0.42662528 0.54383258 0.02954213] prediction 1 target 0.0\n",
      "[0.61422487 0.37799849 0.00777664] prediction 0 target 2.0\n",
      "[0.06082264 0.06082264 0.87835472] prediction 2 target 2.0\n",
      "[0.86498116 0.12406739 0.01095145] prediction 0 target 0.0\n",
      "[0.03180862 0.22176539 0.74642598] prediction 2 target 2.0\n",
      "[0.08053391 0.00710874 0.91235735] prediction 2 target 2.0\n",
      "[0.08093834 0.91693903 0.00212263] prediction 1 target 1.0\n",
      "[0.01139757 0.43460188 0.55400055] prediction 2 target 2.0\n",
      "[0.9686753  0.02540381 0.00592089] prediction 0 target 0.0\n",
      "[0.91485856 0.08075468 0.00438676] prediction 0 target 0.0\n",
      "[0.01866635 0.26956542 0.71176823] prediction 2 target 2.0\n",
      "[0.32688175 0.25643192 0.41668633] prediction 2 target 2.0\n",
      "[0.39875553 0.50830608 0.09293839] prediction 1 target 2.0\n",
      "[0.15419196 0.8433195  0.00248854] prediction 1 target 1.0\n",
      "[0.10000227 0.01125233 0.88874541] prediction 2 target 2.0\n",
      "[0.46227692 0.3626466  0.17507648] prediction 0 target 1.0\n",
      "[0.21744295 0.73187738 0.05067966] prediction 1 target 1.0\n",
      "[0.00568402 0.0643935  0.92992248] prediction 2 target 2.0\n",
      "[0.91735869 0.08097538 0.00166592] prediction 0 target 0.0\n",
      "[0.10043691 0.89260822 0.00695486] prediction 1 target 1.0\n",
      "[0.18270258 0.03340523 0.78389219] prediction 2 target 2.0\n",
      "[0.9752594  0.02006422 0.00467639] prediction 0 target 0.0\n",
      "[0.00896317 0.43567209 0.55536474] prediction 2 target 2.0\n",
      "[0.10000227 0.01125233 0.88874541] prediction 2 target 2.0\n",
      "[0.15419196 0.8433195  0.00248854] prediction 1 target 1.0\n",
      "[0.06447248 0.93106306 0.00446447] prediction 1 target 1.0\n",
      "[0.26956541 0.01866635 0.71176824] prediction 2 target 2.0\n",
      "[0.06467543 0.93399399 0.00133058] prediction 1 target 1.0\n",
      "[0.06447248 0.00446447 0.93106306] prediction 2 target 2.0\n",
      "[0.10000227 0.01125233 0.88874541] prediction 2 target 2.0\n",
      "[0.15419196 0.8433195  0.00248854] prediction 1 target 1.0\n",
      "[0.00350565 0.06453456 0.93195979] prediction 2 target 2.0\n",
      "[0.94747243 0.0514687  0.00105888] prediction 0 target 0.0\n",
      "[0.94761987 0.01199773 0.0403824 ] prediction 0 target 0.0\n",
      "[0.01887764 0.9175833  0.06353906] prediction 1 target 1.0\n",
      "[0.80851683 0.00304131 0.18844186] prediction 0 target 0.0\n",
      "[0.00372968 0.99151598 0.00475434] prediction 1 target 1.0\n",
      "[0.22683702 0.76349642 0.00966656] prediction 1 target 1.0\n",
      "[0.12093411 0.03592988 0.84313601] prediction 2 target 2.0\n",
      "[0.15896896 0.15896896 0.68206208] prediction 2 target 2.0\n",
      "[0.48326779 0.48326779 0.03346442] prediction 0 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.0310677  0.92932933 0.03960297] prediction 1 target 1.0\n",
      "[0.84313602 0.03592988 0.1209341 ] prediction 0 target 0.0\n",
      "[0.11420295 0.79620722 0.08958983] prediction 1 target 1.0\n",
      "[0.65696113 0.09423036 0.24880851] prediction 0 target 1.0\n",
      "[0.09521399 0.84619061 0.0585954 ] prediction 1 target 1.0\n",
      "[0.62684331 0.07053287 0.30262382] prediction 0 target 1.0\n",
      "[0.08093834 0.91693903 0.00212263] prediction 1 target 1.0\n",
      "[0.08053391 0.00710874 0.91235735] prediction 2 target 2.0\n",
      "[0.65696113 0.09423036 0.24880851] prediction 0 target 1.0\n",
      "[0.11420295 0.79620722 0.08958983] prediction 1 target 1.0\n",
      "[0.18992027 0.3086089  0.50147084] prediction 2 target 2.0\n",
      "[0.57872769 0.35615344 0.06511887] prediction 0 target 2.0\n",
      "[0.17321085 0.74316741 0.08362174] prediction 1 target 0.0\n",
      "[0.54098542 0.12608807 0.33292651] prediction 0 target 0.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.93426189 0.064694   0.00104411] prediction 0 target 0.0\n",
      "[0.0035551  0.05134009 0.94510481] prediction 2 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.96867528 0.0059209  0.02540382] prediction 0 target 0.0\n",
      "[0.00461848 0.96318212 0.0321994 ] prediction 1 target 1.0\n",
      "[0.93106306 0.00446447 0.06447247] prediction 0 target 0.0\n",
      "[0.00467639 0.97525939 0.02006422] prediction 1 target 1.0\n",
      "[0.52287294 0.32177994 0.15534711] prediction 0 target 0.0\n",
      "[0.20624466 0.69418571 0.09956964] prediction 1 target 0.0\n",
      "[0.00753529 0.96710214 0.02536257] prediction 1 target 1.0\n",
      "[0.97525939 0.00467639 0.02006422] prediction 0 target 0.0\n",
      "[0.46227692 0.3626466  0.17507648] prediction 0 target 1.0\n",
      "[0.21744295 0.73187738 0.05067966] prediction 1 target 1.0\n",
      "[0.97272353 0.02551    0.00176647] prediction 0 target 0.0\n",
      "[0.00493257 0.18808436 0.80698306] prediction 2 target 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00494157 0.49752921 0.49752921] prediction 1 target 2.0\n",
      "[0.97762402 0.02011287 0.00226311] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.15356508 0.83989081 0.00654411] prediction 1 target 1.0\n",
      "[0.12262864 0.02242134 0.85495002] prediction 2 target 2.0\n",
      "[0.01561326 0.22547494 0.75891181] prediction 2 target 2.0\n",
      "[0.9299225  0.06439348 0.00568402] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.80851683 0.00304131 0.18844186] prediction 0 target 0.0\n",
      "[0.00372968 0.99151598 0.00475434] prediction 1 target 1.0\n",
      "[0.00350565 0.06453456 0.93195979] prediction 2 target 2.0\n",
      "[0.94747243 0.0514687  0.00105888] prediction 0 target 0.0\n",
      "[0.67570197 0.12354494 0.20075309] prediction 0 target 1.0\n",
      "[0.20624465 0.69418571 0.09956964] prediction 1 target 1.0\n",
      "[0.00568402 0.92992248 0.0643935 ] prediction 1 target 1.0\n",
      "[0.96867529 0.00592089 0.02540382] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.3653021  0.59359385 0.04110406] prediction 1 target 1.0\n",
      "[0.23497148 0.1446032  0.62042533] prediction 2 target 2.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.37686678 0.14272941 0.48040381] prediction 2 target 1.0\n",
      "[0.17638978 0.75680675 0.06680346] prediction 1 target 1.0\n",
      "[0.00753529 0.96710214 0.02536257] prediction 1 target 1.0\n",
      "[0.97525939 0.00467639 0.02006422] prediction 0 target 0.0\n",
      "[0.39875553 0.5083061  0.09293837] prediction 1 target 0.0\n",
      "[0.32688176 0.25643191 0.41668634] prediction 2 target 0.0\n",
      "[0.84331951 0.15419194 0.00248854] prediction 0 target 0.0\n",
      "[0.01461347 0.07992522 0.90546131] prediction 2 target 2.0\n",
      "[0.30536858 0.38926283 0.30536858] prediction 1 target 1.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 1.0\n",
      "[0.18856541 0.00238741 0.80904718] prediction 2 target 2.0\n",
      "[2.01449228e-02 9.79181628e-01 6.73449651e-04] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.28984773 0.60037928 0.10977299] prediction 1 target 1.0\n",
      "[0.56183645 0.27124025 0.1669233 ] prediction 0 target 1.0\n",
      "[0.04072585 0.00359488 0.95567927] prediction 2 target 2.0\n",
      "[6.47199984e-02 9.34637188e-01 6.42813570e-04] prediction 1 target 1.0\n",
      "[0.90688444 0.03031736 0.0627982 ] prediction 0 target 0.0\n",
      "[0.01913974 0.93032313 0.05053713] prediction 1 target 1.0\n",
      "[0.0092035  0.92663093 0.06416557] prediction 1 target 1.0\n",
      "[0.95007654 0.00943637 0.04048709] prediction 0 target 0.0\n",
      "[0.2564319  0.41668632 0.32688178] prediction 1 target 0.0\n",
      "[0.54098544 0.33292651 0.12608805] prediction 0 target 0.0\n",
      "[0.01448349 0.43324527 0.55227124] prediction 2 target 2.0\n",
      "[0.96318212 0.0321994  0.00461848] prediction 0 target 0.0\n",
      "[0.00457798 0.95473635 0.04068567] prediction 1 target 1.0\n",
      "[0.96318213 0.00461848 0.03219939] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.83097024 0.01709573 0.15193403] prediction 0 target 0.0\n",
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.00475434 0.99151598 0.00372968] prediction 1 target 1.0\n",
      "[0.84201003 0.00403745 0.15395252] prediction 0 target 0.0\n",
      "[0.0809754  0.91735868 0.00166592] prediction 1 target 1.0\n",
      "[0.18402752 0.02639574 0.78957674] prediction 2 target 2.0\n",
      "[0.89583078 0.10079947 0.00336975] prediction 0 target 0.0\n",
      "[0.01125233 0.10000229 0.88874539] prediction 2 target 2.0\n",
      "[0.9083221  0.01150018 0.08017772] prediction 0 target 0.0\n",
      "[0.01199773 0.94761986 0.04038241] prediction 1 target 1.0\n",
      "[0.34600416 0.21293357 0.44106227] prediction 2 target 2.0\n",
      "[0.34989375 0.56855615 0.0815501 ] prediction 1 target 2.0\n",
      "[0.0035551  0.05134008 0.94510482] prediction 2 target 2.0\n",
      "[0.93426191 0.06469397 0.00104411] prediction 0 target 0.0\n",
      "[0.89090597 0.00884867 0.10024536] prediction 0 target 0.0\n",
      "[0.00467639 0.97525939 0.02006422] prediction 1 target 1.0\n",
      "[0.01524363 0.94450663 0.04024974] prediction 1 target 1.0\n",
      "[0.94761988 0.01199773 0.04038239] prediction 0 target 0.0\n",
      "[0.012187   0.96256931 0.02524369] prediction 1 target 1.0\n",
      "[0.93722205 0.01186608 0.05091187] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.16460862 0.70625934 0.12913203] prediction 1 target 0.0\n",
      "[0.62042533 0.14460321 0.23497146] prediction 0 target 0.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.92429386 0.0117024  0.06400374] prediction 0 target 0.0\n",
      "[0.00760952 0.97662842 0.01576206] prediction 1 target 1.0\n",
      "[0.00467639 0.97525939 0.02006422] prediction 1 target 1.0\n",
      "[0.93106306 0.00446447 0.06447247] prediction 0 target 0.0\n",
      "[0.1009755  0.89739483 0.00162967] prediction 1 target 1.0\n",
      "[0.05122627 0.00576402 0.94300971] prediction 2 target 2.0\n",
      "[0.80851683 0.00304131 0.18844186] prediction 0 target 0.0\n",
      "[0.00372968 0.99151598 0.00475434] prediction 1 target 1.0\n",
      "[0.89260822 0.00695486 0.10043692] prediction 0 target 0.0\n",
      "[0.00967985 0.97459097 0.01572917] prediction 1 target 1.0\n",
      "[0.26428021 0.03790668 0.69781311] prediction 2 target 1.0\n",
      "[0.12369524 0.86238648 0.01391828] prediction 1 target 1.0\n",
      "[0.01391828 0.12369526 0.86238646] prediction 2 target 2.0\n",
      "[0.89500218 0.10070627 0.00429155] prediction 0 target 0.0\n",
      "[0.44106228 0.34600415 0.21293356] prediction 0 target 0.0\n",
      "[0.38882757 0.49565059 0.11552184] prediction 1 target 0.0\n",
      "[0.93266448 0.00275219 0.06458333] prediction 0 target 0.0\n",
      "[0.00289561 0.98126746 0.01583693] prediction 1 target 1.0\n",
      "[0.50830612 0.39875549 0.09293839] prediction 0 target 0.0\n",
      "[0.27124024 0.56183647 0.16692329] prediction 1 target 0.0\n",
      "[0.59359382 0.36530212 0.04110406] prediction 0 target 0.0\n",
      "[0.2034522  0.25934685 0.53720095] prediction 2 target 0.0\n",
      "[0.10000227 0.01125233 0.88874541] prediction 2 target 2.0\n",
      "[0.15419196 0.8433195  0.00248854] prediction 1 target 1.0\n",
      "[0.00493257 0.18808436 0.80698306] prediction 2 target 2.0\n",
      "[0.97272353 0.02551    0.00176647] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.07982324 0.70940921 0.21076756] prediction 1 target 1.0\n",
      "[0.81629889 0.09185055 0.09185056] prediction 0 target 0.0\n",
      "[0.01125233 0.10000229 0.88874539] prediction 2 target 2.0\n",
      "[0.89583078 0.10079947 0.00336975] prediction 0 target 0.0\n",
      "[0.05137945 0.00279104 0.94582951] prediction 2 target 2.0\n",
      "[5.14804353e-02 9.47688709e-01 8.30855692e-04] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.06462169 0.93321799 0.00216032] prediction 1 target 1.0\n",
      "[0.10043691 0.00695486 0.89260823] prediction 2 target 2.0\n",
      "[0.96256931 0.012187   0.02524369] prediction 0 target 0.0\n",
      "[0.01095145 0.86498114 0.12406741] prediction 1 target 1.0\n",
      "[0.18709565 0.01016343 0.80274091] prediction 2 target 2.0\n",
      "[0.0513401 0.9451048 0.0035551] prediction 1 target 1.0\n",
      "[0.01199773 0.04038241 0.94761986] prediction 2 target 2.0\n",
      "[0.76871961 0.22838878 0.00289161] prediction 0 target 0.0\n",
      "[0.0376825  0.07805407 0.88426343] prediction 2 target 2.0\n",
      "[0.67088619 0.32388653 0.00522729] prediction 0 target 0.0\n",
      "[0.21076758 0.70940918 0.07982324] prediction 1 target 0.0\n",
      "[0.49565059 0.38882759 0.11552182] prediction 0 target 0.0\n",
      "[0.08093831 0.91693906 0.00212263] prediction 1 target 1.0\n",
      "[0.08053392 0.00710874 0.91235734] prediction 2 target 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02353112 0.89726698 0.0792019 ] prediction 1 target 1.0\n",
      "[0.93032314 0.01913974 0.05053712] prediction 0 target 0.0\n",
      "[0.96196155 0.03215859 0.00587986] prediction 0 target 0.0\n",
      "[0.01597514 0.60914963 0.37487523] prediction 1 target 2.0\n",
      "[0.44781376 0.44781379 0.10437245] prediction 1 target 1.0\n",
      "[0.3823496  0.38234959 0.23530082] prediction 0 target 1.0\n",
      "[0.0092035  0.92663093 0.06416557] prediction 1 target 1.0\n",
      "[0.97241754 0.00757671 0.02000575] prediction 0 target 0.0\n",
      "[0.91375731 0.00558522 0.08065748] prediction 0 target 0.0\n",
      "[0.00595349 0.97400803 0.02003848] prediction 1 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2741062  0.72375807 0.00213573] prediction 1 target 1.0\n",
      "[0.03195729 0.01210307 0.95593965] prediction 2 target 2.0\n",
      "[0.01228963 0.22623624 0.76147413] prediction 2 target 2.0\n",
      "[0.89500221 0.10070624 0.00429155] prediction 0 target 0.0\n",
      "[0.06462169 0.93321799 0.00216032] prediction 1 target 1.0\n",
      "[0.10043691 0.00695486 0.89260823] prediction 2 target 2.0\n",
      "[0.00327895 0.12502986 0.8716912 ] prediction 2 target 2.0\n",
      "[0.97338483 0.02552734 0.00108784] prediction 0 target 0.0\n",
      "[0.18782983 0.80589098 0.00627919] prediction 1 target 1.0\n",
      "[0.09881109 0.02303    0.87815891] prediction 2 target 2.0\n",
      "[0.93266445 0.06458336 0.00275219] prediction 0 target 0.0\n",
      "[0.00861151 0.12436092 0.86702757] prediction 2 target 2.0\n",
      "[0.80904718 0.18856541 0.00238741] prediction 0 target 0.0\n",
      "[0.01186608 0.05091189 0.93722203] prediction 2 target 2.0\n",
      "[0.37686678 0.14272941 0.48040381] prediction 2 target 1.0\n",
      "[0.17638978 0.75680675 0.06680346] prediction 1 target 1.0\n",
      "[0.15408662 0.84274332 0.00317006] prediction 1 target 1.0\n",
      "[0.06400374 0.0117024  0.92429386] prediction 2 target 2.0\n",
      "[0.00568402 0.06439351 0.92992247] prediction 2 target 2.0\n",
      "[0.91735873 0.08097535 0.00166592] prediction 0 target 0.0\n",
      "[0.96867528 0.0059209  0.02540382] prediction 0 target 0.0\n",
      "[0.00568402 0.92992248 0.0643935 ] prediction 1 target 1.0\n",
      "[0.00710874 0.08053391 0.91235735] prediction 2 target 2.0\n",
      "[0.91693904 0.08093833 0.00212263] prediction 0 target 0.0\n",
      "[0.27124022 0.56183651 0.16692326] prediction 1 target 0.0\n",
      "[0.5087638 0.2456181 0.2456181] prediction 0 target 0.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 0.0\n",
      "[0.30536859 0.38926284 0.30536857] prediction 1 target 0.0\n",
      "[0.0092035  0.06416556 0.92663094] prediction 2 target 2.0\n",
      "[0.87230765 0.12511827 0.00257408] prediction 0 target 0.0\n",
      "[0.97200606 0.01230648 0.01568745] prediction 0 target 0.0\n",
      "[0.01016343 0.80274092 0.18709565] prediction 1 target 1.0\n",
      "[0.30262388 0.62684326 0.07053286] prediction 1 target 0.0\n",
      "[0.36264659 0.17507648 0.46227693] prediction 2 target 0.0\n",
      "[0.12262863 0.02242134 0.85495003] prediction 2 target 2.0\n",
      "[0.15356509 0.8398908  0.00654411] prediction 1 target 1.0\n",
      "[0.06467543 0.93399399 0.00133058] prediction 1 target 1.0\n",
      "[0.06447248 0.00446447 0.93106306] prediction 2 target 2.0\n",
      "[0.00289561 0.98126746 0.01583693] prediction 1 target 1.0\n",
      "[0.93266448 0.00275219 0.06458333] prediction 0 target 0.0\n",
      "[0.01186608 0.05091189 0.93722203] prediction 2 target 2.0\n",
      "[0.80904718 0.18856541 0.00238741] prediction 0 target 0.0\n",
      "[0.00704503 0.43651534 0.55643962] prediction 2 target 2.0\n",
      "[0.96489601 0.03225669 0.0028473 ] prediction 0 target 0.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.58280311 0.28136238 0.13583451] prediction 0 target 0.0\n",
      "[0.23009175 0.4766031  0.29330514] prediction 1 target 0.0\n",
      "[0.15122385 0.02169059 0.82708557] prediction 2 target 2.0\n",
      "[0.12459214 0.86863975 0.00676811] prediction 1 target 1.0\n",
      "[0.81602412 0.14920136 0.03477452] prediction 0 target 2.0\n",
      "[0.07439844 0.40690592 0.51869564] prediction 2 target 2.0\n",
      "[0.00943637 0.0404871  0.95007654] prediction 2 target 2.0\n",
      "[0.80904718 0.18856541 0.00238741] prediction 0 target 0.0\n",
      "[0.00763545 0.97995739 0.01240715] prediction 1 target 1.0\n",
      "[0.83989082 0.00654411 0.15356507] prediction 0 target 0.0\n",
      "[0.28173282 0.35913359 0.3591336 ] prediction 2 target 0.0\n",
      "[0.53945427 0.42319063 0.0373551 ] prediction 0 target 0.0\n",
      "[0.18782985 0.80589096 0.00627919] prediction 1 target 1.0\n",
      "[0.22176538 0.03180862 0.746426  ] prediction 2 target 2.0\n",
      "[0.53945427 0.42319063 0.0373551 ] prediction 0 target 0.0\n",
      "[0.28173282 0.35913359 0.3591336 ] prediction 2 target 0.0\n",
      "[0.59359381 0.36530213 0.04110406] prediction 0 target 0.0\n",
      "[0.14272941 0.4804038  0.37686679] prediction 1 target 0.0\n",
      "[0.0092035  0.06416557 0.92663093] prediction 2 target 2.0\n",
      "[0.87230767 0.12511824 0.00257408] prediction 0 target 0.0\n",
      "[0.20075309 0.12354494 0.67570197] prediction 2 target 2.0\n",
      "[0.36856716 0.59889936 0.03253348] prediction 1 target 2.0\n",
      "[0.08093834 0.91693903 0.00212263] prediction 1 target 1.0\n",
      "[0.08053391 0.00710874 0.91235735] prediction 2 target 2.0\n",
      "[0.90688444 0.03031736 0.0627982 ] prediction 0 target 0.0\n",
      "[0.01913974 0.93032313 0.05053713] prediction 1 target 1.0\n",
      "[0.05122628 0.00576402 0.94300971] prediction 2 target 2.0\n",
      "[0.10097548 0.89739485 0.00162967] prediction 1 target 1.0\n",
      "[0.06465179 0.93365269 0.00169551] prediction 1 target 1.0\n",
      "[0.08065747 0.00558521 0.91375732] prediction 2 target 2.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.44106228 0.34600416 0.21293357] prediction 0 target 0.0\n",
      "[0.29687122 0.61492747 0.08820131] prediction 1 target 0.0\n",
      "[0.89394819 0.00546413 0.10058767] prediction 0 target 0.0\n",
      "[0.00597931 0.97823274 0.01578795] prediction 1 target 1.0\n",
      "[0.34600416 0.44106227 0.21293357] prediction 1 target 0.0\n",
      "[0.48040382 0.37686679 0.14272938] prediction 0 target 0.0\n",
      "[0.6204253  0.23497147 0.14460323] prediction 0 target 1.0\n",
      "[0.2034522  0.53720095 0.25934685] prediction 1 target 1.0\n",
      "[0.23009176 0.29330515 0.47660309] prediction 2 target 0.0\n",
      "[0.48677859 0.48677856 0.02644284] prediction 0 target 0.0\n",
      "[0.35913359 0.35913359 0.28173281] prediction 0 target 0.0\n",
      "[0.42039302 0.42039303 0.15921395] prediction 1 target 0.0\n",
      "[0.91284903 0.02393976 0.06321122] prediction 0 target 0.0\n",
      "[0.01815667 0.88253935 0.09930398] prediction 1 target 1.0\n",
      "[0.94450662 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.00933256 0.93962502 0.05104241] prediction 1 target 1.0\n",
      "[0.02393976 0.912849   0.06321124] prediction 1 target 1.0\n",
      "[0.87815893 0.02303    0.09881107] prediction 0 target 0.0\n",
      "[0.15433966 0.84412741 0.00153294] prediction 1 target 1.0\n",
      "[0.0321586  0.00587986 0.96196155] prediction 2 target 2.0\n",
      "[2.01411963e-02 9.79000496e-01 8.58307911e-04] prediction 1 target 1.0\n",
      "[0.15419197 0.00248854 0.84331949] prediction 2 target 2.0\n",
      "[0.23009177 0.4766031  0.29330513] prediction 1 target 0.0\n",
      "[0.55609713 0.34222639 0.10167648] prediction 0 target 0.0\n",
      "[0.08097537 0.9173587  0.00166592] prediction 1 target 1.0\n",
      "[0.06416556 0.0092035  0.92663094] prediction 2 target 2.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.94418264 0.00452737 0.05128998] prediction 0 target 0.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 1.0\n",
      "[0.30536858 0.38926283 0.30536858] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.02332369 0.42935898 0.54731733] prediction 2 target 2.0\n",
      "[0.93722205 0.05091187 0.01186608] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.95353708 0.00582836 0.04063456] prediction 0 target 0.0\n",
      "[0.01257546 0.37617036 0.61125418] prediction 2 target 2.0\n",
      "[0.96196153 0.03215861 0.00587986] prediction 0 target 0.0\n",
      "[0.46227692 0.3626466  0.17507648] prediction 0 target 1.0\n",
      "[0.21744295 0.73187738 0.05067966] prediction 1 target 1.0\n",
      "[0.10070627 0.89500218 0.00429155] prediction 1 target 1.0\n",
      "[0.12369525 0.01391828 0.86238647] prediction 2 target 2.0\n",
      "[0.29687122 0.61492747 0.08820131] prediction 1 target 0.0\n",
      "[0.44106228 0.34600416 0.21293357] prediction 0 target 0.0\n",
      "[0.83989082 0.00654411 0.15356507] prediction 0 target 0.0\n",
      "[0.00763545 0.97995739 0.01240715] prediction 1 target 1.0\n",
      "[0.15356508 0.83989081 0.00654411] prediction 1 target 1.0\n",
      "[0.12262864 0.02242134 0.85495002] prediction 2 target 2.0\n",
      "[0.01461347 0.90546132 0.07992521] prediction 1 target 1.0\n",
      "[0.93417663 0.01507692 0.05074645] prediction 0 target 0.0\n",
      "[0.44106228 0.34600416 0.21293357] prediction 0 target 0.0\n",
      "[0.29687122 0.61492747 0.08820131] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00372968 0.99151598 0.00475434] prediction 1 target 1.0\n",
      "[0.80851683 0.00304131 0.18844186] prediction 0 target 0.0\n",
      "[0.16460862 0.70625934 0.12913203] prediction 1 target 0.0\n",
      "[0.62042533 0.14460321 0.23497146] prediction 0 target 0.0\n",
      "[0.80851685 0.18844184 0.00304131] prediction 0 target 0.0\n",
      "[0.01186608 0.05091188 0.93722204] prediction 2 target 2.0\n",
      "[0.01018187 0.49490909 0.49490904] prediction 1 target 2.0\n",
      "[0.97400804 0.02003847 0.00595349] prediction 0 target 0.0\n",
      "[0.15249593 0.01346084 0.83404323] prediction 2 target 2.0\n",
      "[0.08075471 0.91485852 0.00438677] prediction 1 target 1.0\n",
      "[0.01470251 0.27065425 0.71464324] prediction 2 target 2.0\n",
      "[0.94300971 0.05122627 0.00576402] prediction 0 target 0.0\n",
      "[0.12369524 0.86238648 0.01391828] prediction 1 target 1.0\n",
      "[0.26428021 0.03790668 0.69781311] prediction 2 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.00763545 0.97995739 0.01240715] prediction 1 target 1.0\n",
      "[0.83989082 0.00654411 0.15356507] prediction 0 target 0.0\n",
      "[0.00441377 0.27348052 0.72210571] prediction 2 target 2.0\n",
      "[0.96595378 0.03229205 0.00175417] prediction 0 target 0.0\n",
      "[0.58280304 0.2813624  0.13583455] prediction 0 target 2.0\n",
      "[0.24880851 0.65696113 0.09423036] prediction 1 target 2.0\n",
      "[0.03790668 0.26428027 0.69781305] prediction 2 target 2.0\n",
      "[0.86238647 0.12369525 0.01391828] prediction 0 target 0.0\n",
      "[0.01461347 0.90546132 0.07992521] prediction 1 target 1.0\n",
      "[0.93417663 0.01507692 0.05074645] prediction 0 target 0.0\n",
      "[0.52287294 0.32177994 0.15534711] prediction 0 target 0.0\n",
      "[0.20624466 0.69418571 0.09956964] prediction 1 target 0.0\n",
      "[0.15249592 0.01346084 0.83404324] prediction 2 target 2.0\n",
      "[0.15408666 0.84274328 0.00317006] prediction 1 target 1.0\n",
      "[0.09969409 0.01429949 0.88600642] prediction 2 target 2.0\n",
      "[0.1249173  0.87090668 0.00417601] prediction 1 target 1.0\n",
      "[0.07053286 0.62684328 0.30262386] prediction 1 target 2.0\n",
      "[0.84619063 0.09521397 0.0585954 ] prediction 0 target 2.0\n",
      "[0.15427473 0.84377201 0.00195326] prediction 1 target 1.0\n",
      "[0.04056959 0.00741772 0.95201269] prediction 2 target 2.0\n",
      "[0.36856717 0.03253348 0.59889935] prediction 2 target 2.0\n",
      "[0.08017772 0.9083221  0.01150018] prediction 1 target 1.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.44781378 0.44781377 0.10437245] prediction 0 target 2.0\n",
      "[0.30536858 0.30536858 0.38926284] prediction 2 target 2.0\n",
      "[0.09969409 0.01429949 0.88600642] prediction 2 target 2.0\n",
      "[0.1249173  0.87090668 0.00417601] prediction 1 target 1.0\n",
      "[0.96256931 0.012187   0.02524369] prediction 0 target 0.0\n",
      "[0.01095145 0.86498114 0.12406741] prediction 1 target 1.0\n",
      "[0.52287294 0.32177994 0.15534711] prediction 0 target 0.0\n",
      "[0.20624466 0.69418571 0.09956964] prediction 1 target 0.0\n",
      "[0.08037695 0.00904407 0.91057899] prediction 2 target 2.0\n",
      "[0.10087274 0.89648184 0.00264542] prediction 1 target 1.0\n",
      "[0.01346084 0.83404323 0.15249593] prediction 1 target 1.0\n",
      "[0.95935723 0.01548331 0.02515945] prediction 0 target 0.0\n",
      "[0.00289561 0.98126746 0.01583693] prediction 1 target 1.0\n",
      "[0.93266448 0.00275219 0.06458333] prediction 0 target 0.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.3626466  0.17507649 0.46227691] prediction 2 target 0.0\n",
      "[0.30262383 0.6268433  0.07053287] prediction 1 target 0.0\n",
      "[0.10087277 0.89648181 0.00264542] prediction 1 target 1.0\n",
      "[0.10000226 0.01125233 0.88874542] prediction 2 target 2.0\n",
      "[0.90688444 0.03031736 0.0627982 ] prediction 0 target 0.0\n",
      "[0.01913974 0.93032313 0.05053713] prediction 1 target 1.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.92932935 0.03960296 0.03106769] prediction 0 target 0.0\n",
      "[0.02998194 0.70356093 0.26645713] prediction 1 target 1.0\n",
      "[0.22853126 0.76919891 0.00226982] prediction 1 target 1.0\n",
      "[0.0321994  0.00461848 0.96318213] prediction 2 target 2.0\n",
      "[0.49565062 0.38882756 0.11552182] prediction 0 target 0.0\n",
      "[0.55609717 0.34222637 0.10167647] prediction 0 target 0.0\n",
      "[0.9686753  0.02540381 0.00592089] prediction 0 target 0.0\n",
      "[0.01139757 0.43460188 0.55400055] prediction 2 target 2.0\n",
      "[0.67570197 0.12354494 0.20075309] prediction 0 target 1.0\n",
      "[0.20624465 0.69418571 0.09956964] prediction 1 target 1.0\n",
      "[0.9686753  0.02540381 0.00592089] prediction 0 target 0.0\n",
      "[0.01139757 0.43460188 0.55400055] prediction 2 target 2.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.00967985 0.97459097 0.01572917] prediction 1 target 1.0\n",
      "[0.89260822 0.00695486 0.10043692] prediction 0 target 0.0\n",
      "[0.64038286 0.24252991 0.11708723] prediction 0 target 2.0\n",
      "[0.18992025 0.50147082 0.30860893] prediction 1 target 2.0\n",
      "[0.05122628 0.00576402 0.9430097 ] prediction 2 target 2.0\n",
      "[0.10097557 0.89739476 0.00162967] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 0.0\n",
      "[0.3591336  0.35913359 0.28173282] prediction 0 target 0.0\n",
      "[0.42039302 0.42039303 0.15921395] prediction 1 target 0.0\n",
      "[0.23009178 0.47660309 0.29330513] prediction 1 target 0.0\n",
      "[0.58280307 0.28136237 0.13583455] prediction 0 target 0.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.37686678 0.14272941 0.48040381] prediction 2 target 1.0\n",
      "[0.17638978 0.75680675 0.06680346] prediction 1 target 1.0\n",
      "[0.01709573 0.1519341  0.83097017] prediction 2 target 2.0\n",
      "[0.9148585  0.08075473 0.00438677] prediction 0 target 0.0\n",
      "[0.12369524 0.86238648 0.01391828] prediction 1 target 1.0\n",
      "[0.26428021 0.03790668 0.69781311] prediction 2 target 1.0\n",
      "[0.04080172 0.95745954 0.00173875] prediction 1 target 1.0\n",
      "[0.15378198 0.00514097 0.84107705] prediction 2 target 2.0\n",
      "[0.18104107 0.04219544 0.77676349] prediction 2 target 2.0\n",
      "[0.06447247 0.93106307 0.00446447] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.38053343 0.61834366 0.00112291] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.17728714 0.22599345 0.59671942] prediction 2 target 2.0\n",
      "[0.65057725 0.31408201 0.03534074] prediction 0 target 2.0\n",
      "[0.97525939 0.00467639 0.02006422] prediction 0 target 0.0\n",
      "[0.00753529 0.96710214 0.02536257] prediction 1 target 1.0\n",
      "[0.83097021 0.01709573 0.15193406] prediction 0 target 0.0\n",
      "[0.01951911 0.9487635  0.03171739] prediction 1 target 1.0\n",
      "[0.01815667 0.88253935 0.09930398] prediction 1 target 1.0\n",
      "[0.91284903 0.02393976 0.06321122] prediction 0 target 0.0\n",
      "[0.01644032 0.49177984 0.49177984] prediction 1 target 2.0\n",
      "[0.95843971 0.03204086 0.00951943] prediction 0 target 0.0\n",
      "[0.97762402 0.02011287 0.00226311] prediction 0 target 0.0\n",
      "[0.00494157 0.49752921 0.49752921] prediction 1 target 2.0\n",
      "[0.00933256 0.05104242 0.93962502] prediction 2 target 2.0\n",
      "[0.76957545 0.22864305 0.0017815 ] prediction 0 target 0.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.00933256 0.93962502 0.05104241] prediction 1 target 1.0\n",
      "[0.94450662 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95353708 0.00582836 0.04063456] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.10079949 0.89583076 0.00336975] prediction 1 target 1.0\n",
      "[0.10000227 0.01125233 0.8887454 ] prediction 2 target 2.0\n",
      "[0.01815667 0.88253935 0.09930398] prediction 1 target 1.0\n",
      "[0.91284903 0.02393976 0.06321122] prediction 0 target 0.0\n",
      "[0.12524225 0.00158568 0.87317207] prediction 2 target 2.0\n",
      "[1.24959672e-02 9.86971523e-01 5.32509985e-04] prediction 1 target 1.0\n",
      "[0.02367318 0.70813673 0.26819009] prediction 1 target 1.0\n",
      "[0.94370288 0.03154821 0.02474891] prediction 0 target 0.0\n",
      "[0.48040382 0.37686679 0.14272938] prediction 0 target 0.0\n",
      "[0.34600416 0.44106227 0.21293357] prediction 1 target 0.0\n",
      "[0.29330513 0.23009176 0.47660311] prediction 2 target 2.0\n",
      "[0.36122297 0.58696548 0.05181154] prediction 1 target 2.0\n",
      "[0.01461347 0.90546132 0.07992521] prediction 1 target 1.0\n",
      "[0.93417663 0.01507692 0.05074645] prediction 0 target 0.0\n",
      "[0.96489601 0.03225669 0.0028473 ] prediction 0 target 0.0\n",
      "[0.00715238 0.2727282  0.72011942] prediction 2 target 2.0\n",
      "[0.00741772 0.95201268 0.0405696 ] prediction 1 target 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94151877 0.00733595 0.05114527] prediction 0 target 0.0\n",
      "[0.47660312 0.23009176 0.29330513] prediction 0 target 1.0\n",
      "[0.2813624  0.58280307 0.13583453] prediction 1 target 1.0\n",
      "[0.01507692 0.05074645 0.93417663] prediction 2 target 2.0\n",
      "[8.73888814e-01 1.25345031e-01 7.66154731e-04] prediction 0 target 0.0\n",
      "[0.30536859 0.38926284 0.30536857] prediction 1 target 0.0\n",
      "[0.48040382 0.37686677 0.14272941] prediction 0 target 0.0\n",
      "[0.00465075 0.96991297 0.02543628] prediction 1 target 1.0\n",
      "[0.95353708 0.00582836 0.04063456] prediction 0 target 0.0\n",
      "[0.48677859 0.48677856 0.02644284] prediction 0 target 0.0\n",
      "[0.23009176 0.29330515 0.47660309] prediction 2 target 0.0\n",
      "[0.12511824 0.87230767 0.00257408] prediction 1 target 1.0\n",
      "[0.06416557 0.0092035  0.92663093] prediction 2 target 2.0\n",
      "[0.00769477 0.98756982 0.00473542] prediction 1 target 1.0\n",
      "[0.80589101 0.00627919 0.18782979] prediction 0 target 0.0\n",
      "[0.12369524 0.86238648 0.01391828] prediction 1 target 1.0\n",
      "[0.26428021 0.03790668 0.69781311] prediction 2 target 1.0\n",
      "[0.15356508 0.83989081 0.00654411] prediction 1 target 1.0\n",
      "[0.12262864 0.02242134 0.85495002] prediction 2 target 2.0\n",
      "[0.01913974 0.93032313 0.05053713] prediction 1 target 1.0\n",
      "[0.90688444 0.03031736 0.0627982 ] prediction 0 target 0.0\n",
      "[0.10070627 0.00429155 0.89500217] prediction 2 target 2.0\n",
      "[0.04081701 0.95781847 0.00136452] prediction 1 target 1.0\n",
      "[0.93266448 0.00275219 0.06458333] prediction 0 target 0.0\n",
      "[0.00289561 0.98126746 0.01583693] prediction 1 target 1.0\n",
      "[0.01059047 0.83646989 0.15293964] prediction 1 target 1.0\n",
      "[0.97459097 0.00967985 0.01572918] prediction 0 target 0.0\n",
      "[0.01016343 0.18709566 0.80274091] prediction 2 target 2.0\n",
      "[0.94510482 0.05134008 0.0035551 ] prediction 0 target 0.0\n",
      "[0.06447248 0.00446447 0.93106306] prediction 2 target 2.0\n",
      "[0.06467543 0.93399399 0.00133058] prediction 1 target 1.0\n",
      "[0.14272941 0.4804038  0.37686679] prediction 1 target 0.0\n",
      "[0.59359381 0.36530213 0.04110406] prediction 0 target 0.0\n",
      "[0.96991297 0.00465075 0.02543627] prediction 0 target 0.0\n",
      "[0.00452737 0.94418264 0.05128999] prediction 1 target 1.0\n",
      "[0.3591336  0.35913359 0.28173282] prediction 0 target 0.0\n",
      "[0.42039302 0.42039303 0.15921395] prediction 1 target 0.0\n",
      "number of inputs of each class [342, 341, 217]\n",
      "correctly predicted [258, 289, 166]\n",
      "correctly predicted class 1 at 75.439\n",
      "correctly predicted class 2 at 84.751\n",
      "correctly predicted class 3 at 76.498\n",
      "accuracy at 79.222\n"
     ]
    }
   ],
   "source": [
    "# show statistics\n",
    "num_inputs_train_stats = 0\n",
    "num_inputs_test_stats = 0\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def get_prediction(output_tensor):\n",
    "    prediction_list = softmax(output_tensor.tolist())\n",
    "    max_val = -1\n",
    "    prediction = 0\n",
    "    for i in range(len(prediction_list)):\n",
    "        if prediction_list[i] > max_val:\n",
    "            max_val = prediction_list[i]\n",
    "            prediction = i\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def test_on_everything(print_output):\n",
    "\n",
    "    list_input_train_total = [0, 0, 0]\n",
    "    list_input_train_correct_total = [0, 0, 0]\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        (input, target) = data\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        output = bnn_pynq_model(input)\n",
    "        #print(target, output)\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            if print_output:\n",
    "                print(softmax(output[i].tolist()), \"prediction\", get_prediction(output[i]), \"target\", target[i].tolist())\n",
    "\n",
    "            list_input_train_total[int(target[i].tolist())] += 1\n",
    "\n",
    "            if int(target[i].tolist()) == get_prediction(output[i]):\n",
    "                list_input_train_correct_total[int(target[i].tolist())] += 1\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        (input, target) = data\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        output = bnn_pynq_model(input)\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            if print_output:\n",
    "                print(softmax(output[i].tolist()), \"prediction\", get_prediction(output[i]), \"target\", target[i].tolist())\n",
    "\n",
    "            list_input_train_total[int(target[i].tolist())] += 1\n",
    "\n",
    "            if int(target[i].tolist()) == get_prediction(output[i]):\n",
    "                list_input_train_correct_total[int(target[i].tolist())] += 1    \n",
    "\n",
    "    print(\"number of inputs of each class\", list_input_train_total)\n",
    "    print(\"correctly predicted\", list_input_train_correct_total)\n",
    "\n",
    "    running_total = 0\n",
    "    running_total_correct = 0\n",
    "    for i in range(len(list_input_train_total)):\n",
    "        print(\"correctly predicted class %d at %.3f\" % ((i + 1), (list_input_train_correct_total[i] * 100 / list_input_train_total[i])))\n",
    "        running_total += list_input_train_total[i]\n",
    "        running_total_correct += list_input_train_correct_total[i]\n",
    "    \n",
    "    print(\"accuracy at %.3f\" % ((running_total_correct * 100 / running_total)))\n",
    "    \n",
    "test_on_everything(print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model weights\n",
    "for param in bnn_pynq_model.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Split Model into Conv1D and FC Layers\n",
    "\n",
    "Given that FINN cannot synthesize Conv1D layers, we need to split the model into two components, so the FC layers can undergo synthesis and be accelerated through hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the software half\n",
    "class CNV_software(Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device=\"cpu\"):\n",
    "        super(CNV_software, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        weight_quant_type = get_quant_type(weight_bit_width)\n",
    "        act_quant_type = get_quant_type(act_bit_width)\n",
    "        in_quant_type = get_quant_type(in_bit_width)\n",
    "        stats_op = get_stats_op(weight_quant_type)\n",
    "\n",
    "        self.conv_features = ModuleList()\n",
    "        self.conv_features.append(get_act_quant(in_bit_width, in_quant_type))\n",
    "\n",
    "        # convolution layers\n",
    "        for i, out_ch, is_pool_enabled in CNV_OUT_CH_POOL:\n",
    "            self.conv_features.append(get_quant_conv1d(in_ch=in_ch,\n",
    "                                                       out_ch=out_ch,\n",
    "                                                       bit_width=weight_bit_width,\n",
    "                                                       quant_type=weight_quant_type,\n",
    "                                                       stats_op=stats_op))\n",
    "            in_ch = out_ch\n",
    "            self.conv_features.append(BatchNorm1d(in_ch))\n",
    "            if i == (NUM_CONV_LAYERS - 1):\n",
    "                self.conv_features.append(Sequential())\n",
    "            self.conv_features.append(get_act_quant(act_bit_width, act_quant_type))\n",
    "            if is_pool_enabled:\n",
    "                self.conv_features.append(MaxPool1d(kernel_size=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0]).to(self.device)\n",
    "        for mod in self.conv_features:\n",
    "            x = mod(x)\n",
    "            \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def cnv_software(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):\n",
    "    net = CNV_software(weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "              act_bit_width=ACT_BIT_WIDTH,\n",
    "              in_bit_width=IN_BIT_WIDTH,\n",
    "              num_classes=NUM_CLASSES,\n",
    "              in_ch=IN_CHANNELS)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hardware half\n",
    "# declare the classes needed for the CNN, taken from: https://github.com/maltanar/brevitas_cnv_lfc\n",
    "# this is where the pre-trained models also come from, however, we will import the whole thing here to make custom CNNs\n",
    "class CNV_hardware(Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, weight_bit_width=None, act_bit_width=None,in_bit_width=None, in_ch=3, device=\"cpu\"):\n",
    "        super(CNV_hardware, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        weight_quant_type = get_quant_type(weight_bit_width)\n",
    "        act_quant_type = get_quant_type(act_bit_width)\n",
    "        in_quant_type = get_quant_type(in_bit_width)\n",
    "        stats_op = get_stats_op(weight_quant_type)\n",
    "\n",
    "        self.linear_features = ModuleList()\n",
    "\n",
    "        # fully connected layers\n",
    "        for in_features, out_features in INTERMEDIATE_FC_FEATURES:\n",
    "            self.linear_features.append(get_quant_linear(in_features=in_features,\n",
    "                                                         out_features=out_features,\n",
    "                                                         per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n",
    "                                                         bit_width=weight_bit_width,\n",
    "                                                         quant_type=weight_quant_type,\n",
    "                                                         stats_op=stats_op))\n",
    "            self.linear_features.append(BatchNorm1d(out_features))\n",
    "            self.linear_features.append(get_act_quant(act_bit_width, act_quant_type))\n",
    "            \n",
    "        # last layer\n",
    "        self.fc = get_quant_linear(in_features=LAST_FC_IN_FEATURES,\n",
    "                                   out_features=num_classes,\n",
    "                                   per_out_ch_scaling=LAST_FC_PER_OUT_CH_SCALING,\n",
    "                                   bit_width=weight_bit_width,\n",
    "                                   quant_type=weight_quant_type,\n",
    "                                   stats_op=stats_op)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        for mod in self.linear_features:\n",
    "            x = mod(x)\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def cnv_hardware(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS):\n",
    "    net = CNV_hardware(weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "              act_bit_width=ACT_BIT_WIDTH,\n",
    "              in_bit_width=IN_BIT_WIDTH,\n",
    "              num_classes=NUM_CLASSES,\n",
    "              in_ch=IN_CHANNELS)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0064)\n",
      "tensor([[[ 2.2162e-01, -2.4257e-01, -2.1222e-01],\n",
      "         [ 1.7725e-01, -2.5708e-01,  2.7807e-01]],\n",
      "\n",
      "        [[ 2.0136e-01,  2.9895e-01, -2.5669e-01],\n",
      "         [ 1.0038e-01,  2.2872e-01, -1.6162e-01]],\n",
      "\n",
      "        [[-1.0714e-01, -2.0621e-01, -3.6598e-01],\n",
      "         [ 4.4886e-02, -3.5604e-01, -2.2989e-01]],\n",
      "\n",
      "        [[-2.9662e-01, -3.8312e-01, -1.7982e-04],\n",
      "         [-2.5084e-01,  3.6624e-01, -3.2510e-01]],\n",
      "\n",
      "        [[-1.7536e-02, -2.2805e-01,  2.8585e-01],\n",
      "         [-2.4778e-01, -2.5871e-01,  1.8433e-02]],\n",
      "\n",
      "        [[ 3.0157e-01, -1.4764e-01, -1.6992e-05],\n",
      "         [-3.4394e-01, -1.0211e-01, -4.1567e-01]],\n",
      "\n",
      "        [[-2.3728e-01, -1.6206e-02,  2.2787e-04],\n",
      "         [ 1.5364e-01,  4.0198e-01,  2.0517e-01]],\n",
      "\n",
      "        [[ 2.4769e-02,  3.6992e-01,  7.6293e-02],\n",
      "         [-3.1279e-01, -1.0879e-01,  4.5410e-01]],\n",
      "\n",
      "        [[ 3.7683e-01, -3.6153e-01, -1.7172e-01],\n",
      "         [-2.1467e-02,  2.0284e-01, -2.3384e-01]],\n",
      "\n",
      "        [[-1.1654e-01, -9.1859e-02,  1.4876e-01],\n",
      "         [-2.8274e-01,  1.5145e-01,  2.4564e-01]],\n",
      "\n",
      "        [[-1.7327e-01,  3.4133e-01,  8.8845e-02],\n",
      "         [ 3.7272e-01,  1.2331e-01, -2.1860e-01]],\n",
      "\n",
      "        [[ 3.2154e-01,  1.3021e-01, -7.7395e-02],\n",
      "         [-2.6851e-01,  2.6963e-01,  2.7115e-01]],\n",
      "\n",
      "        [[ 4.4107e-01,  2.0427e-01,  4.8580e-03],\n",
      "         [-1.1720e-02,  2.3993e-01, -1.7660e-01]],\n",
      "\n",
      "        [[-1.8679e-01, -1.4859e-03, -1.5103e-01],\n",
      "         [ 2.7547e-01,  3.1606e-01, -1.5153e-01]],\n",
      "\n",
      "        [[ 3.2723e-01,  8.2532e-02,  2.8369e-01],\n",
      "         [ 4.5056e-01, -2.3681e-01, -3.9600e-01]],\n",
      "\n",
      "        [[-3.8344e-01, -1.3339e-01,  1.5987e-01],\n",
      "         [-3.7975e-01,  1.4233e-01, -1.4523e-01]]])\n",
      "tensor([0.5580, 0.5355, 0.7016, 0.0429, 0.9378, 0.5715, 0.3792, 0.4848, 0.0423,\n",
      "        0.5938, 0.1177, 0.0217, 0.6996, 0.8030, 0.7694, 0.6569])\n",
      "tensor([-1.8777e-02,  3.2866e-02,  3.7473e-02, -5.5124e-08, -1.0546e-01,\n",
      "        -5.3674e-03, -4.8760e-03,  1.3448e-01, -3.6774e-03, -4.6957e-03,\n",
      "        -4.4466e-08,  1.6153e-08,  1.6941e-02,  2.3289e-01, -6.3608e-02,\n",
      "         1.1068e-01])\n",
      "tensor([[[-0.1568,  0.0535, -0.0740],\n",
      "         [-0.0097,  0.0850,  0.1541],\n",
      "         [-0.1408, -0.0423,  0.0887],\n",
      "         ...,\n",
      "         [-0.0536, -0.1246, -0.0990],\n",
      "         [-0.0337, -0.0170,  0.0600],\n",
      "         [ 0.1679, -0.0778, -0.1187]],\n",
      "\n",
      "        [[-0.0870, -0.1066,  0.0538],\n",
      "         [ 0.1255,  0.1362, -0.0262],\n",
      "         [-0.1064,  0.0947,  0.0279],\n",
      "         ...,\n",
      "         [ 0.0959,  0.0903, -0.0402],\n",
      "         [ 0.1161, -0.1184, -0.0348],\n",
      "         [ 0.0932,  0.1336, -0.0374]],\n",
      "\n",
      "        [[ 0.0882,  0.0652,  0.1015],\n",
      "         [ 0.0507,  0.1226, -0.1050],\n",
      "         [ 0.0776, -0.1419,  0.0239],\n",
      "         ...,\n",
      "         [ 0.0138,  0.0949,  0.0518],\n",
      "         [-0.0110,  0.0845, -0.0979],\n",
      "         [-0.0136, -0.1037, -0.0193]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0067,  0.0433, -0.1521],\n",
      "         [ 0.0818,  0.0255,  0.1164],\n",
      "         [ 0.0924,  0.0239, -0.0302],\n",
      "         ...,\n",
      "         [-0.1083, -0.0021, -0.0263],\n",
      "         [ 0.0257,  0.0988, -0.0474],\n",
      "         [-0.0298, -0.0193,  0.0221]],\n",
      "\n",
      "        [[ 0.1429, -0.0928, -0.0340],\n",
      "         [-0.0391, -0.1774, -0.0636],\n",
      "         [ 0.0997,  0.1109, -0.1550],\n",
      "         ...,\n",
      "         [-0.0182,  0.1730,  0.0996],\n",
      "         [ 0.0380,  0.1115, -0.0785],\n",
      "         [-0.1143, -0.1398, -0.0401]],\n",
      "\n",
      "        [[ 0.0376, -0.1431, -0.1081],\n",
      "         [-0.0966,  0.1105,  0.0824],\n",
      "         [ 0.0100, -0.0720,  0.0886],\n",
      "         ...,\n",
      "         [ 0.1617,  0.0710, -0.0352],\n",
      "         [-0.0817,  0.1123,  0.1016],\n",
      "         [ 0.0073,  0.0950,  0.0934]]])\n",
      "tensor([ 0.9989,  0.3766,  0.5964,  0.6867,  0.5409,  0.6724,  0.9532,  0.4383,\n",
      "        -0.6168,  0.2149,  0.4813,  0.1323,  1.1409,  0.6512, -0.0049, -0.0097,\n",
      "         0.4206,  0.6575,  0.4885,  1.0191,  0.9793,  0.8125,  0.7189,  0.4946,\n",
      "         0.1502,  0.5166,  0.6807,  0.6463,  0.5656,  0.8027,  0.6051,  0.9207])\n",
      "tensor([ 1.9574e-02,  8.3087e-02, -1.3539e-02, -7.3643e-03,  5.3040e-02,\n",
      "        -6.3900e-02,  2.3183e-01, -7.7317e-03, -5.8072e-02,  3.3387e-03,\n",
      "        -7.7237e-02, -2.8330e-04,  9.8780e-02,  6.3823e-02,  9.7363e-08,\n",
      "         2.2571e-07, -2.7037e-02,  1.5171e-02, -1.8824e-02,  8.2052e-02,\n",
      "         1.7804e-01, -4.0030e-02,  3.3995e-02, -1.3134e-02,  1.6089e-07,\n",
      "        -3.1501e-02, -7.0338e-02, -1.3771e-01, -2.4051e-02, -5.8371e-02,\n",
      "         6.5677e-02, -7.6271e-02])\n",
      "tensor([[[ 0.0542, -0.1045,  0.0865],\n",
      "         [ 0.0403, -0.0588,  0.0733],\n",
      "         [ 0.0269, -0.0466, -0.0534],\n",
      "         ...,\n",
      "         [ 0.0135, -0.0588, -0.0752],\n",
      "         [ 0.0626,  0.0449,  0.0055],\n",
      "         [-0.0360, -0.0760,  0.0607]],\n",
      "\n",
      "        [[-0.0526,  0.0697, -0.1203],\n",
      "         [-0.0149, -0.0466,  0.0615],\n",
      "         [ 0.0092, -0.0624,  0.0417],\n",
      "         ...,\n",
      "         [-0.0254,  0.0605,  0.1140],\n",
      "         [-0.0248,  0.0628, -0.0637],\n",
      "         [ 0.0580,  0.0141, -0.0478]],\n",
      "\n",
      "        [[-0.0817,  0.0067,  0.0711],\n",
      "         [-0.0527,  0.0399,  0.0415],\n",
      "         [ 0.0397, -0.0055,  0.0118],\n",
      "         ...,\n",
      "         [-0.0607,  0.0301, -0.0145],\n",
      "         [ 0.0258,  0.0535,  0.0455],\n",
      "         [-0.0706, -0.0833,  0.0540]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0419, -0.0748, -0.0922],\n",
      "         [-0.0210, -0.0822,  0.0483],\n",
      "         [-0.0537,  0.0274, -0.0915],\n",
      "         ...,\n",
      "         [ 0.0428,  0.0278,  0.0751],\n",
      "         [-0.0124, -0.0049, -0.0914],\n",
      "         [ 0.0476,  0.0317,  0.0872]],\n",
      "\n",
      "        [[ 0.0851, -0.0600,  0.0214],\n",
      "         [ 0.0733, -0.0544, -0.0240],\n",
      "         [ 0.0853, -0.0298,  0.0138],\n",
      "         ...,\n",
      "         [ 0.0375,  0.0753, -0.0346],\n",
      "         [ 0.0654,  0.0465,  0.0600],\n",
      "         [-0.0497,  0.0444, -0.0157]],\n",
      "\n",
      "        [[-0.0678, -0.0110,  0.0273],\n",
      "         [ 0.0001,  0.0884,  0.0192],\n",
      "         [ 0.0901,  0.0305,  0.0034],\n",
      "         ...,\n",
      "         [ 0.0533,  0.0408,  0.0314],\n",
      "         [ 0.0098, -0.0544, -0.0017],\n",
      "         [ 0.1070, -0.0479,  0.0602]]])\n",
      "tensor([ 0.7094,  0.6144,  0.2263,  0.2977,  0.5314,  0.8937,  1.0654,  0.2876,\n",
      "         0.1178,  1.0286, -0.0363,  0.4869,  0.4108, -0.1067,  0.8960, -0.3966,\n",
      "         0.8262,  0.7566,  0.7863, -0.0931,  0.8915,  0.1185,  0.9873,  0.6694,\n",
      "         0.2282,  1.0000,  0.9996,  0.1041,  0.9261,  0.5674,  0.2144,  0.5984,\n",
      "         0.8858,  0.0397, -0.1418,  0.8952,  0.2178,  0.3940,  0.6154,  0.1967,\n",
      "         0.7800,  0.4425,  0.7857,  1.0927,  0.4957, -0.5121,  0.7626,  0.7381,\n",
      "         1.0022,  0.6060,  0.4966,  0.0592,  0.9671, -0.2389,  0.7945,  0.3455,\n",
      "         0.8660,  0.2842,  0.3479,  0.3487,  0.0752,  0.3047,  0.0718,  0.5233])\n",
      "tensor([ 1.8685e-02,  4.9926e-02, -5.7878e-08,  5.6562e-04, -3.2649e-03,\n",
      "        -4.1092e-02,  9.3566e-03,  1.8965e-04,  9.9086e-03, -6.4551e-02,\n",
      "         1.0018e-07, -5.5537e-03,  1.8000e-07,  6.3055e-08, -6.1368e-03,\n",
      "        -2.7575e-03, -8.9180e-02,  1.5949e-01, -1.8517e-01,  8.0296e-08,\n",
      "        -7.1238e-03, -2.9593e-09, -4.8390e-02, -1.5111e-01, -3.9030e-03,\n",
      "         1.2612e-01,  1.4615e-01, -1.0137e-07,  1.1292e-02,  1.1586e-01,\n",
      "        -1.5777e-02, -4.2481e-03, -1.9165e-02,  4.5494e-08, -9.9837e-09,\n",
      "         5.4158e-02,  4.9090e-08, -9.9834e-02,  1.4886e-02, -5.2581e-03,\n",
      "         1.5350e-01,  1.3733e-01,  1.5282e-01, -1.1070e-01, -2.4991e-02,\n",
      "        -1.3536e-03,  1.9711e-01,  2.4087e-01, -8.7206e-02,  1.2194e-02,\n",
      "         1.4073e-01,  1.2065e-07, -9.7920e-02,  2.7069e-04, -1.2360e-01,\n",
      "         9.1955e-05,  1.4323e-01, -1.2500e-07, -6.1352e-02,  3.6195e-02,\n",
      "        -3.7357e-08,  2.1620e-02,  7.1211e-02, -6.9517e-02])\n",
      "tensor([[[-0.0306,  0.0694,  0.0560],\n",
      "         [-0.0008, -0.0033, -0.0625],\n",
      "         [-0.0475, -0.0560,  0.0142],\n",
      "         ...,\n",
      "         [ 0.0610, -0.0356, -0.0758],\n",
      "         [ 0.0187,  0.0189,  0.0571],\n",
      "         [-0.0272,  0.0602, -0.0542]],\n",
      "\n",
      "        [[ 0.0258,  0.0369,  0.0486],\n",
      "         [-0.0788, -0.0943, -0.0023],\n",
      "         [ 0.0582, -0.0247,  0.0399],\n",
      "         ...,\n",
      "         [ 0.0021, -0.0050, -0.0269],\n",
      "         [ 0.0657,  0.0356,  0.0003],\n",
      "         [ 0.0309,  0.0450,  0.0488]],\n",
      "\n",
      "        [[ 0.0681,  0.0531, -0.0539],\n",
      "         [ 0.0644, -0.0314,  0.0012],\n",
      "         [-0.0553,  0.0552,  0.0153],\n",
      "         ...,\n",
      "         [ 0.0237,  0.0068, -0.0226],\n",
      "         [ 0.0057, -0.0089,  0.0612],\n",
      "         [ 0.0066,  0.0190,  0.0085]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0841,  0.0518, -0.0290],\n",
      "         [ 0.0180,  0.0400, -0.0661],\n",
      "         [-0.0404,  0.0675, -0.0318],\n",
      "         ...,\n",
      "         [-0.0588,  0.0080, -0.0573],\n",
      "         [-0.0302,  0.0101,  0.0746],\n",
      "         [ 0.0500,  0.0386, -0.0214]],\n",
      "\n",
      "        [[ 0.0687, -0.0262, -0.0339],\n",
      "         [-0.0370,  0.0617, -0.0331],\n",
      "         [ 0.0635,  0.0086,  0.0597],\n",
      "         ...,\n",
      "         [ 0.0229,  0.0264,  0.0538],\n",
      "         [ 0.0290, -0.0570,  0.0562],\n",
      "         [-0.0213, -0.0451,  0.0431]],\n",
      "\n",
      "        [[ 0.0527,  0.0372, -0.0126],\n",
      "         [-0.0718,  0.0190, -0.0846],\n",
      "         [ 0.0651,  0.0491,  0.0345],\n",
      "         ...,\n",
      "         [ 0.0192, -0.0456, -0.0341],\n",
      "         [ 0.0120,  0.0016,  0.0547],\n",
      "         [-0.0521,  0.0465, -0.0346]]])\n",
      "tensor([ 7.7777e-01,  9.3618e-01,  7.0060e-01,  8.5798e-01,  3.7753e-01,\n",
      "         4.1665e-01,  6.8791e-03,  8.0000e-01,  8.8870e-01,  2.4777e-01,\n",
      "         8.8970e-01, -9.6660e-04, -1.7244e-02,  8.7116e-01,  2.2395e-01,\n",
      "         4.5609e-01,  6.6936e-01,  2.4918e-01,  6.1630e-01,  4.5354e-02,\n",
      "         5.6505e-01,  7.8711e-01,  7.3299e-01,  7.7272e-01,  8.3114e-01,\n",
      "         1.1113e+00,  5.8826e-01,  7.4593e-01,  3.2299e-02,  1.0677e+00,\n",
      "         4.0733e-01, -1.1737e-01,  8.3216e-01,  2.5569e-01,  1.7827e-01,\n",
      "         7.2715e-01,  7.4456e-01,  3.3612e-01,  2.8098e-01,  4.5528e-02,\n",
      "         2.7313e-01,  6.6291e-01,  1.0093e+00,  2.1921e-01,  1.0282e+00,\n",
      "        -5.4320e-03,  3.9736e-02,  6.6120e-01,  8.4302e-01,  3.4145e-01,\n",
      "         6.1743e-01,  6.4617e-01,  6.5607e-01,  2.6764e-01,  8.2607e-01,\n",
      "         7.9290e-01,  7.7288e-01,  2.8403e-01,  1.3668e-01,  4.1057e-01,\n",
      "         2.5374e-01,  9.7702e-01,  1.8925e-01,  6.7830e-01,  5.0989e-01,\n",
      "         7.6032e-01,  1.8006e-01,  6.7862e-01,  6.5697e-02,  8.4843e-01,\n",
      "         7.6818e-01,  5.4117e-01,  3.2003e-01,  5.1525e-01,  3.8431e-01,\n",
      "         4.3388e-01,  4.5083e-01,  5.5123e-01,  6.9121e-01,  5.9249e-01,\n",
      "         8.8161e-01,  1.0056e+00,  1.0320e+00,  3.1076e-01, -1.8590e-02,\n",
      "         8.6550e-01,  1.4709e-01,  7.2441e-01,  5.9925e-01,  6.9120e-01,\n",
      "         3.4076e-01,  7.0158e-01,  1.1414e+00,  2.3622e-02,  9.4063e-01,\n",
      "         7.6738e-01,  1.7565e-01,  6.4312e-01, -6.9999e-03,  6.8726e-01,\n",
      "         7.2212e-01,  6.5477e-01, -1.7812e-02, -3.1956e-02,  3.9755e-01,\n",
      "         6.7820e-01,  6.1576e-01,  7.8861e-01,  5.3489e-01,  6.1871e-01,\n",
      "         3.2068e-01,  7.8874e-01,  2.4829e-01,  5.5715e-01,  6.5295e-01,\n",
      "         1.4705e-01,  9.3777e-01,  5.1765e-02,  3.1317e-01,  9.3940e-01,\n",
      "         4.3958e-01,  5.6364e-01,  2.1717e-01, -7.2823e-02,  3.6504e-01,\n",
      "         6.4697e-01,  6.0140e-01,  7.8794e-01])\n",
      "tensor([ 1.5323e-01,  2.1738e-02,  8.7334e-03,  1.3448e-01,  9.9623e-09,\n",
      "        -1.8743e-08,  3.0225e-08,  1.0197e-02, -3.8564e-02, -3.1533e-09,\n",
      "         3.8816e-02,  2.4496e-08, -1.6300e-08, -6.3099e-02,  1.0691e-08,\n",
      "         3.8132e-02,  4.0533e-02, -4.1374e-09, -2.3050e-02,  6.9710e-09,\n",
      "         4.8267e-04, -3.1849e-02,  8.8291e-02, -8.2372e-02,  5.8182e-03,\n",
      "         3.3939e-03, -3.0704e-02, -5.3132e-02, -2.2136e-08, -3.5397e-02,\n",
      "        -2.6850e-08,  1.7013e-08,  4.3742e-02, -1.2350e-08, -1.5691e-09,\n",
      "         3.4729e-02,  3.2033e-02,  1.1853e-08,  5.7877e-09, -1.6888e-09,\n",
      "        -7.6505e-09, -3.9853e-02, -1.3574e-01,  5.2009e-09, -9.2945e-02,\n",
      "         9.7546e-09,  6.3372e-09, -6.9360e-02,  6.0264e-02, -6.6364e-03,\n",
      "         5.0980e-02, -5.0332e-03, -1.3181e-02,  3.0053e-09,  1.0490e-01,\n",
      "        -7.7671e-02, -1.6395e-02,  7.9023e-09, -1.0138e-08, -2.2540e-08,\n",
      "        -1.7113e-08,  1.1018e-01,  1.2155e-08,  2.0783e-02,  1.0598e-08,\n",
      "         4.2127e-02, -2.5513e-09, -1.6892e-02, -1.1166e-08,  1.2845e-02,\n",
      "        -5.7266e-02,  4.1186e-03,  3.5461e-02, -1.2601e-08, -2.9001e-08,\n",
      "         4.1047e-03, -3.5762e-04, -4.1216e-03, -1.7734e-02, -4.4624e-02,\n",
      "        -1.9290e-02, -1.4382e-01,  1.6176e-03,  5.3688e-09, -9.5655e-09,\n",
      "        -5.0599e-02, -7.6661e-09,  4.4603e-02, -5.2454e-03, -1.8244e-03,\n",
      "         2.9297e-10, -4.1232e-02,  1.8218e-01, -2.1365e-09,  2.1413e-02,\n",
      "         1.3059e-02, -3.9120e-10,  4.9358e-02, -2.3906e-09, -4.3474e-03,\n",
      "        -1.8328e-02,  8.1601e-03,  9.5555e-09, -2.0145e-09,  2.8234e-08,\n",
      "         2.4283e-02, -2.0697e-02, -5.7809e-02,  6.5091e-09, -2.4507e-02,\n",
      "        -7.6437e-09, -8.7199e-02,  9.1918e-09, -2.8207e-03, -5.5451e-02,\n",
      "         6.2424e-09,  1.9945e-01, -3.4947e-08, -3.0327e-10, -5.5651e-02,\n",
      "         1.2107e-08, -3.3832e-02,  9.6072e-09, -2.4306e-09,  1.5264e-08,\n",
      "         1.3748e-02, -4.8579e-04,  1.8063e-02])\n",
      "tensor([[ 2.9551e-02, -7.2062e-03,  7.2162e-02,  ..., -4.3352e-02,\n",
      "         -3.8591e-02, -2.8161e-02],\n",
      "        [ 1.9337e-02,  5.3529e-02,  6.3475e-02,  ...,  1.0917e-02,\n",
      "          1.9347e-02,  2.7778e-02],\n",
      "        [ 3.5793e-03,  3.0430e-02,  2.7088e-02,  ...,  5.2701e-02,\n",
      "          5.5873e-02, -6.2073e-03],\n",
      "        ...,\n",
      "        [ 1.6399e-02,  3.5601e-05,  1.5477e-02,  ..., -7.9455e-02,\n",
      "         -3.3945e-02,  1.5089e-02],\n",
      "        [ 1.2484e-02, -4.4670e-02,  3.9056e-02,  ...,  2.3847e-02,\n",
      "         -4.9671e-02, -3.6577e-02],\n",
      "        [ 1.6561e-02,  4.7503e-02,  4.8830e-02,  ...,  2.7202e-02,\n",
      "          5.8513e-02,  3.6944e-02]])\n",
      "tensor([ 2.2560e-01,  3.7280e-01,  2.7660e-01,  1.6638e-01,  9.5067e-01,\n",
      "         8.1255e-01,  2.0576e-01,  1.9673e-01,  1.5563e-01,  4.2878e-01,\n",
      "         8.8257e-01,  9.9013e-01,  4.3946e-01,  9.8031e-02,  3.0946e-01,\n",
      "        -2.0191e-02,  1.0191e-01,  4.5421e-01,  6.0305e-01,  8.5502e-01,\n",
      "         5.7326e-01,  5.6225e-01, -6.3843e-03,  7.0847e-02,  2.3426e-01,\n",
      "         9.6105e-01,  7.6256e-01,  6.7588e-01, -1.3082e-02,  9.8842e-01,\n",
      "         3.5486e-01,  9.0037e-01,  1.0550e-01,  5.6716e-01,  7.0811e-01,\n",
      "         9.6865e-01,  1.8543e-01,  1.0016e+00,  1.1720e-01,  9.2547e-01,\n",
      "         9.4880e-01,  7.0114e-01,  2.1375e-02,  1.0200e+00,  1.5809e-01,\n",
      "         3.8617e-01,  2.2563e-02,  5.9367e-01,  5.9061e-01,  5.7404e-01,\n",
      "         5.5779e-01,  4.9744e-01,  7.8645e-04,  3.0027e-01,  4.3731e-01,\n",
      "         5.6754e-01,  1.7602e-02,  8.9251e-01,  1.0014e+00,  5.4094e-01,\n",
      "         1.8976e-01,  1.0313e-01,  9.5140e-01,  7.5708e-01,  5.1073e-01,\n",
      "         8.1117e-01,  1.0014e+00,  7.9937e-01,  1.2531e-02,  7.0822e-01,\n",
      "         9.7956e-01,  2.0068e-01,  7.0175e-02,  5.2422e-01,  9.8618e-01,\n",
      "         2.2915e-01,  7.3182e-01,  4.6926e-01,  9.9604e-01,  1.0503e-01,\n",
      "        -6.8362e-03,  1.4931e-01,  9.4260e-01,  1.6187e-02,  2.6813e-01,\n",
      "         6.7764e-01,  3.9956e-02,  3.4503e-01,  1.4943e-03,  7.8811e-01,\n",
      "         2.4287e-01,  5.2382e-01,  1.4765e-02,  5.5071e-01,  7.8524e-01,\n",
      "        -1.4720e-02,  3.0445e-01,  2.9112e-01,  8.2184e-01,  2.8122e-01,\n",
      "         1.4399e-02,  4.3449e-01,  2.9215e-01,  2.6993e-02,  9.3616e-01,\n",
      "         8.7823e-01,  5.4757e-01,  1.5800e-01,  3.1028e-01,  5.3892e-01,\n",
      "        -3.0567e-03,  3.3680e-01,  3.5858e-02,  1.3138e-01,  3.8594e-01,\n",
      "         5.8376e-01,  5.5838e-01,  5.0528e-01,  9.3300e-01,  9.4326e-01,\n",
      "         2.1667e-01,  4.3814e-01,  7.3435e-01,  2.7022e-02,  2.4846e-02,\n",
      "         5.9274e-01,  5.0147e-01,  3.4394e-01])\n",
      "tensor([ 1.0917e-02, -2.3289e-02,  4.9429e-02,  2.6275e-02, -4.9457e-02,\n",
      "        -4.8949e-02, -4.8949e-02, -5.0020e-02,  3.5808e-09, -2.3997e-02,\n",
      "         2.0876e-02,  1.4601e-02, -6.0453e-03,  9.9643e-03,  1.6122e-03,\n",
      "        -2.3289e-02, -3.8931e-02, -3.5808e-09, -1.8222e-03,  6.6743e-04,\n",
      "         3.5808e-09,  2.3289e-02, -2.3684e-02,  4.5828e-02, -4.7982e-02,\n",
      "        -4.1756e-02, -2.5660e-02,  2.5660e-02,  9.7832e-03, -1.1678e-02,\n",
      "         4.8949e-02,  2.5464e-02,  6.0569e-03,  3.5808e-09,  7.5715e-03,\n",
      "         3.5808e-09,  3.5808e-09, -4.1215e-03, -1.4720e-02, -2.3289e-02,\n",
      "        -4.6009e-02, -1.8181e-02, -1.8929e-02,  1.7177e-02, -2.5660e-02,\n",
      "        -4.8949e-02,  2.5441e-02, -2.6732e-02, -2.3289e-02, -6.6259e-05,\n",
      "         3.6441e-03,  2.3289e-02, -7.7058e-04, -2.3289e-02, -2.1475e-02,\n",
      "        -2.2682e-02, -2.5660e-02, -3.8767e-03,  4.7958e-04, -2.5660e-02,\n",
      "        -2.3289e-02,  1.2985e-02,  1.0836e-02,  2.0677e-02, -4.2764e-03,\n",
      "        -2.3428e-02, -8.2718e-04, -4.8949e-02,  6.2035e-03, -3.5808e-09,\n",
      "        -2.2034e-02, -4.7687e-02, -4.9682e-02, -3.5808e-09, -1.6235e-02,\n",
      "         2.3289e-02,  2.1229e-02,  2.5122e-02,  4.6051e-03, -2.5660e-02,\n",
      "        -4.6416e-02,  3.5808e-09,  2.3289e-02, -1.3180e-02,  2.2794e-02,\n",
      "         4.8583e-02, -2.6199e-02, -1.9233e-02, -3.5808e-09, -2.0520e-03,\n",
      "        -4.8370e-03,  3.8566e-02, -4.8949e-02, -2.5435e-02,  4.7601e-02,\n",
      "         4.8949e-02,  5.7969e-03,  4.8949e-02,  2.5660e-02, -2.5031e-02,\n",
      "         3.9592e-03, -2.3289e-02, -3.0920e-02, -2.4825e-02,  2.0359e-03,\n",
      "         1.9006e-02, -3.5808e-09,  3.3724e-02, -1.8638e-02,  2.4171e-02,\n",
      "        -2.2564e-03,  3.5808e-09,  1.5985e-02, -4.8949e-02, -4.8949e-02,\n",
      "         2.2331e-02, -2.5660e-02,  2.3289e-02, -2.3289e-02,  3.5808e-09,\n",
      "        -2.5660e-02, -4.5987e-02,  4.6516e-02,  2.6752e-02, -2.3014e-02,\n",
      "        -2.1958e-02,  4.8949e-02, -5.4841e-02])\n",
      "tensor([[-0.0195,  0.0758,  0.0746, -0.0617, -0.0973, -0.1069, -0.0539, -0.0092,\n",
      "         -0.1280, -0.0508, -0.0595,  0.0731, -0.0426, -0.0083,  0.1263,  0.0213,\n",
      "          0.0258,  0.0728, -0.0301,  0.1363, -0.0513, -0.0759, -0.0114,  0.0099,\n",
      "         -0.0272, -0.0632, -0.0489,  0.0814,  0.0052, -0.0541,  0.0461,  0.1121,\n",
      "          0.0042, -0.0145, -0.0047, -0.0294, -0.0091,  0.0933, -0.0138,  0.0997,\n",
      "         -0.0193,  0.0993, -0.0227, -0.1475, -0.0350, -0.0369, -0.0862, -0.0535,\n",
      "          0.1002, -0.0219,  0.1080, -0.1028, -0.0051,  0.0331, -0.0267,  0.1705,\n",
      "         -0.0287,  0.0520,  0.1104, -0.0630,  0.0931, -0.0504,  0.0059, -0.1622,\n",
      "         -0.0584,  0.1188, -0.1282, -0.0606, -0.0065,  0.0760, -0.1221, -0.0963,\n",
      "         -0.0046,  0.0885, -0.0828, -0.0563, -0.1514,  0.0360,  0.0411, -0.0790,\n",
      "         -0.0531, -0.1126, -0.0785,  0.0797,  0.0504,  0.0664,  0.0414,  0.1550,\n",
      "          0.0728,  0.0528, -0.0047, -0.0262, -0.0738, -0.0741,  0.0670,  0.0638,\n",
      "          0.1110,  0.0906,  0.0997,  0.0153, -0.0050,  0.1226,  0.0137, -0.0372,\n",
      "         -0.0990, -0.0985,  0.0863,  0.0740,  0.0174, -0.0904,  0.0108, -0.1338,\n",
      "         -0.1159, -0.0385, -0.0413,  0.0523, -0.0134, -0.0580,  0.0830, -0.0589,\n",
      "         -0.0493, -0.0272,  0.0344,  0.0324, -0.0652,  0.0826,  0.0109, -0.0889],\n",
      "        [-0.0796, -0.0530, -0.0061,  0.0524, -0.0755, -0.0876, -0.0832, -0.0803,\n",
      "         -0.0497,  0.0419,  0.0544, -0.0749,  0.0795, -0.0494, -0.0758, -0.0396,\n",
      "         -0.0927,  0.0865, -0.0171, -0.0044, -0.0420,  0.1279,  0.0835,  0.0560,\n",
      "         -0.0755, -0.0923,  0.0786, -0.1256, -0.0412,  0.1150,  0.0848, -0.0726,\n",
      "         -0.0057, -0.1115,  0.1279, -0.0133, -0.0548, -0.0994,  0.0736, -0.1211,\n",
      "         -0.0876, -0.1717,  0.0748, -0.1058,  0.0367, -0.0744,  0.0059,  0.0405,\n",
      "         -0.1077, -0.0583,  0.0258,  0.1323, -0.0458, -0.0647,  0.0148, -0.0851,\n",
      "          0.0184, -0.0106, -0.1150,  0.1392, -0.0728,  0.0187, -0.1448,  0.1090,\n",
      "         -0.0078, -0.0928, -0.0895, -0.0257, -0.0777,  0.1495, -0.0359, -0.0214,\n",
      "         -0.0566,  0.0688, -0.0994,  0.0863,  0.0903, -0.0313, -0.0228,  0.0314,\n",
      "         -0.0478, -0.0934,  0.0859, -0.0046, -0.1185,  0.0369, -0.0384, -0.0689,\n",
      "          0.0279,  0.0707,  0.0857,  0.0723, -0.0258,  0.1345,  0.0689,  0.0607,\n",
      "         -0.0108,  0.0171, -0.0883,  0.0070,  0.0637, -0.0932, -0.1402,  0.0744,\n",
      "          0.0596,  0.0730,  0.0878,  0.0049, -0.0082,  0.1723,  0.0484, -0.0340,\n",
      "          0.0129, -0.0703, -0.0923, -0.0631,  0.0194,  0.0776, -0.1268, -0.0311,\n",
      "          0.0071, -0.0841,  0.0718,  0.0059, -0.0099, -0.0537,  0.0952, -0.0122],\n",
      "        [-0.0048,  0.0705, -0.1027, -0.0206,  0.1175,  0.0454,  0.0150,  0.0625,\n",
      "         -0.0755,  0.0328, -0.0551, -0.1270, -0.0051, -0.1176, -0.0140,  0.0588,\n",
      "          0.0607,  0.0276, -0.1007,  0.0228, -0.1227, -0.1158,  0.0240, -0.0133,\n",
      "          0.0951,  0.0601,  0.0387, -0.0465, -0.0804,  0.0395, -0.0541, -0.0438,\n",
      "         -0.0484, -0.0651,  0.0100, -0.1371, -0.0351,  0.0767, -0.0108,  0.0566,\n",
      "          0.0949,  0.0598, -0.0137,  0.1397,  0.0302,  0.0419, -0.0191,  0.0663,\n",
      "          0.0982, -0.0762,  0.0047, -0.0718, -0.0161,  0.1215,  0.0371,  0.0331,\n",
      "          0.0434,  0.1109, -0.0452,  0.0053,  0.0167,  0.0069, -0.0859, -0.0461,\n",
      "         -0.0790,  0.0256,  0.1060,  0.0673,  0.0092,  0.0100,  0.0800,  0.0502,\n",
      "          0.0223,  0.0402,  0.0580, -0.0342, -0.0631, -0.0921,  0.0967,  0.0343,\n",
      "          0.0473, -0.0226, -0.0695,  0.0368,  0.0044, -0.0883,  0.0691, -0.0083,\n",
      "          0.0898,  0.0410,  0.0969, -0.0258,  0.0825,  0.0691, -0.0721, -0.0821,\n",
      "         -0.0135, -0.0141, -0.0512,  0.0231,  0.0343,  0.0964,  0.0123, -0.0039,\n",
      "          0.0123, -0.0513,  0.0213, -0.0207, -0.0140, -0.1060,  0.0979, -0.0778,\n",
      "          0.0103,  0.0386,  0.0317, -0.0932,  0.0755, -0.0310,  0.0881, -0.0622,\n",
      "          0.0603,  0.0358, -0.0377, -0.0603, -0.0217,  0.1284, -0.0634,  0.0545]])\n"
     ]
    }
   ],
   "source": [
    "# generate both models\n",
    "cnv_software_model = cnv_software(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)\n",
    "cnv_hardware_model = cnv_hardware(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)\n",
    "\n",
    "# split the layers of the original model\n",
    "cnv_pretrained_model = cnv_manual(WEIGHT_BIT_WIDTH, ACT_BIT_WIDTH, IN_BIT_WIDTH, NUM_CLASSES, IN_CHANNELS)\n",
    "cnv_pretrained_model.load_state_dict(torch.load(build_dir + model_path))\n",
    "cnv_pretrained_model.eval()\n",
    "\n",
    "# print the model weights for reference if needed\n",
    "for param in bnn_pynq_model.parameters():\n",
    "    print(param.data)\n",
    "    \n",
    "# copy over the layers\n",
    "cnv_software_model.conv_features = cnv_pretrained_model.conv_features\n",
    "cnv_hardware_model.linear_features = cnv_pretrained_model.linear_features\n",
    "cnv_hardware_model.fc = cnv_pretrained_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0064)\n",
      "tensor([[[ 2.2162e-01, -2.4257e-01, -2.1222e-01],\n",
      "         [ 1.7725e-01, -2.5708e-01,  2.7807e-01]],\n",
      "\n",
      "        [[ 2.0136e-01,  2.9895e-01, -2.5669e-01],\n",
      "         [ 1.0038e-01,  2.2872e-01, -1.6162e-01]],\n",
      "\n",
      "        [[-1.0714e-01, -2.0621e-01, -3.6598e-01],\n",
      "         [ 4.4886e-02, -3.5604e-01, -2.2989e-01]],\n",
      "\n",
      "        [[-2.9662e-01, -3.8312e-01, -1.7982e-04],\n",
      "         [-2.5084e-01,  3.6624e-01, -3.2510e-01]],\n",
      "\n",
      "        [[-1.7536e-02, -2.2805e-01,  2.8585e-01],\n",
      "         [-2.4778e-01, -2.5871e-01,  1.8433e-02]],\n",
      "\n",
      "        [[ 3.0157e-01, -1.4764e-01, -1.6992e-05],\n",
      "         [-3.4394e-01, -1.0211e-01, -4.1567e-01]],\n",
      "\n",
      "        [[-2.3728e-01, -1.6206e-02,  2.2787e-04],\n",
      "         [ 1.5364e-01,  4.0198e-01,  2.0517e-01]],\n",
      "\n",
      "        [[ 2.4769e-02,  3.6992e-01,  7.6293e-02],\n",
      "         [-3.1279e-01, -1.0879e-01,  4.5410e-01]],\n",
      "\n",
      "        [[ 3.7683e-01, -3.6153e-01, -1.7172e-01],\n",
      "         [-2.1467e-02,  2.0284e-01, -2.3384e-01]],\n",
      "\n",
      "        [[-1.1654e-01, -9.1859e-02,  1.4876e-01],\n",
      "         [-2.8274e-01,  1.5145e-01,  2.4564e-01]],\n",
      "\n",
      "        [[-1.7327e-01,  3.4133e-01,  8.8845e-02],\n",
      "         [ 3.7272e-01,  1.2331e-01, -2.1860e-01]],\n",
      "\n",
      "        [[ 3.2154e-01,  1.3021e-01, -7.7395e-02],\n",
      "         [-2.6851e-01,  2.6963e-01,  2.7115e-01]],\n",
      "\n",
      "        [[ 4.4107e-01,  2.0427e-01,  4.8580e-03],\n",
      "         [-1.1720e-02,  2.3993e-01, -1.7660e-01]],\n",
      "\n",
      "        [[-1.8679e-01, -1.4859e-03, -1.5103e-01],\n",
      "         [ 2.7547e-01,  3.1606e-01, -1.5153e-01]],\n",
      "\n",
      "        [[ 3.2723e-01,  8.2532e-02,  2.8369e-01],\n",
      "         [ 4.5056e-01, -2.3681e-01, -3.9600e-01]],\n",
      "\n",
      "        [[-3.8344e-01, -1.3339e-01,  1.5987e-01],\n",
      "         [-3.7975e-01,  1.4233e-01, -1.4523e-01]]])\n",
      "tensor([0.5580, 0.5355, 0.7016, 0.0429, 0.9378, 0.5715, 0.3792, 0.4848, 0.0423,\n",
      "        0.5938, 0.1177, 0.0217, 0.6996, 0.8030, 0.7694, 0.6569])\n",
      "tensor([-1.8777e-02,  3.2866e-02,  3.7473e-02, -5.5124e-08, -1.0546e-01,\n",
      "        -5.3674e-03, -4.8760e-03,  1.3448e-01, -3.6774e-03, -4.6957e-03,\n",
      "        -4.4466e-08,  1.6153e-08,  1.6941e-02,  2.3289e-01, -6.3608e-02,\n",
      "         1.1068e-01])\n",
      "tensor([[[-0.1568,  0.0535, -0.0740],\n",
      "         [-0.0097,  0.0850,  0.1541],\n",
      "         [-0.1408, -0.0423,  0.0887],\n",
      "         ...,\n",
      "         [-0.0536, -0.1246, -0.0990],\n",
      "         [-0.0337, -0.0170,  0.0600],\n",
      "         [ 0.1679, -0.0778, -0.1187]],\n",
      "\n",
      "        [[-0.0870, -0.1066,  0.0538],\n",
      "         [ 0.1255,  0.1362, -0.0262],\n",
      "         [-0.1064,  0.0947,  0.0279],\n",
      "         ...,\n",
      "         [ 0.0959,  0.0903, -0.0402],\n",
      "         [ 0.1161, -0.1184, -0.0348],\n",
      "         [ 0.0932,  0.1336, -0.0374]],\n",
      "\n",
      "        [[ 0.0882,  0.0652,  0.1015],\n",
      "         [ 0.0507,  0.1226, -0.1050],\n",
      "         [ 0.0776, -0.1419,  0.0239],\n",
      "         ...,\n",
      "         [ 0.0138,  0.0949,  0.0518],\n",
      "         [-0.0110,  0.0845, -0.0979],\n",
      "         [-0.0136, -0.1037, -0.0193]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0067,  0.0433, -0.1521],\n",
      "         [ 0.0818,  0.0255,  0.1164],\n",
      "         [ 0.0924,  0.0239, -0.0302],\n",
      "         ...,\n",
      "         [-0.1083, -0.0021, -0.0263],\n",
      "         [ 0.0257,  0.0988, -0.0474],\n",
      "         [-0.0298, -0.0193,  0.0221]],\n",
      "\n",
      "        [[ 0.1429, -0.0928, -0.0340],\n",
      "         [-0.0391, -0.1774, -0.0636],\n",
      "         [ 0.0997,  0.1109, -0.1550],\n",
      "         ...,\n",
      "         [-0.0182,  0.1730,  0.0996],\n",
      "         [ 0.0380,  0.1115, -0.0785],\n",
      "         [-0.1143, -0.1398, -0.0401]],\n",
      "\n",
      "        [[ 0.0376, -0.1431, -0.1081],\n",
      "         [-0.0966,  0.1105,  0.0824],\n",
      "         [ 0.0100, -0.0720,  0.0886],\n",
      "         ...,\n",
      "         [ 0.1617,  0.0710, -0.0352],\n",
      "         [-0.0817,  0.1123,  0.1016],\n",
      "         [ 0.0073,  0.0950,  0.0934]]])\n",
      "tensor([ 0.9989,  0.3766,  0.5964,  0.6867,  0.5409,  0.6724,  0.9532,  0.4383,\n",
      "        -0.6168,  0.2149,  0.4813,  0.1323,  1.1409,  0.6512, -0.0049, -0.0097,\n",
      "         0.4206,  0.6575,  0.4885,  1.0191,  0.9793,  0.8125,  0.7189,  0.4946,\n",
      "         0.1502,  0.5166,  0.6807,  0.6463,  0.5656,  0.8027,  0.6051,  0.9207])\n",
      "tensor([ 1.9574e-02,  8.3087e-02, -1.3539e-02, -7.3643e-03,  5.3040e-02,\n",
      "        -6.3900e-02,  2.3183e-01, -7.7317e-03, -5.8072e-02,  3.3387e-03,\n",
      "        -7.7237e-02, -2.8330e-04,  9.8780e-02,  6.3823e-02,  9.7363e-08,\n",
      "         2.2571e-07, -2.7037e-02,  1.5171e-02, -1.8824e-02,  8.2052e-02,\n",
      "         1.7804e-01, -4.0030e-02,  3.3995e-02, -1.3134e-02,  1.6089e-07,\n",
      "        -3.1501e-02, -7.0338e-02, -1.3771e-01, -2.4051e-02, -5.8371e-02,\n",
      "         6.5677e-02, -7.6271e-02])\n",
      "tensor([[[ 0.0542, -0.1045,  0.0865],\n",
      "         [ 0.0403, -0.0588,  0.0733],\n",
      "         [ 0.0269, -0.0466, -0.0534],\n",
      "         ...,\n",
      "         [ 0.0135, -0.0588, -0.0752],\n",
      "         [ 0.0626,  0.0449,  0.0055],\n",
      "         [-0.0360, -0.0760,  0.0607]],\n",
      "\n",
      "        [[-0.0526,  0.0697, -0.1203],\n",
      "         [-0.0149, -0.0466,  0.0615],\n",
      "         [ 0.0092, -0.0624,  0.0417],\n",
      "         ...,\n",
      "         [-0.0254,  0.0605,  0.1140],\n",
      "         [-0.0248,  0.0628, -0.0637],\n",
      "         [ 0.0580,  0.0141, -0.0478]],\n",
      "\n",
      "        [[-0.0817,  0.0067,  0.0711],\n",
      "         [-0.0527,  0.0399,  0.0415],\n",
      "         [ 0.0397, -0.0055,  0.0118],\n",
      "         ...,\n",
      "         [-0.0607,  0.0301, -0.0145],\n",
      "         [ 0.0258,  0.0535,  0.0455],\n",
      "         [-0.0706, -0.0833,  0.0540]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0419, -0.0748, -0.0922],\n",
      "         [-0.0210, -0.0822,  0.0483],\n",
      "         [-0.0537,  0.0274, -0.0915],\n",
      "         ...,\n",
      "         [ 0.0428,  0.0278,  0.0751],\n",
      "         [-0.0124, -0.0049, -0.0914],\n",
      "         [ 0.0476,  0.0317,  0.0872]],\n",
      "\n",
      "        [[ 0.0851, -0.0600,  0.0214],\n",
      "         [ 0.0733, -0.0544, -0.0240],\n",
      "         [ 0.0853, -0.0298,  0.0138],\n",
      "         ...,\n",
      "         [ 0.0375,  0.0753, -0.0346],\n",
      "         [ 0.0654,  0.0465,  0.0600],\n",
      "         [-0.0497,  0.0444, -0.0157]],\n",
      "\n",
      "        [[-0.0678, -0.0110,  0.0273],\n",
      "         [ 0.0001,  0.0884,  0.0192],\n",
      "         [ 0.0901,  0.0305,  0.0034],\n",
      "         ...,\n",
      "         [ 0.0533,  0.0408,  0.0314],\n",
      "         [ 0.0098, -0.0544, -0.0017],\n",
      "         [ 0.1070, -0.0479,  0.0602]]])\n",
      "tensor([ 0.7094,  0.6144,  0.2263,  0.2977,  0.5314,  0.8937,  1.0654,  0.2876,\n",
      "         0.1178,  1.0286, -0.0363,  0.4869,  0.4108, -0.1067,  0.8960, -0.3966,\n",
      "         0.8262,  0.7566,  0.7863, -0.0931,  0.8915,  0.1185,  0.9873,  0.6694,\n",
      "         0.2282,  1.0000,  0.9996,  0.1041,  0.9261,  0.5674,  0.2144,  0.5984,\n",
      "         0.8858,  0.0397, -0.1418,  0.8952,  0.2178,  0.3940,  0.6154,  0.1967,\n",
      "         0.7800,  0.4425,  0.7857,  1.0927,  0.4957, -0.5121,  0.7626,  0.7381,\n",
      "         1.0022,  0.6060,  0.4966,  0.0592,  0.9671, -0.2389,  0.7945,  0.3455,\n",
      "         0.8660,  0.2842,  0.3479,  0.3487,  0.0752,  0.3047,  0.0718,  0.5233])\n",
      "tensor([ 1.8685e-02,  4.9926e-02, -5.7878e-08,  5.6562e-04, -3.2649e-03,\n",
      "        -4.1092e-02,  9.3566e-03,  1.8965e-04,  9.9086e-03, -6.4551e-02,\n",
      "         1.0018e-07, -5.5537e-03,  1.8000e-07,  6.3055e-08, -6.1368e-03,\n",
      "        -2.7575e-03, -8.9180e-02,  1.5949e-01, -1.8517e-01,  8.0296e-08,\n",
      "        -7.1238e-03, -2.9593e-09, -4.8390e-02, -1.5111e-01, -3.9030e-03,\n",
      "         1.2612e-01,  1.4615e-01, -1.0137e-07,  1.1292e-02,  1.1586e-01,\n",
      "        -1.5777e-02, -4.2481e-03, -1.9165e-02,  4.5494e-08, -9.9837e-09,\n",
      "         5.4158e-02,  4.9090e-08, -9.9834e-02,  1.4886e-02, -5.2581e-03,\n",
      "         1.5350e-01,  1.3733e-01,  1.5282e-01, -1.1070e-01, -2.4991e-02,\n",
      "        -1.3536e-03,  1.9711e-01,  2.4087e-01, -8.7206e-02,  1.2194e-02,\n",
      "         1.4073e-01,  1.2065e-07, -9.7920e-02,  2.7069e-04, -1.2360e-01,\n",
      "         9.1955e-05,  1.4323e-01, -1.2500e-07, -6.1352e-02,  3.6195e-02,\n",
      "        -3.7357e-08,  2.1620e-02,  7.1211e-02, -6.9517e-02])\n",
      "tensor([[[-0.0306,  0.0694,  0.0560],\n",
      "         [-0.0008, -0.0033, -0.0625],\n",
      "         [-0.0475, -0.0560,  0.0142],\n",
      "         ...,\n",
      "         [ 0.0610, -0.0356, -0.0758],\n",
      "         [ 0.0187,  0.0189,  0.0571],\n",
      "         [-0.0272,  0.0602, -0.0542]],\n",
      "\n",
      "        [[ 0.0258,  0.0369,  0.0486],\n",
      "         [-0.0788, -0.0943, -0.0023],\n",
      "         [ 0.0582, -0.0247,  0.0399],\n",
      "         ...,\n",
      "         [ 0.0021, -0.0050, -0.0269],\n",
      "         [ 0.0657,  0.0356,  0.0003],\n",
      "         [ 0.0309,  0.0450,  0.0488]],\n",
      "\n",
      "        [[ 0.0681,  0.0531, -0.0539],\n",
      "         [ 0.0644, -0.0314,  0.0012],\n",
      "         [-0.0553,  0.0552,  0.0153],\n",
      "         ...,\n",
      "         [ 0.0237,  0.0068, -0.0226],\n",
      "         [ 0.0057, -0.0089,  0.0612],\n",
      "         [ 0.0066,  0.0190,  0.0085]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0841,  0.0518, -0.0290],\n",
      "         [ 0.0180,  0.0400, -0.0661],\n",
      "         [-0.0404,  0.0675, -0.0318],\n",
      "         ...,\n",
      "         [-0.0588,  0.0080, -0.0573],\n",
      "         [-0.0302,  0.0101,  0.0746],\n",
      "         [ 0.0500,  0.0386, -0.0214]],\n",
      "\n",
      "        [[ 0.0687, -0.0262, -0.0339],\n",
      "         [-0.0370,  0.0617, -0.0331],\n",
      "         [ 0.0635,  0.0086,  0.0597],\n",
      "         ...,\n",
      "         [ 0.0229,  0.0264,  0.0538],\n",
      "         [ 0.0290, -0.0570,  0.0562],\n",
      "         [-0.0213, -0.0451,  0.0431]],\n",
      "\n",
      "        [[ 0.0527,  0.0372, -0.0126],\n",
      "         [-0.0718,  0.0190, -0.0846],\n",
      "         [ 0.0651,  0.0491,  0.0345],\n",
      "         ...,\n",
      "         [ 0.0192, -0.0456, -0.0341],\n",
      "         [ 0.0120,  0.0016,  0.0547],\n",
      "         [-0.0521,  0.0465, -0.0346]]])\n",
      "tensor([ 7.7777e-01,  9.3618e-01,  7.0060e-01,  8.5798e-01,  3.7753e-01,\n",
      "         4.1665e-01,  6.8791e-03,  8.0000e-01,  8.8870e-01,  2.4777e-01,\n",
      "         8.8970e-01, -9.6660e-04, -1.7244e-02,  8.7116e-01,  2.2395e-01,\n",
      "         4.5609e-01,  6.6936e-01,  2.4918e-01,  6.1630e-01,  4.5354e-02,\n",
      "         5.6505e-01,  7.8711e-01,  7.3299e-01,  7.7272e-01,  8.3114e-01,\n",
      "         1.1113e+00,  5.8826e-01,  7.4593e-01,  3.2299e-02,  1.0677e+00,\n",
      "         4.0733e-01, -1.1737e-01,  8.3216e-01,  2.5569e-01,  1.7827e-01,\n",
      "         7.2715e-01,  7.4456e-01,  3.3612e-01,  2.8098e-01,  4.5528e-02,\n",
      "         2.7313e-01,  6.6291e-01,  1.0093e+00,  2.1921e-01,  1.0282e+00,\n",
      "        -5.4320e-03,  3.9736e-02,  6.6120e-01,  8.4302e-01,  3.4145e-01,\n",
      "         6.1743e-01,  6.4617e-01,  6.5607e-01,  2.6764e-01,  8.2607e-01,\n",
      "         7.9290e-01,  7.7288e-01,  2.8403e-01,  1.3668e-01,  4.1057e-01,\n",
      "         2.5374e-01,  9.7702e-01,  1.8925e-01,  6.7830e-01,  5.0989e-01,\n",
      "         7.6032e-01,  1.8006e-01,  6.7862e-01,  6.5697e-02,  8.4843e-01,\n",
      "         7.6818e-01,  5.4117e-01,  3.2003e-01,  5.1525e-01,  3.8431e-01,\n",
      "         4.3388e-01,  4.5083e-01,  5.5123e-01,  6.9121e-01,  5.9249e-01,\n",
      "         8.8161e-01,  1.0056e+00,  1.0320e+00,  3.1076e-01, -1.8590e-02,\n",
      "         8.6550e-01,  1.4709e-01,  7.2441e-01,  5.9925e-01,  6.9120e-01,\n",
      "         3.4076e-01,  7.0158e-01,  1.1414e+00,  2.3622e-02,  9.4063e-01,\n",
      "         7.6738e-01,  1.7565e-01,  6.4312e-01, -6.9999e-03,  6.8726e-01,\n",
      "         7.2212e-01,  6.5477e-01, -1.7812e-02, -3.1956e-02,  3.9755e-01,\n",
      "         6.7820e-01,  6.1576e-01,  7.8861e-01,  5.3489e-01,  6.1871e-01,\n",
      "         3.2068e-01,  7.8874e-01,  2.4829e-01,  5.5715e-01,  6.5295e-01,\n",
      "         1.4705e-01,  9.3777e-01,  5.1765e-02,  3.1317e-01,  9.3940e-01,\n",
      "         4.3958e-01,  5.6364e-01,  2.1717e-01, -7.2823e-02,  3.6504e-01,\n",
      "         6.4697e-01,  6.0140e-01,  7.8794e-01])\n",
      "tensor([ 1.5323e-01,  2.1738e-02,  8.7334e-03,  1.3448e-01,  9.9623e-09,\n",
      "        -1.8743e-08,  3.0225e-08,  1.0197e-02, -3.8564e-02, -3.1533e-09,\n",
      "         3.8816e-02,  2.4496e-08, -1.6300e-08, -6.3099e-02,  1.0691e-08,\n",
      "         3.8132e-02,  4.0533e-02, -4.1374e-09, -2.3050e-02,  6.9710e-09,\n",
      "         4.8267e-04, -3.1849e-02,  8.8291e-02, -8.2372e-02,  5.8182e-03,\n",
      "         3.3939e-03, -3.0704e-02, -5.3132e-02, -2.2136e-08, -3.5397e-02,\n",
      "        -2.6850e-08,  1.7013e-08,  4.3742e-02, -1.2350e-08, -1.5691e-09,\n",
      "         3.4729e-02,  3.2033e-02,  1.1853e-08,  5.7877e-09, -1.6888e-09,\n",
      "        -7.6505e-09, -3.9853e-02, -1.3574e-01,  5.2009e-09, -9.2945e-02,\n",
      "         9.7546e-09,  6.3372e-09, -6.9360e-02,  6.0264e-02, -6.6364e-03,\n",
      "         5.0980e-02, -5.0332e-03, -1.3181e-02,  3.0053e-09,  1.0490e-01,\n",
      "        -7.7671e-02, -1.6395e-02,  7.9023e-09, -1.0138e-08, -2.2540e-08,\n",
      "        -1.7113e-08,  1.1018e-01,  1.2155e-08,  2.0783e-02,  1.0598e-08,\n",
      "         4.2127e-02, -2.5513e-09, -1.6892e-02, -1.1166e-08,  1.2845e-02,\n",
      "        -5.7266e-02,  4.1186e-03,  3.5461e-02, -1.2601e-08, -2.9001e-08,\n",
      "         4.1047e-03, -3.5762e-04, -4.1216e-03, -1.7734e-02, -4.4624e-02,\n",
      "        -1.9290e-02, -1.4382e-01,  1.6176e-03,  5.3688e-09, -9.5655e-09,\n",
      "        -5.0599e-02, -7.6661e-09,  4.4603e-02, -5.2454e-03, -1.8244e-03,\n",
      "         2.9297e-10, -4.1232e-02,  1.8218e-01, -2.1365e-09,  2.1413e-02,\n",
      "         1.3059e-02, -3.9120e-10,  4.9358e-02, -2.3906e-09, -4.3474e-03,\n",
      "        -1.8328e-02,  8.1601e-03,  9.5555e-09, -2.0145e-09,  2.8234e-08,\n",
      "         2.4283e-02, -2.0697e-02, -5.7809e-02,  6.5091e-09, -2.4507e-02,\n",
      "        -7.6437e-09, -8.7199e-02,  9.1918e-09, -2.8207e-03, -5.5451e-02,\n",
      "         6.2424e-09,  1.9945e-01, -3.4947e-08, -3.0327e-10, -5.5651e-02,\n",
      "         1.2107e-08, -3.3832e-02,  9.6072e-09, -2.4306e-09,  1.5264e-08,\n",
      "         1.3748e-02, -4.8579e-04,  1.8063e-02])\n",
      "tensor([[ 2.9551e-02, -7.2062e-03,  7.2162e-02,  ..., -4.3352e-02,\n",
      "         -3.8591e-02, -2.8161e-02],\n",
      "        [ 1.9337e-02,  5.3529e-02,  6.3475e-02,  ...,  1.0917e-02,\n",
      "          1.9347e-02,  2.7778e-02],\n",
      "        [ 3.5793e-03,  3.0430e-02,  2.7088e-02,  ...,  5.2701e-02,\n",
      "          5.5873e-02, -6.2073e-03],\n",
      "        ...,\n",
      "        [ 1.6399e-02,  3.5601e-05,  1.5477e-02,  ..., -7.9455e-02,\n",
      "         -3.3945e-02,  1.5089e-02],\n",
      "        [ 1.2484e-02, -4.4670e-02,  3.9056e-02,  ...,  2.3847e-02,\n",
      "         -4.9671e-02, -3.6577e-02],\n",
      "        [ 1.6561e-02,  4.7503e-02,  4.8830e-02,  ...,  2.7202e-02,\n",
      "          5.8513e-02,  3.6944e-02]])\n",
      "tensor([ 2.2560e-01,  3.7280e-01,  2.7660e-01,  1.6638e-01,  9.5067e-01,\n",
      "         8.1255e-01,  2.0576e-01,  1.9673e-01,  1.5563e-01,  4.2878e-01,\n",
      "         8.8257e-01,  9.9013e-01,  4.3946e-01,  9.8031e-02,  3.0946e-01,\n",
      "        -2.0191e-02,  1.0191e-01,  4.5421e-01,  6.0305e-01,  8.5502e-01,\n",
      "         5.7326e-01,  5.6225e-01, -6.3843e-03,  7.0847e-02,  2.3426e-01,\n",
      "         9.6105e-01,  7.6256e-01,  6.7588e-01, -1.3082e-02,  9.8842e-01,\n",
      "         3.5486e-01,  9.0037e-01,  1.0550e-01,  5.6716e-01,  7.0811e-01,\n",
      "         9.6865e-01,  1.8543e-01,  1.0016e+00,  1.1720e-01,  9.2547e-01,\n",
      "         9.4880e-01,  7.0114e-01,  2.1375e-02,  1.0200e+00,  1.5809e-01,\n",
      "         3.8617e-01,  2.2563e-02,  5.9367e-01,  5.9061e-01,  5.7404e-01,\n",
      "         5.5779e-01,  4.9744e-01,  7.8645e-04,  3.0027e-01,  4.3731e-01,\n",
      "         5.6754e-01,  1.7602e-02,  8.9251e-01,  1.0014e+00,  5.4094e-01,\n",
      "         1.8976e-01,  1.0313e-01,  9.5140e-01,  7.5708e-01,  5.1073e-01,\n",
      "         8.1117e-01,  1.0014e+00,  7.9937e-01,  1.2531e-02,  7.0822e-01,\n",
      "         9.7956e-01,  2.0068e-01,  7.0175e-02,  5.2422e-01,  9.8618e-01,\n",
      "         2.2915e-01,  7.3182e-01,  4.6926e-01,  9.9604e-01,  1.0503e-01,\n",
      "        -6.8362e-03,  1.4931e-01,  9.4260e-01,  1.6187e-02,  2.6813e-01,\n",
      "         6.7764e-01,  3.9956e-02,  3.4503e-01,  1.4943e-03,  7.8811e-01,\n",
      "         2.4287e-01,  5.2382e-01,  1.4765e-02,  5.5071e-01,  7.8524e-01,\n",
      "        -1.4720e-02,  3.0445e-01,  2.9112e-01,  8.2184e-01,  2.8122e-01,\n",
      "         1.4399e-02,  4.3449e-01,  2.9215e-01,  2.6993e-02,  9.3616e-01,\n",
      "         8.7823e-01,  5.4757e-01,  1.5800e-01,  3.1028e-01,  5.3892e-01,\n",
      "        -3.0567e-03,  3.3680e-01,  3.5858e-02,  1.3138e-01,  3.8594e-01,\n",
      "         5.8376e-01,  5.5838e-01,  5.0528e-01,  9.3300e-01,  9.4326e-01,\n",
      "         2.1667e-01,  4.3814e-01,  7.3435e-01,  2.7022e-02,  2.4846e-02,\n",
      "         5.9274e-01,  5.0147e-01,  3.4394e-01])\n",
      "tensor([ 1.0917e-02, -2.3289e-02,  4.9429e-02,  2.6275e-02, -4.9457e-02,\n",
      "        -4.8949e-02, -4.8949e-02, -5.0020e-02,  3.5808e-09, -2.3997e-02,\n",
      "         2.0876e-02,  1.4601e-02, -6.0453e-03,  9.9643e-03,  1.6122e-03,\n",
      "        -2.3289e-02, -3.8931e-02, -3.5808e-09, -1.8222e-03,  6.6743e-04,\n",
      "         3.5808e-09,  2.3289e-02, -2.3684e-02,  4.5828e-02, -4.7982e-02,\n",
      "        -4.1756e-02, -2.5660e-02,  2.5660e-02,  9.7832e-03, -1.1678e-02,\n",
      "         4.8949e-02,  2.5464e-02,  6.0569e-03,  3.5808e-09,  7.5715e-03,\n",
      "         3.5808e-09,  3.5808e-09, -4.1215e-03, -1.4720e-02, -2.3289e-02,\n",
      "        -4.6009e-02, -1.8181e-02, -1.8929e-02,  1.7177e-02, -2.5660e-02,\n",
      "        -4.8949e-02,  2.5441e-02, -2.6732e-02, -2.3289e-02, -6.6259e-05,\n",
      "         3.6441e-03,  2.3289e-02, -7.7058e-04, -2.3289e-02, -2.1475e-02,\n",
      "        -2.2682e-02, -2.5660e-02, -3.8767e-03,  4.7958e-04, -2.5660e-02,\n",
      "        -2.3289e-02,  1.2985e-02,  1.0836e-02,  2.0677e-02, -4.2764e-03,\n",
      "        -2.3428e-02, -8.2718e-04, -4.8949e-02,  6.2035e-03, -3.5808e-09,\n",
      "        -2.2034e-02, -4.7687e-02, -4.9682e-02, -3.5808e-09, -1.6235e-02,\n",
      "         2.3289e-02,  2.1229e-02,  2.5122e-02,  4.6051e-03, -2.5660e-02,\n",
      "        -4.6416e-02,  3.5808e-09,  2.3289e-02, -1.3180e-02,  2.2794e-02,\n",
      "         4.8583e-02, -2.6199e-02, -1.9233e-02, -3.5808e-09, -2.0520e-03,\n",
      "        -4.8370e-03,  3.8566e-02, -4.8949e-02, -2.5435e-02,  4.7601e-02,\n",
      "         4.8949e-02,  5.7969e-03,  4.8949e-02,  2.5660e-02, -2.5031e-02,\n",
      "         3.9592e-03, -2.3289e-02, -3.0920e-02, -2.4825e-02,  2.0359e-03,\n",
      "         1.9006e-02, -3.5808e-09,  3.3724e-02, -1.8638e-02,  2.4171e-02,\n",
      "        -2.2564e-03,  3.5808e-09,  1.5985e-02, -4.8949e-02, -4.8949e-02,\n",
      "         2.2331e-02, -2.5660e-02,  2.3289e-02, -2.3289e-02,  3.5808e-09,\n",
      "        -2.5660e-02, -4.5987e-02,  4.6516e-02,  2.6752e-02, -2.3014e-02,\n",
      "        -2.1958e-02,  4.8949e-02, -5.4841e-02])\n",
      "tensor([[-0.0195,  0.0758,  0.0746, -0.0617, -0.0973, -0.1069, -0.0539, -0.0092,\n",
      "         -0.1280, -0.0508, -0.0595,  0.0731, -0.0426, -0.0083,  0.1263,  0.0213,\n",
      "          0.0258,  0.0728, -0.0301,  0.1363, -0.0513, -0.0759, -0.0114,  0.0099,\n",
      "         -0.0272, -0.0632, -0.0489,  0.0814,  0.0052, -0.0541,  0.0461,  0.1121,\n",
      "          0.0042, -0.0145, -0.0047, -0.0294, -0.0091,  0.0933, -0.0138,  0.0997,\n",
      "         -0.0193,  0.0993, -0.0227, -0.1475, -0.0350, -0.0369, -0.0862, -0.0535,\n",
      "          0.1002, -0.0219,  0.1080, -0.1028, -0.0051,  0.0331, -0.0267,  0.1705,\n",
      "         -0.0287,  0.0520,  0.1104, -0.0630,  0.0931, -0.0504,  0.0059, -0.1622,\n",
      "         -0.0584,  0.1188, -0.1282, -0.0606, -0.0065,  0.0760, -0.1221, -0.0963,\n",
      "         -0.0046,  0.0885, -0.0828, -0.0563, -0.1514,  0.0360,  0.0411, -0.0790,\n",
      "         -0.0531, -0.1126, -0.0785,  0.0797,  0.0504,  0.0664,  0.0414,  0.1550,\n",
      "          0.0728,  0.0528, -0.0047, -0.0262, -0.0738, -0.0741,  0.0670,  0.0638,\n",
      "          0.1110,  0.0906,  0.0997,  0.0153, -0.0050,  0.1226,  0.0137, -0.0372,\n",
      "         -0.0990, -0.0985,  0.0863,  0.0740,  0.0174, -0.0904,  0.0108, -0.1338,\n",
      "         -0.1159, -0.0385, -0.0413,  0.0523, -0.0134, -0.0580,  0.0830, -0.0589,\n",
      "         -0.0493, -0.0272,  0.0344,  0.0324, -0.0652,  0.0826,  0.0109, -0.0889],\n",
      "        [-0.0796, -0.0530, -0.0061,  0.0524, -0.0755, -0.0876, -0.0832, -0.0803,\n",
      "         -0.0497,  0.0419,  0.0544, -0.0749,  0.0795, -0.0494, -0.0758, -0.0396,\n",
      "         -0.0927,  0.0865, -0.0171, -0.0044, -0.0420,  0.1279,  0.0835,  0.0560,\n",
      "         -0.0755, -0.0923,  0.0786, -0.1256, -0.0412,  0.1150,  0.0848, -0.0726,\n",
      "         -0.0057, -0.1115,  0.1279, -0.0133, -0.0548, -0.0994,  0.0736, -0.1211,\n",
      "         -0.0876, -0.1717,  0.0748, -0.1058,  0.0367, -0.0744,  0.0059,  0.0405,\n",
      "         -0.1077, -0.0583,  0.0258,  0.1323, -0.0458, -0.0647,  0.0148, -0.0851,\n",
      "          0.0184, -0.0106, -0.1150,  0.1392, -0.0728,  0.0187, -0.1448,  0.1090,\n",
      "         -0.0078, -0.0928, -0.0895, -0.0257, -0.0777,  0.1495, -0.0359, -0.0214,\n",
      "         -0.0566,  0.0688, -0.0994,  0.0863,  0.0903, -0.0313, -0.0228,  0.0314,\n",
      "         -0.0478, -0.0934,  0.0859, -0.0046, -0.1185,  0.0369, -0.0384, -0.0689,\n",
      "          0.0279,  0.0707,  0.0857,  0.0723, -0.0258,  0.1345,  0.0689,  0.0607,\n",
      "         -0.0108,  0.0171, -0.0883,  0.0070,  0.0637, -0.0932, -0.1402,  0.0744,\n",
      "          0.0596,  0.0730,  0.0878,  0.0049, -0.0082,  0.1723,  0.0484, -0.0340,\n",
      "          0.0129, -0.0703, -0.0923, -0.0631,  0.0194,  0.0776, -0.1268, -0.0311,\n",
      "          0.0071, -0.0841,  0.0718,  0.0059, -0.0099, -0.0537,  0.0952, -0.0122],\n",
      "        [-0.0048,  0.0705, -0.1027, -0.0206,  0.1175,  0.0454,  0.0150,  0.0625,\n",
      "         -0.0755,  0.0328, -0.0551, -0.1270, -0.0051, -0.1176, -0.0140,  0.0588,\n",
      "          0.0607,  0.0276, -0.1007,  0.0228, -0.1227, -0.1158,  0.0240, -0.0133,\n",
      "          0.0951,  0.0601,  0.0387, -0.0465, -0.0804,  0.0395, -0.0541, -0.0438,\n",
      "         -0.0484, -0.0651,  0.0100, -0.1371, -0.0351,  0.0767, -0.0108,  0.0566,\n",
      "          0.0949,  0.0598, -0.0137,  0.1397,  0.0302,  0.0419, -0.0191,  0.0663,\n",
      "          0.0982, -0.0762,  0.0047, -0.0718, -0.0161,  0.1215,  0.0371,  0.0331,\n",
      "          0.0434,  0.1109, -0.0452,  0.0053,  0.0167,  0.0069, -0.0859, -0.0461,\n",
      "         -0.0790,  0.0256,  0.1060,  0.0673,  0.0092,  0.0100,  0.0800,  0.0502,\n",
      "          0.0223,  0.0402,  0.0580, -0.0342, -0.0631, -0.0921,  0.0967,  0.0343,\n",
      "          0.0473, -0.0226, -0.0695,  0.0368,  0.0044, -0.0883,  0.0691, -0.0083,\n",
      "          0.0898,  0.0410,  0.0969, -0.0258,  0.0825,  0.0691, -0.0721, -0.0821,\n",
      "         -0.0135, -0.0141, -0.0512,  0.0231,  0.0343,  0.0964,  0.0123, -0.0039,\n",
      "          0.0123, -0.0513,  0.0213, -0.0207, -0.0140, -0.1060,  0.0979, -0.0778,\n",
      "          0.0103,  0.0386,  0.0317, -0.0932,  0.0755, -0.0310,  0.0881, -0.0622,\n",
      "          0.0603,  0.0358, -0.0377, -0.0603, -0.0217,  0.1284, -0.0634,  0.0545]])\n"
     ]
    }
   ],
   "source": [
    "# print the model weights for reference if needed\n",
    "for param in cnv_software_model.parameters():\n",
    "    print(param.data)\n",
    "    \n",
    "for param in cnv_hardware_model.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.04019617 0.21984415 0.73995968] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.06227948 0.03832725 0.89939327] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.06227948 0.03832725 0.89939327] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.06227948 0.03832725 0.89939327] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0772543  0.04754288 0.87520282] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.10814792 0.13785955 0.75399253] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.04008187 0.0193505  0.94056763] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.04952166 0.0388487  0.91162964] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.07982323 0.21076757 0.70940919] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.012187   0.02524369 0.96256931] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.04019617 0.21984415 0.73995968] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.07439843 0.51869563 0.40690594] prediction 1 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.10814792 0.13785955 0.75399253] prediction 2 target 2.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.16460862 0.12913203 0.70625934] prediction 2 target 2.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.99050105 0.00474948 0.00474948] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.09521399 0.0585954  0.8461906 ] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.09370552 0.07351002 0.83278446] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.09370552 0.07351002 0.83278446] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.01855376 0.07960563 0.90184061] prediction 2 target 2.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.00715239 0.27272821 0.7201194 ] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.04390868 0.14778943 0.8083019 ] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.0376825  0.07805409 0.8842634 ] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0772543  0.04754288 0.87520282] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.2285312  0.76919898 0.00226982] prediction 1 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.07439843 0.51869563 0.40690594] prediction 1 target 2.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.99050105 0.00474948 0.00474948] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0376825  0.07805409 0.8842634 ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.059823   0.07625825 0.86391875] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.01815667 0.09930397 0.88253936] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.99050105 0.00474948 0.00474948] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.99050105 0.00474948 0.00474948] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.10814792 0.13785955 0.75399253] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.02453625 0.03986992 0.93559383] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.05317145 0.1789664  0.76786214] prediction 2 target 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.05181155 0.36122299 0.58696546] prediction 2 target 2.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.02980318 0.07869318 0.89150364] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.96873081 0.01563459 0.0156346 ] prediction 0 target 0.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02453625 0.03986993 0.93559382] prediction 2 target 2.0\n",
      "[0.06227948 0.03832725 0.89939327] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.10814792 0.13785955 0.75399253] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.07439843 0.51869563 0.40690594] prediction 1 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.07439843 0.51869563 0.40690594] prediction 1 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.20624465 0.69418573 0.09956962] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.03477452 0.14920135 0.81602414] prediction 2 target 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.05317145 0.1789664  0.76786214] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02453625 0.03986992 0.93559383] prediction 2 target 2.0\n",
      "[0.05710172 0.11827828 0.82462   ] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.16460862 0.12913203 0.70625934] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.059823   0.07625825 0.86391875] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02474891 0.03154821 0.94370288] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02453625 0.03986993 0.93559382] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.1810411  0.04219544 0.77676346] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.01346084 0.15249595 0.83404321] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.03926781 0.92146438 0.03926781] prediction 1 target 1.0\n",
      "[0.0376825  0.07805409 0.8842634 ] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n",
      "[0.9527716  0.03185137 0.01537703] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.05530462 0.14602789 0.79866749] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.06082264 0.06082265 0.87835471] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.06082263 0.06082264 0.87835474] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.0772543  0.04754287 0.87520284] prediction 2 target 2.0\n",
      "[0.95529366 0.01965346 0.02505288] prediction 0 target 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.98465588 0.00767206 0.00767206] prediction 0 target 0.0\n",
      "[0.02082538 0.18508037 0.79409426] prediction 2 target 2.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.90546133 0.0799252  0.01461347] prediction 0 target 0.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.0585954  0.09521399 0.84619061] prediction 2 target 2.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.02453625 0.03986992 0.93559383] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "[0.94450663 0.01524364 0.04024974] prediction 0 target 0.0\n",
      "[0.03884871 0.04952165 0.91162964] prediction 2 target 2.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.9703976 0.0199642 0.0096382] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.02393976 0.06321124 0.912849  ] prediction 2 target 2.0\n",
      "[0.0772543  0.04754288 0.87520282] prediction 2 target 2.0\n",
      "[0.14602789 0.05530461 0.7986675 ] prediction 2 target 2.0\n",
      "[0.9799574  0.01240715 0.00763545] prediction 0 target 0.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.20075309 0.67570194 0.12354497] prediction 1 target 1.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.89090596 0.10024537 0.00884867] prediction 0 target 0.0\n",
      "[0.1850804  0.79409422 0.02082538] prediction 1 target 1.0\n",
      "[0.0392678  0.92146439 0.0392678 ] prediction 1 target 1.0\n",
      "[0.02353112 0.07920189 0.89726699] prediction 2 target 2.0\n",
      "[0.96783486 0.01225367 0.01991147] prediction 0 target 0.0\n",
      "[0.14114946 0.7719861  0.08686444] prediction 1 target 1.0\n",
      "number of inputs of each class [342, 341, 217]\n",
      "correctly predicted [341, 341, 213]\n",
      "correctly predicted class 1 at 99.708\n",
      "correctly predicted class 2 at 100.000\n",
      "correctly predicted class 3 at 98.157\n",
      "accuracy at 99.444\n"
     ]
    }
   ],
   "source": [
    "# test through both models\n",
    "def test_on_everything_split(print_output):\n",
    "\n",
    "    list_input_train_total = [0, 0, 0]\n",
    "    list_input_train_correct_total = [0, 0, 0]\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        (input, target) = data\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        software_output = cnv_software_model(input)\n",
    "        output = cnv_hardware_model(software_output)\n",
    "        #print(target, output)\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            if print_output:\n",
    "                print(softmax(output[i].tolist()), \"prediction\", get_prediction(output[i]), \"target\", target[i].tolist())\n",
    "\n",
    "            list_input_train_total[int(target[i].tolist())] += 1\n",
    "\n",
    "            if int(target[i].tolist()) == get_prediction(output[i]):\n",
    "                list_input_train_correct_total[int(target[i].tolist())] += 1\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        (input, target) = data\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        software_output = cnv_software_model(input)\n",
    "        output = cnv_hardware_model(software_output)\n",
    "        \n",
    "        for i in range(len(output)):\n",
    "            if print_output:\n",
    "                print(softmax(output[i].tolist()), \"prediction\", get_prediction(output[i]), \"target\", target[i].tolist())\n",
    "\n",
    "            list_input_train_total[int(target[i].tolist())] += 1\n",
    "\n",
    "            if int(target[i].tolist()) == get_prediction(output[i]):\n",
    "                list_input_train_correct_total[int(target[i].tolist())] += 1    \n",
    "\n",
    "    print(\"number of inputs of each class\", list_input_train_total)\n",
    "    print(\"correctly predicted\", list_input_train_correct_total)\n",
    "\n",
    "    running_total = 0\n",
    "    running_total_correct = 0\n",
    "    for i in range(len(list_input_train_total)):\n",
    "        print(\"correctly predicted class %d at %.3f\" % ((i + 1), (list_input_train_correct_total[i] * 100 / list_input_train_total[i])))\n",
    "        running_total += list_input_train_total[i]\n",
    "        running_total_correct += list_input_train_correct_total[i]\n",
    "    \n",
    "    print(\"accuracy at %.3f\" % ((running_total_correct * 100 / running_total)))\n",
    "    \n",
    "test_on_everything_split(print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV_hardware(\n",
      "  (linear_features): ModuleList(\n",
      "    (0): QuantLinear(\n",
      "      in_features=256, out_features=128, bias=False\n",
      "      (weight_reg): WeightReg()\n",
      "      (weight_quant): WeightQuantProxy(\n",
      "        (tensor_quant): BinaryQuant(\n",
      "          (scaling_impl): ParameterStatsScaling(\n",
      "            (parameter_list_stats): ParameterListStats(\n",
      "              (first_tracked_param): _ViewParameterWrapper()\n",
      "              (stats): Stats(\n",
      "                (stats_impl): AbsAve()\n",
      "              )\n",
      "            )\n",
      "            (stats_scaling_impl): StatsScaling(\n",
      "              (affine_rescaling): Identity()\n",
      "              (restrict_scaling): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "              (restrict_scaling_preprocess): LogTwo()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bias_quant): BiasQuantProxy()\n",
      "    )\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): QuantHardTanh(\n",
      "      (act_quant_proxy): ActivationQuantProxy(\n",
      "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "          (activation_impl): Identity()\n",
      "          (tensor_quant): ClampedBinaryQuant(\n",
      "            (scaling_impl): StandaloneScaling(\n",
      "              (restrict_value): RestrictValue(\n",
      "                (forward_impl): Sequential(\n",
      "                  (0): PowerOfTwo()\n",
      "                  (1): ClampMin()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): QuantLinear(\n",
      "    in_features=128, out_features=3, bias=False\n",
      "    (weight_reg): WeightReg()\n",
      "    (weight_quant): WeightQuantProxy(\n",
      "      (tensor_quant): BinaryQuant(\n",
      "        (scaling_impl): ParameterStatsScaling(\n",
      "          (parameter_list_stats): ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper()\n",
      "            (stats): Stats(\n",
      "              (stats_impl): AbsAve()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_scaling): RestrictValue(\n",
      "              (forward_impl): Sequential(\n",
      "                (0): PowerOfTwo()\n",
      "                (1): ClampMin()\n",
      "              )\n",
      "            )\n",
      "            (restrict_scaling_preprocess): LogTwo()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxy()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# export the trained hardware model to ONNX to synthesize\n",
    "INPUT_SPECIFICATIONS_HARDWARE = (1, 256) # batch size, length\n",
    "bo.export_finn_onnx(cnv_hardware_model, INPUT_SPECIFICATIONS_HARDWARE, build_dir + file_name + \".onnx\")\n",
    "print(cnv_hardware_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Preparing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd0182b8320>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the onnx model made by brevitas\n",
    "model = ModelWrapper(build_dir + file_name + \".onnx\")\n",
    "showInNetron(build_dir + file_name + \".onnx\")\n",
    "\n",
    "# use http://localhost:8081/ since this is on Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd018308b00>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some transformations and then show on netron\n",
    "\n",
    "model = model.transform(DoubleToSingleFloat())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "#model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + file_name + \"_tidy.onnx\")\n",
    "\n",
    "showInNetron(build_dir + file_name + \"_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is exported, let's have a look at its layer structure with Netron. Remember that the visualization below is interactive, you can click on the individual nodes and view the layer attributes, trained weights and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the network is composed of a repeating convolution-convolution-maxpool layer pattern to extract features using 3x3 convolution kernels (with weights binarized) and `Sign` activations, followed by fully connected layers acting as the classifier. Also notice the initial `MultiThreshold` layer at the beginning of the network, which is quantizing float inputs to 8-bit ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How FINN Implements Convolutions: Lowering and Streamlining\n",
    "\n",
    "In FINN, we implement convolutions with the *lowering* approach: we convert them to matrix-matrix multiply operations, where one of the matrices is generated by sliding a window over the input image. You can read more about the sliding window operator and how convolution lowering works [in this notebook](https://github.com/maltanar/qnn-inference-examples/blob/master/3-convolutional-binarized-gtsrb.ipynb). The streaming dataflow architecture we will end up with is going to look something like this figure from the [FINN-R paper](https://arxiv.org/abs/1809.04570):\n",
    "\n",
    "![](cnv-mp-fc.png)\n",
    "\n",
    "Note how the convolution layer looks very similar to the fully connected one in terms of the matrix-vector-threshold unit (MVTU), but now the MVTU is preceded by a sliding window unit that produces the matrix from the input image. All of these building blocks, including the `MaxPool` layer you see in this figure, exist as templated Vivado HLS C++ functions in [finn-hlslib](https://github.com/Xilinx/finn-hlslib).\n",
    "\n",
    "\n",
    "To target this kind of hardware architecture with our network we'll apply a convolution lowering transformation, in addition to streamlining. You may recall the *streamlining transformation* that we applied to the TFC-w1a1 network, which is a series of mathematical simplifications that allow us to get rid of floating point scaling operations by implementing few-bit activations as thresholding operations. **The current implementation of streamlining is highly network-specific and may not work for your network if its topology is very different than the example network here. We hope to rectify this in future releases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd01818ff98>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + file_name + \"_tidy.onnx\")\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "\n",
    "model.save(build_dir + file_name + \"_streamlined.onnx\")\n",
    "showInNetron(build_dir + file_name + \"_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into too much detail about what happens in each transformation and why they are called in the particular order they are (feel free to visualize the intermediate steps using Netron yourself if you are curious) but here is a brief summmmary:\n",
    "\n",
    "* `Streamline` moves floating point scaling and addition operations closer to the input of the nearest thresholding activation and absorbs them into thresholds\n",
    "* `LowerConvsToMatMul` converts ONNX `Conv` nodes into sequences of `Im2Col, MatMul` nodes as discussed above. `Im2Col` is a custom FINN ONNX high-level node type that implements the sliding window operator.\n",
    "* `MakeMaxPoolNHWC` and `AbsorbTransposeIntoMultiThreshold` convert the *data layout* of the network into the NHWC data layout that finn-hlslib primitives use. NCHW means the tensor dimensions are ordered as `(N : batch, H : height, W : width, C : channels)` (assuming 2D images). The ONNX standard ops normally use the NCHW layout, but the ONNX intermediate representation itself does not dictate any data layout.\n",
    "* You may recall `ConvertBipolarMatMulToXnorPopcount` from the TFC-w1a1 example, which is needed to implement bipolar-by-bipolar (w1a1) networks correctly using finn-hlslib.\n",
    "\n",
    "Let's visualize the streamlined and lowered network with Netron. Observe how all the `Conv` nodes have turned into pairs of `Im2Col, MatMul` nodes, and many nodes including `BatchNorm, Mul, Add` nodes have disappeared and replaced with `MultiThreshold` nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Partitioning, Conversion to HLS Layers and Folding\n",
    "\n",
    "The next steps will be (again) very similar to what we did for the TFC-w1a1 network. We'll first convert the layers that we can put into the FPGA into their HLS equivalents and separate them out into a *dataflow partition*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd01832ee10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import MoveReshape\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_streamlined.onnx\")\n",
    "model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "\n",
    "# get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(MoveReshape())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + file_name + \"_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(build_dir + file_name + \"_dataflow_model.onnx\")\n",
    "showInNetron(build_dir + file_name + \"_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the maxpoolnhwc can be made into streamingmaxpool_batch nodes\n",
    "# basically, the input dimension into the maxpool node must be divisible by the maxpool kernel size\n",
    "# if this is not fulfilled, then the dataflowmodel will be broken up into several pieces\n",
    "# if done correctly, the dataflowmodel should be one linear model\n",
    "# this is commented out by default\n",
    "\n",
    "class InferStreamingMaxPool_test(Transformation):\n",
    "    \"\"\"Convert MaxPoolNHWC layers to StreamingMaxPool layers.\"\"\"\n",
    "\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        node_ind = 0\n",
    "        graph_modified = False\n",
    "        for n in graph.node:\n",
    "            node_ind += 1\n",
    "            if n.op_type == \"MaxPoolNHWC\":\n",
    "                mp_input = n.input[0]\n",
    "                mp_output = n.output[0]\n",
    "                mp_in_shape = model.get_tensor_shape(mp_input)\n",
    "                # mp_out_shape = model.get_tensor_shape(mp_output)\n",
    "                dt = model.get_tensor_datatype(mp_input)\n",
    "                mp_inst = getCustomOp(n)\n",
    "                # stride = mp_inst.get_nodeattr(\"strides\")[0]\n",
    "                k = mp_inst.get_nodeattr(\"kernel_shape\")[0]\n",
    "                # pad = mp_inst.get_nodeattr(\"pads\")[0]\n",
    "                ifm_ch = mp_in_shape[-1]\n",
    "                ifm_dim = mp_in_shape[1]\n",
    "                # ofm_dim = mp_out_shape[1]\n",
    "                print(ifm_dim)\n",
    "                print(k)\n",
    "                if ifm_dim % k == 0:\n",
    "                    print(\"setting\")\n",
    "                    # create equivalent StreamingMaxPool_Batch node\n",
    "                    # TODO support non-k strides\n",
    "                    new_node = helper.make_node(\n",
    "                        \"StreamingMaxPool_Batch\",\n",
    "                        [mp_input],\n",
    "                        [mp_output],\n",
    "                        domain=\"finn\",\n",
    "                        backend=\"fpgadataflow\",\n",
    "                        PoolDim=k,\n",
    "                        NumChannels=ifm_ch,\n",
    "                        ImgDim=ifm_dim,\n",
    "                        dataType=dt.name,\n",
    "                    )\n",
    "                    graph.node.insert(node_ind, new_node)\n",
    "                    # remove old nodes\n",
    "                    graph.node.remove(n)\n",
    "                    graph_modified = True\n",
    "        if graph_modified:\n",
    "            model = model.transform(InferShapes())\n",
    "            model = model.transform(InferDataTypes())\n",
    "        return (model, graph_modified)\n",
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "#mem_mode = \"decoupled\"\n",
    "\n",
    "#model = ModelWrapper(build_dir + file_name + \"_streamlined.onnx\")\n",
    "#model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "#model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "#model = model.transform(to_hls.InferConvInpGen())\n",
    "#model = model.transform(InferStreamingMaxPool_test())\n",
    "#model.save(build_dir + file_name + \"_dataflow_model.onnx\")\n",
    "#showInNetron(build_dir + file_name + \"_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the additional `MoveReshape` transformation that was not used for TFC-w1a1. In the last Netron visualization you may have noticed a `Reshape` operation towards the end of the network where the convolutional part of the network ends and the fully-connected layers started. That `Reshape` is essentialy a tensor flattening operation, which we can remove for the purposes of hardware implementation. We can examine the contents of the dataflow partition with Netron, and observe the `ConvolutionInputGenerator`, `StreamingFCLayer_Batch` and `StreamingMaxPool_Batch` nodes that implement the sliding window, matrix multiply and maxpool operations in hlslib. *Note that the StreamingFCLayer instances following the ConvolutionInputGenerator nodes are really implementing the convolutions, despite the name. The final three StreamingFCLayer instances implement actual FC layers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to set the *folding factors* for certain layers to adjust the performance of our accelerator, similar to the TFC-w1a1 example. We'll also set the desired FIFO depths around those layers, which are important to achieve full throughput in the accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"MultiThreshold_0_out0\"\n",
      "input: \"XnorPopcountMatMul_0_param0\"\n",
      "output: \"XnorPopcountMatMul_0_out0\"\n",
      "op_type: \"StreamingFCLayer_Batch\"\n",
      "attribute {\n",
      "  name: \"ActVal\"\n",
      "  i: 0\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"MH\"\n",
      "  i: 3\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"MW\"\n",
      "  i: 128\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"PE\"\n",
      "  i: 3\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"SIMD\"\n",
      "  i: 32\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"backend\"\n",
      "  s: \"fpgadataflow\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"binaryXnorMode\"\n",
      "  i: 1\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"inputDataType\"\n",
      "  s: \"BINARY\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"mem_mode\"\n",
      "  s: \"decoupled\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"noActivation\"\n",
      "  i: 1\n",
      "  type: INT\n",
      "}\n",
      "attribute {\n",
      "  name: \"numInputVectors\"\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"outputDataType\"\n",
      "  s: \"UINT32\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"resType\"\n",
      "  s: \"ap_resource_lut()\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"weightDataType\"\n",
      "  s: \"BINARY\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"inFIFODepth\"\n",
      "  i: 128\n",
      "  type: INT\n",
      "}\n",
      "domain: \"finn\"\n",
      "\n",
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset_folded_intermediate.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd0180f8b70>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_tlastmarker import InsertTLastMarker\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_dataflow_model.onnx\")\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# each tuple is (PE, SIMD, in_fifo_depth) for a layer\n",
    "folding = [\n",
    "    (3, 32, 128),\n",
    "    (32, 8, 128),\n",
    "    (32, 8, 128),\n",
    "    (16, 2, 128),\n",
    "    (16, 8, 128),\n",
    "    (3, 8, 81)\n",
    "]\n",
    "\n",
    "for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififodepth)\n",
    "    print(fcl)\n",
    "\n",
    "# use same SIMD values for the sliding window operators\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    simd = folding[i][1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "\n",
    "# save intermediate so that we can reference in netron and debug if folding factors are not correct\n",
    "model.save(build_dir + file_name + \"_folded_intermediate.onnx\")\n",
    "showInNetron(build_dir + file_name + \"_folded_intermediate.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/notebooks/CNN/cnn_1d_3_classes_sample_dataset_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd01832e908>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the transformation\n",
    "model = ModelWrapper(build_dir + file_name + \"_folded_intermediate.onnx\")\n",
    "\n",
    "model = model.transform(InsertDWC())\n",
    "model = model.transform(InsertFIFO())\n",
    "model = model.transform(InsertTLastMarker())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "model.save(build_dir + file_name + \"_folded.onnx\")\n",
    "showInNetron(build_dir + file_name + \"_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualize in Netron to observe the `StreamingDataWidthConverter` and `StreamingFIFO` nodes that have been inserted into graph, as well as the folding factors in the `PE` and `SIMD` attributes of each `StreamingFCLayer_Batch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network is now ready and we can start with the hardware generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hardware Generation\n",
    "\n",
    "From this point onward, the steps we have to follow do not depend on the particular network and will be exactly the same as the TFC-w1a1 example. We first proceed with HLS synthesis, **which may take 10-20 minutes depending on your host computer and your RAM cause of WSL**.\n",
    "\n",
    "**Note: WSL takes 10GB of RAM to perform synthesis, else it crashes halfway.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0:02:54.420459\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.util.basic import pynq_part_map\n",
    "time = datetime.datetime.now()\n",
    "\n",
    "test_pynq_board = \"Ultra96\"\n",
    "test_fpga_part = pynq_part_map[test_pynq_board]\n",
    "target_clk_ns = 10\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_folded.onnx\")\n",
    "model = model.transform(PrepareIP(test_fpga_part, target_clk_ns))\n",
    "model = model.transform(HLSSynthIP())\n",
    "model.save(build_dir + file_name + \"_ipgen.onnx\")\n",
    "print(\"took\", datetime.datetime.now() - time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the HLS synthesis is complete, we can stitch together the generated IP blocks into a larger IP that is the implementation of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0:00:23.266048\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (\n",
    "    ReplaceVerilogRelPaths,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "time = datetime.datetime.now()\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_ipgen.onnx\")\n",
    "model = model.transform(ReplaceVerilogRelPaths())\n",
    "model = model.transform(CreateStitchedIP(test_fpga_part))\n",
    "model.save(build_dir + file_name + \"_ipstitch.onnx\")\n",
    "print(\"took\", datetime.datetime.now() - time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a PYNQ project that includes the hardware \"shell\" that will support our accelerator, including the data movers, and run Vivado synthesis, **which may take around 30 minutes depending on your host computer.**\n",
    "\n",
    "*If you'd like to watch the progress, you can open the generated project file (printed below) with the Vivado GUI.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivado synthesis project is at /tmp/finn_dev_dant/vivado_pynq_proj_ao46bxva/resizer.xpr\n",
      "took 0:00:26.588611\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_proj import MakePYNQProject\n",
    "from finn.transformation.fpgadataflow.synth_pynq_proj import SynthPYNQProject\n",
    "time = datetime.datetime.now()\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_ipstitch.onnx\")\n",
    "model = model.transform(MakePYNQProject(test_pynq_board))\n",
    "vivado_proj = model.get_metadata_prop(\"vivado_pynq_proj\")\n",
    "print(\"Vivado synthesis project is at %s/resizer.xpr\" % vivado_proj)\n",
    "model.save(build_dir + file_name + \"_pynqproj.onnx\")\n",
    "print(\"took\", datetime.datetime.now() - time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0:12:01.478193\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "model = ModelWrapper(build_dir + file_name + \"_pynqproj.onnx\")\n",
    "model = model.transform(SynthPYNQProject())\n",
    "model.save(build_dir + file_name + \"_synth.onnx\")\n",
    "print(\"took\", datetime.datetime.now() - time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deployment and Remote Execution\n",
    "\n",
    "Now that we're done with the hardware generation, we can generate a Python driver for accelerator and copy the necessary files onto our PYNQ board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "# FINN will use ssh to deploy and run the generated accelerator\n",
    "# please run ultra96_port_forwarding.ipynb before transferring\n",
    "ip = \"localhost\"\n",
    "port = \"3100\"\n",
    "username = \"xilinx\"\n",
    "password = \"xilinx\"\n",
    "target_dir = \"/home/xilinx/finn/cnv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + file_name + \"_synth.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy to the remote Ultra96\n",
    "model = model.transform(MakePYNQDriver())\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(build_dir + file_name + \"_pynq_deploy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xilinx/finn/cnv/pynq_deployment_51f6krls:\r\n",
      "total 5776\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6359 Oct 20 09:40 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Oct 20 09:40 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Oct 20 09:40 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329653 Oct 20 09:40 resizer.hwh\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_bjb6droj:\r\n",
      "total 5788\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6373 Oct 14 15:38 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Oct 14 15:38 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx     384 Oct 14 15:41 input.npy\r\n",
      "-rw-r--r-- 1 root   root        92 Oct 14 15:41 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Oct 14 15:38 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329650 Oct 14 15:38 resizer.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Oct 14 15:41 sds_trace_data.dat\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_i_uguh4y:\r\n",
      "total 5788\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6373 Oct 13 06:47 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Oct 13 06:47 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx     384 Oct 13 06:49 input.npy\r\n",
      "-rw-r--r-- 1 root   root        92 Oct 13 06:49 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Oct 13 06:47 resizer1.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329650 Oct 13 06:47 resizer1.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Oct 13 06:49 sds_trace_data.dat\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_m0276khc:\r\n",
      "total 5820\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6407 Sep 29 12:13 driver.py\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6409 Sep 29 17:03 driver.py.save\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Sep 29 04:13 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx   12416 Sep 29 12:52 input.npy\r\n",
      "-rw-r--r-- 1 root   root       120 Sep 29 12:52 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Sep 29 04:13 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329656 Sep 29 04:13 resizer.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Sep 29 15:09 sds_trace_data.dat\r\n",
      "-rw------- 1 xilinx xilinx    8845 Sep 29 15:07 test_driver.py\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_oa_v0uqz:\r\n",
      "total 5788\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6373 Oct 17 14:03 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Oct 17 14:03 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx     384 Oct 17 14:05 input.npy\r\n",
      "-rw-r--r-- 1 root   root        92 Oct 17 14:05 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Oct 17 14:03 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329650 Oct 17 14:03 resizer.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Oct 17 14:05 sds_trace_data.dat\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_vhs9bymj:\r\n",
      "total 5780\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6422 Sep 29 12:56 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Sep 29 12:55 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx     272 Sep 29 12:56 input.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Sep 29 12:55 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329650 Sep 29 12:55 resizer.hwh\r\n",
      "\r\n",
      "/home/xilinx/finn/cnv/pynq_deployment_yvlqa036:\r\n",
      "total 5788\r\n",
      "-rw-r--r-- 1 xilinx xilinx    6373 Sep 29 16:20 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Sep 29 16:20 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx     384 Sep 29 16:22 input.npy\r\n",
      "-rw-r--r-- 1 root   root       104 Sep 29 16:22 output.npy\r\n",
      "-rw-r--r-- 1 xilinx xilinx 5568787 Sep 29 16:20 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  329650 Sep 29 16:20 resizer.hwh\r\n",
      "-rw-r--r-- 1 root   root        32 Sep 29 16:22 sds_trace_data.dat\r\n"
     ]
    }
   ],
   "source": [
    "# verify that the files are copied over\n",
    "pynq_folder_name = vivado_proj[36:]\n",
    "#print(pynq_folder_name)\n",
    "! sshpass -p {password} ssh {username}@{ip} -p {port} 'ls -l {target_dir}/*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Dataset\n",
    "\n",
    "Load the testing data and do remote execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_model = ModelWrapper(build_dir + file_name + \"_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "sdp_node.set_nodeattr(\"model\", build_dir + file_name + \"_pynq_deploy.onnx\")\n",
    "parent_model.save(build_dir + file_name + \"_dataflow_parent_with_remote_bitfile_exec.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input 47\n",
      "input: tensor([[148.9900, 126.6900,  59.3100,  68.2400,  56.6500,  44.8700,  23.8400,\n",
      "           5.5900, -28.5800, -63.0600, -73.0800, -69.4100, -63.5300, -59.1300,\n",
      "         -64.5900, 158.4200],\n",
      "        [113.7300, 102.4700,  82.8900,  48.8500,  12.4900,   7.5800,  13.5200,\n",
      "          27.2100,  56.6300,  58.8800, -25.3000, -46.3800, -29.2300, -10.7900,\n",
      "           2.9500, 105.4800]]), output: 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the next input from the test_loader (dataset is random)\n",
    "\n",
    "test_input, test_output = next(iter(test_loader))\n",
    "test_output = test_output[0]\n",
    "\n",
    "print(\"input: {}, output: {}\".format(test_input[0], test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "# perform software inference locally here\n",
    "software_output = cnv_software_model(test_input)\n",
    "\n",
    "iname = parent_model.graph.input[0].name\n",
    "oname = parent_model.graph.output[0].name\n",
    "ishape = parent_model.get_tensor_shape(iname)\n",
    "\n",
    "input_dict = {iname: software_output[0].reshape(ishape).detach().numpy()}\n",
    "\n",
    "ret = execute_onnx(parent_model, input_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18508047 0.79409415 0.0208254 ]\n",
      "predicted: zigzag , actual: zigzag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 193,
       "width": 1153
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_logits(logits):\n",
    "    prediction_list = softmax(logits)\n",
    "    max_val = -1\n",
    "    prediction = 0\n",
    "    for i in range(len(prediction_list)):\n",
    "        if prediction_list[i] > max_val:\n",
    "            max_val = prediction_list[i]\n",
    "            prediction = i\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "logits = ret[oname].flatten()\n",
    "prob = softmax(logits)\n",
    "\n",
    "print(prob)\n",
    "print(\"predicted:\", classes[softmax_logits(logits)], \", actual:\", classes[int(test_output.tolist())])\n",
    "\n",
    "plt.figure(figsize=(20, 3)) \n",
    "plt.bar(classes, prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
